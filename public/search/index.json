[{"content":"使用log4j2 打印日志，对一些敏感数据进行脱敏。【通过配置选择哪个日志生效】\n一、常见日志框架 日志框架采用外观模式来实现，给系统提供门面，不暴露具体实现细节。\n1、外观模式 使用者只需和外观角色打交道就行\n2、门面 2.1 slf4j SLF4J是一款Java程序编写的日志门面框架，其本身定义了统一的日志接口，且对不同的日志实现框架进行抽象化，我们的应用只需要跟SLF4J进行沟通\n在引入包的时候，需要同时引入slf4j.jar，日志实现.jar，以及对应的适配包.jar\n日志使用中都是引入slf4j包里面的\n1 2 3 4 import org.slf4j.Logger; import org.slf4j.LoggerFactory; private final static Logger logger = LoggerFactory.getLogger(SLF4JandLog4j.class); 在执行的时候选择具体的实现系统\nSlf4j实现机制： Slf4j在编译期间，静态绑定本地的LOG库，因此可以在OSGi中正常使用。它是通过查找类路径下org.slf4j.impl.StaticLoggerBinder，然后绑定工作都在这类里面进。\n2.2 Commons Logging 是一个基于Java的日志记录实用程序，是用于日志记录和其他工具包的编程模型。它通过其他一些工具提供API，日志实现和包装器实现。Commons Loggin自动搜索并使用Log4j（Log4j是另一个流行的日志系统），如果没有找到Log4j，再使用JDK Logging。\n1 2 3 4 5 6 7 8 9 10 import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory; public class Main { public static void main(String[] args) { Log log = LogFactory.getLog(Main.class); log.info(\u0026#34;start...\u0026#34;); log.warn(\u0026#34;end.\u0026#34;); } } 3、实现 log4j logback Springboot 默认会使用logback 来记录日志，引入spring-boot-starter-logging的时候会引入如下包\npom 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;!--比较纯粹的时候logback--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;jul-to-slf4j\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;log4j-to-slf4j\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.apache.logging.log4j\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; Logback 则支持 XML 与 groovy 两种方式配置方式；\n配置 默认情况下，Spring Boot将日志输出到控制台，不会写到日志文件。可以在application.properties或application.yml配置，这样只能配置简单的场景，保存路径、日志格式等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 logging: level: # 全局输出级别 root: info # 指定包输出级别 com.huochai.controller: error pattern: # 输出格式(控制台输出格式) console: \u0026#34;%d - %msg%n\u0026#34; # 输出格式（文件输出格式） file: \u0026#34;%d - %msg%n\u0026#34; # 日志输出文件的位置 file: /Users/peilizhi/javaProects/log/logback.log # 日志输出文件的目录 path: # 没有指定logging.file 时会默认创建一个spring.log文件用于记录 /Users/peilizhi/javaProects/log # 自定义配置文件 # classpath 与文件地址要写在同一行中才有效 config: classpath:log/logback-test.xml 在配置的时候 系统不建议使用file 与 path 参数，可能是想通过自定义配置来指定文件输出位置\nlogging.file，设置文件，可以是绝对路径，也可以是相对路径。如：logging.file=my.log logging.path，设置目录，会在该目录下创建spring.log文件，并写入日志内容。 如果同时指定了logging.file 与logging.path 的话，logging.file 会生效，logging.path 不会生效 自定义配置 是xml 形式的配置文件，只需增加固定开头之后，可以直接书写配置\n固定开头：\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e\nconfiguration debug: 默认false\n​\ttrue :打印logback 内部执行日志 scan; 默认值为true\ntrue时，配置文件如果发生改变，将会被重新加载 scanPeriod ：加载的时间间隔，默认的时间间隔为1分钟。\n如果开启自动加载的话，有任何改动应该是立即生效的\nappender : 负责写日志的组件，定义了一些输出的格式、文件大小等\nname : 名称 class ： 全类名，常见的有ch.qos.logback.core.ConsoleAppender【控制台输出】、ch.qos.logback.core.rolling.RollingFileAppender[文件输出]。 ConsoleAppender 用于控制台输出\nencode ：对输出日志进行格式规范 target ： 字符串System.out(默认)或者System.err FileAppender 负责写日志到文件中\nfile：被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。　append：如果是 true，日志被追加到文件结尾，如果是 false，清空现存文件，默认是true。 encoder：对记录事件进行格式化。 prudent：如果是 true，日志会被安全的写入文件，即使其他的FileAppender也在向此文件做写入操作，效率低，默认是 false。 RollingFileAppender 滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件。可用于每天记录不同的日志到不同的文件中\nfile：被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。\nappend：如果是 true，日志被追加到文件结尾，如果是 false，清空现存文件，默认是true。\nrollingPolicy :当发生滚动时，决定RollingFileAppender的行为，涉及文件移动和重命名。属性class定义具体的滚动策略类\nTimeBasedRollingPolicy\n按照一定的时间执行滚动\nfileNamePattern ：包含文件名及“%d”转换符，“%d”可以包含一个java.text.SimpleDateFormat指定的时间格式，如：%d{yyyy-MM}。这就是滚动的时间规律， maxHistory：控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每个月滚动，且maxHistory是6，则只保存最近6个月的文件，删除之前的旧文件 SizeBasedTriggeringPolicy\n根据文件大小进行滚动\nmaxFileSize:这是活动文件的大小，默认值是10MB。 triggeringPolicy : 告知 RollingFileAppender 合适激活滚动。 logger 用于控制指定包或者类的打印策略，可以指定level，appender\nname : 全类名 level :日志级别 大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL和OFF，还有一个特殊值INHERITED或者同义词NULL，代表强制执行上级的级别。 如果未设置此属性，那么当前loger将会继承上级的级别。 append-ref : 指定的输出类，是之前appender 标签中name 字段的引用（可以指定多个） addtivity: 是否向上级logger传递打印信息。默认是true。可以包含零个或多个元素，标识这个appender将会添加到这个logger。 root 它也是元素，但是它是根loger,是所有的上级。只有一个level属性，因为name已经被命名为\u0026quot;root\u0026quot;,且已经是最上级了。\n日志格式 %m （%msg）输出代码中指定的消息\n%p（%level） 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL\n%r输出自应用启动到输出该log信息耗费的毫秒数\n%c输出所属的类目，通常就是所在类的全名\n%t输出产生该日志事件的线程名\n%n输出一个回车换行符，Windows平台为“\\r\\n”，Unix平台为“\\n”\n%d输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyy MMM dd HH:mm:ss,SSS}，\n%l输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main(TestLog4.java:10)\n%thread 线程名\nlogback的配置，需要配置输出源appender，打日志的logger（子节点）和root（根节点），实际上，它输出日志是从子节点开始，子节点如果有输出源直接输入，如果无，判断配置的addtivity，是否向上级传递，即是否向root传递，传递则采用root的输出源，否则不输出日志。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!--打印logback内部执行日志--\u0026gt; \u0026lt;configuration debug=\u0026#34;true\u0026#34; scan=\u0026#34;true\u0026#34; scanPeriod=\u0026#34;60 seconds\u0026#34;\u0026gt; \u0026lt;!--定义一些常用的参数--\u0026gt; \u0026lt;property name=\u0026#34;LOG_PATH\u0026#34; value=\u0026#34;/Users/peilizhi/javaProects/log\u0026#34;/\u0026gt; \u0026lt;!--控制台日志， 控制台输出 --\u0026gt; \u0026lt;appender name=\u0026#34;STDOUT\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;!-- class=\u0026#34;ch.qos.logback.classic.encoder.PatternLayoutEncoder\u0026#34;--\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度,%msg：日志消息，%n是换行符--\u0026gt; \u0026lt;pattern\u0026gt;%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{50} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;charset\u0026gt;UTF-8\u0026lt;/charset\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!--文件日志， 按照每天生成日志文件 --\u0026gt; \u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;!--当天正在使用的日志--\u0026gt; \u0026lt;file\u0026gt;${LOG_PATH}/logback.log\u0026lt;/file\u0026gt; \u0026lt;!--基于文件大小和时间的滚动策略--\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;!--日志文件输出的文件名【历史记录】--\u0026gt; \u0026lt;FileNamePattern\u0026gt;${LOG_PATH}/logback-%d{yyyy-MM-dd}-%i.log\u0026lt;/FileNamePattern\u0026gt; \u0026lt;!--日志文件保留天数--\u0026gt; \u0026lt;MaxHistory\u0026gt;60\u0026lt;/MaxHistory\u0026gt; \u0026lt;!--日志文件最大的大小--\u0026gt; \u0026lt;MaxFileSize\u0026gt;10MB\u0026lt;/MaxFileSize\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;encoder class=\u0026#34;ch.qos.logback.classic.encoder.PatternLayoutEncoder\u0026#34;\u0026gt; \u0026lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--\u0026gt; \u0026lt;pattern\u0026gt;%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{50} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;charset\u0026gt;UTF-8\u0026lt;/charset\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;!-- 日志过滤 --\u0026gt; \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.LevelFilter\u0026#34;\u0026gt; \u0026lt;!-- 指定日志级别 --\u0026gt; \u0026lt;level\u0026gt;ERROR\u0026lt;/level\u0026gt; \u0026lt;!-- 匹配则全部接受 --\u0026gt; \u0026lt;onMatch\u0026gt;ACCEPT\u0026lt;/onMatch\u0026gt; \u0026lt;!-- 不匹配则全部拒绝 --\u0026gt; \u0026lt;onMismatch\u0026gt;DENY\u0026lt;/onMismatch\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- 输出ERROR日志 --\u0026gt; \u0026lt;appender name=\u0026#34;ERROR_LOG_FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;${LOG_PATH}/logback-error.log\u0026lt;/file\u0026gt; \u0026lt;!-- 基于文件大小和时间的滚动策略 --\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;fileNamePattern\u0026gt;${LOG_PATH}/logback-error-%d{yyyy-MM-dd}-%i.log\u0026lt;/fileNamePattern\u0026gt; \u0026lt;!-- 日志文件保留天数 --\u0026gt; \u0026lt;maxHistory\u0026gt;60\u0026lt;/maxHistory\u0026gt; \u0026lt;!-- 单个日志文件大小 --\u0026gt; \u0026lt;maxFileSize\u0026gt;10MB\u0026lt;/maxFileSize\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;!-- 日志输出格式 --\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;[%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36}: %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;charset\u0026gt;UTF-8\u0026lt;/charset\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;!-- 日志过滤 --\u0026gt; \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.LevelFilter\u0026#34;\u0026gt; \u0026lt;!-- 指定日志级别 --\u0026gt; \u0026lt;level\u0026gt;ERROR\u0026lt;/level\u0026gt; \u0026lt;!-- 匹配则全部接受 --\u0026gt; \u0026lt;onMatch\u0026gt;ACCEPT\u0026lt;/onMatch\u0026gt; \u0026lt;!-- 不匹配则全部拒绝 --\u0026gt; \u0026lt;onMismatch\u0026gt;DENY\u0026lt;/onMismatch\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;appender name=\u0026#34;ASYNC_FILE\u0026#34; class=\u0026#34;ch.qos.logback.classic.AsyncAppender\u0026#34;\u0026gt; \u0026lt;!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --\u0026gt; \u0026lt;discardingThreshold\u0026gt;0\u0026lt;/discardingThreshold\u0026gt; \u0026lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为256 --\u0026gt; \u0026lt;queueSize\u0026gt;512\u0026lt;/queueSize\u0026gt; \u0026lt;!-- 添加附加的appender,最多只能添加一个 --\u0026gt; \u0026lt;appender-ref ref=\u0026#34;FILE\u0026#34;/\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- show parameters for hibernate sql 专为 Hibernate 定制 --\u0026gt; \u0026lt;logger name=\u0026#34;org.hibernate.type.descriptor.sql.BasicBinder\u0026#34; level=\u0026#34;TRACE\u0026#34;/\u0026gt; \u0026lt;logger name=\u0026#34;org.hibernate.type.descriptor.sql.BasicExtractor\u0026#34; level=\u0026#34;DEBUG\u0026#34;/\u0026gt; \u0026lt;logger name=\u0026#34;org.hibernate.SQL\u0026#34; level=\u0026#34;DEBUG\u0026#34;/\u0026gt; \u0026lt;logger name=\u0026#34;org.hibernate.engine.QueryParameters\u0026#34; level=\u0026#34;DEBUG\u0026#34;/\u0026gt; \u0026lt;logger name=\u0026#34;org.hibernate.engine.query.HQLQueryPlan\u0026#34; level=\u0026#34;DEBUG\u0026#34;/\u0026gt; \u0026lt;!--myibatis log configure--\u0026gt; \u0026lt;logger name=\u0026#34;com.apache.ibatis\u0026#34; level=\u0026#34;TRACE\u0026#34;/\u0026gt; \u0026lt;logger name=\u0026#34;java.sql.Connection\u0026#34; level=\u0026#34;DEBUG\u0026#34;/\u0026gt; \u0026lt;logger name=\u0026#34;java.sql.Statement\u0026#34; level=\u0026#34;DEBUG\u0026#34;/\u0026gt; \u0026lt;logger name=\u0026#34;java.sql.PreparedStatement\u0026#34; level=\u0026#34;DEBUG\u0026#34;/\u0026gt; \u0026lt;!-- 日志输出级别 --\u0026gt; \u0026lt;root level=\u0026#34;DEBUG\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;STDOUT\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;ASYNC_FILE\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;ERROR_LOG_FILE\u0026#34;/\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; 异步输出 AsyncAppender，异步记录日志。\nAsyncAppender并不处理日志，只是将日志缓冲到一个BlockingQueue里面去，并在内部创建一个工作线程从队列头部获取日志，之后将获取的日志循环记录到附加的其他appender上去，从而达到不阻塞主线程的效果。因此AsynAppender仅仅充当事件转发器，必须引用另一个appender来做事。\n由于使用了BlockingQueue来缓存日志，因此就会出现队列满的情况。正如上面原理中所说的，在这种情况下，AsyncAppender会做出一些处理：默认情况下，如果队列80%已满，AsyncAppender将丢弃TRACE、DEBUG和INFO级别的event\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u0026lt;appender name=\u0026#34;FILE\u0026#34; class= \u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;!-- 按天来回滚，如果需要按小时来回滚，则设置为{yyyy-MM-dd_HH} --\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;fileNamePattern\u0026gt;/opt/log/test.%d{yyyy-MM-dd}.log\u0026lt;/fileNamePattern\u0026gt; \u0026lt;!-- 如果按天来回滚，则最大保存时间为1天，1天之前的都将被清理掉 --\u0026gt; \u0026lt;maxHistory\u0026gt;30\u0026lt;/maxHistory\u0026gt; \u0026lt;!-- 日志输出格式 --\u0026gt; \u0026lt;layout class=\u0026#34;ch.qos.logback.classic.PatternLayout\u0026#34;\u0026gt; \u0026lt;Pattern\u0026gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} -%msg%n\u0026lt;/Pattern\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- 异步输出 --\u0026gt; \u0026lt;appender name =\u0026#34;ASYNC\u0026#34; class= \u0026#34;ch.qos.logback.classic.AsyncAppender\u0026#34;\u0026gt; \u0026lt;!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --\u0026gt; \u0026lt;discardingThreshold \u0026gt;0\u0026lt;/discardingThreshold\u0026gt; \u0026lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为256 --\u0026gt; \u0026lt;queueSize\u0026gt;512\u0026lt;/queueSize\u0026gt; \u0026lt;!-- 添加附加的appender,最多只能添加一个 --\u0026gt; \u0026lt;appender-ref ref =\u0026#34;FILE\u0026#34;/\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;root level =\u0026#34;trace\u0026#34;\u0026gt; \u0026lt;appender-ref ref =\u0026#34;ASYNC\u0026#34;/\u0026gt; \u0026lt;/root\u0026gt; log4j2 pom 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;!-- 排除默认的logback日志--\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-logging\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 引入log4j2配置--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-log4j2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-log4j2.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 引入异步log4j2--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.lmax\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;disruptor\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${disruptor}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置 1 2 logging: config: classpath:log/log4j2-test.xml 自定义配置 其中log4j2支持多个格式自定义配置：log4j2.properties log4j2.yaml log4j2.json `log4j2.xml\n加载的优先级为 properties \u0026gt; yaml \u0026gt; json \u0026gt; xml。\n配置文件的节点与logback文件节点大致一样\nconfiguration status :这个属性表示log4j2本身的日志信息打印级别。如果把status改为TRACE再执行测试代码，可以看到控制台中打印了一些log4j加载插件、组装logger等调试信息。 ​\t日志级别以及优先级排序: OFF \u0026gt; FATAL \u0026gt; ERROR \u0026gt; WARN \u0026gt; INFO \u0026gt; DEBUG \u0026gt; TRACE \u0026gt; ALL\nmonitorInterval: Log4j2 能够自动检测修改配置 文件和重新配置本身，设置间隔秒数 appender 有RollingFile、Console、RollingRandomAccessFile。\nRollingRandomAccessFileAppender 与 RollingFileAppender 在功能上基本一致，但是底层的实现有所区别，RollingFileAppender 底层是 BufferedOutputStream，RollingRandomAccessFileAppender 底层是使用 ByteBuffer + RandomAccessFile ，性能上有了很大的提升。\nRollingRandomAccessFileAppender fileName 指定当前日志文件的位置和文件名称 filePattern 指定当发生Rolling时，文件的转移和重命名规则 SizeBasedTriggeringPolicy 指定当文件体积大于size指定的值时，触发Rolling DefaultRolloverStrategy 指定最多保存的文件个数 TimeBasedTriggeringPolicy 这个配置需要和filePattern结合使用，注意filePattern中配置的文件重命名规则是${log_path}/zcrTest%d{yyyy-MM-dd}.log，最小的时间粒度是dd，即分钟，TimeBasedTriggeringPolicy指定的size是1，结合起来就是每一天生成一个新文件。如果改成%d{yyyy-MM-dd HH}，最小粒度为小时，则每一个小时生成一个文件。\nfilers Log4j2 中的过滤日志的配置，可以排除一些不需要的配置 。根据范围分为：\nContext-wide（全局配置），Logger ，Appender ，Appender Reference\n配置文件中节点的顺序， 全局Filter节点\u0026lt;Filters\u0026gt; 必须放在\u0026lt;properties\u0026gt;节点之后。 否则会出现意料不到的问题。例如本人碰到的就是 \u0026lt;PatternLayout pattern=\u0026quot;${pattern_debug_info_warn}\u0026quot; /\u0026gt; 替换失败。\n经常使用的filter\nCompositeFilter ： 组合模式，用以向外界提供统一的访问接口。\nThresholdFilter ： 这个Filter负责按照所配置的日志级别过滤Log Event，等于或超出所配置级别的log Event将返回onMatch结果。（threshold ： 阈值, 临界值; 门槛，入口）\nLevelRangeFilter ： 这个Filter也是负责按照日志级别过滤Log，只是相比较于ThresholdFilter，它比较的是指定区间范围。这里有一个需要密切注意就是其两个参数minLevel，maxLevel的配置；其和我们的思维惯式有着些许的差异，可能会造成困扰。细节之处可以查看StandardLevel中各个日志级别的底层数值，以及Level.isInRange的比较逻辑。概括而言就是 底层支撑的数值越小，日志危险级别越高。也就是我们如果想要只保留WARN到ERROR级别的日志，那么应该如下配置：\n```xml \u0026lt;LevelRangeFilter minLevel=\u0026quot;ERROR\u0026quot; maxLevel=\u0026quot;WARN\u0026quot; onMatch=\u0026quot;ACCEPT\u0026quot;\u0026gt; \u0026lt;/LevelRangeFilter\u0026gt; ``` DynamicThresholdFilter ：这个Filter允许依据ThreadContext中是否存在特定的某些值，以及日志级别来过滤LOG。\n策略\nACCEPT(接受)，DENY(拒绝)，NEUTRAL(中立)\n中立适合就是当前过滤器暂时不处理，交给后面的过滤器处理\n1 2 3 4 5 6 \u0026lt;Filters\u0026gt; \u0026lt;!--如果是error级别拒绝，设置 onMismatch=\u0026#34;NEUTRAL\u0026#34; 可以让日志经过后续的过滤器--\u0026gt; \u0026lt;ThresholdFilter level=\u0026#34;error\u0026#34; onMatch=\u0026#34;DENY\u0026#34; onMismatch=\u0026#34;NEUTRAL\u0026#34;/\u0026gt; \u0026lt;!--如果是debug\\info\\warn级别的日志输出--\u0026gt; \u0026lt;ThresholdFilter level=\u0026#34;debug\u0026#34; onMatch=\u0026#34;ACCEPT\u0026#34; onMismatch=\u0026#34;DENY\u0026#34;/\u0026gt; \u0026lt;/Filters\u0026gt; 完整配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 \u0026lt;Configuration status=\u0026#34;info\u0026#34;\u0026gt; \u0026lt;Properties\u0026gt; \u0026lt;property name=\u0026#34;LOG_PATH\u0026#34; value=\u0026#34;/Users/peilizhi/javaProects/log\u0026#34;/\u0026gt; \u0026lt;/Properties\u0026gt; \u0026lt;Filters\u0026gt; \u0026lt;!-- 全局级别Filter,放在property之后 --\u0026gt; \u0026lt;LevelRangeFilter minLevel=\u0026#34;ERROR\u0026#34; maxLevel=\u0026#34;DEBUG\u0026#34; onMatch=\u0026#34;ACCEPT\u0026#34;/\u0026gt; \u0026lt;/Filters\u0026gt; \u0026lt;Appenders\u0026gt; \u0026lt;Console name=\u0026#34;Console\u0026#34; target=\u0026#34;SYSTEM_OUT\u0026#34;\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{50} - %msg%n\u0026#34;/\u0026gt; \u0026lt;/Console\u0026gt; \u0026lt;RollingRandomAccessFile name=\u0026#34;fileAppender\u0026#34; fileName=\u0026#34;${LOG_PATH}/log4j2.log\u0026#34; filePattern=\u0026#34;${LOG_PATH}/log4j2-%d{yyyyMMddHH}-%i.log\u0026#34; append=\u0026#34;true\u0026#34; immediateFlush=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{50} - %msg%n\u0026#34;/\u0026gt; \u0026lt;Policies\u0026gt; \u0026lt;TimeBasedTriggeringPolicy/\u0026gt; \u0026lt;SizeBasedTriggeringPolicy size=\u0026#34;250 MB\u0026#34;/\u0026gt; \u0026lt;/Policies\u0026gt; \u0026lt;/RollingRandomAccessFile\u0026gt; \u0026lt;RollingRandomAccessFile name=\u0026#34;errorAppender\u0026#34; fileName=\u0026#34;${LOG_PATH}/log4j2-error.log\u0026#34; filePattern=\u0026#34;${LOG_PATH}/log4j2-error-%d{yyyyMMddHH}-%i.log\u0026#34; append=\u0026#34;true\u0026#34; immediateFlush=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{50} - %msg%n\u0026#34;/\u0026gt; \u0026lt;Policies\u0026gt; \u0026lt;TimeBasedTriggeringPolicy/\u0026gt; \u0026lt;SizeBasedTriggeringPolicy size=\u0026#34;250 MB\u0026#34;/\u0026gt; \u0026lt;/Policies\u0026gt; \u0026lt;!--appender 级别filer--\u0026gt; \u0026lt;Filters\u0026gt; \u0026lt;ThresholdFilter level=\u0026#34;ERROR\u0026#34; onMatch=\u0026#34;ACCEPT\u0026#34; onMismatch=\u0026#34;DENY\u0026#34;/\u0026gt; \u0026lt;/Filters\u0026gt; \u0026lt;/RollingRandomAccessFile\u0026gt; \u0026lt;/Appenders\u0026gt; \u0026lt;Loggers\u0026gt; \u0026lt;AsyncRoot level=\u0026#34;info\u0026#34; includeLocation=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;fileAppender\u0026#34;/\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;errorAppender\u0026#34;/\u0026gt; \u0026lt;/AsyncRoot\u0026gt; \u0026lt;/Loggers\u0026gt; \u0026lt;/Configuration\u0026gt; 日志格式 %d 表示时间，默认情况下表示打印完整时间戳 2012-11-02 14:34:02,123，可以调整 %d 后面的参数来调整输出的时间格式\n%p 表示输出日志的等级，可以使用 %highlight{%p} 来高亮显示日志级别\n%c 用来输出类名，默认输出的是完整的包名和类名，%c{1.} 输出包名的首字母和完整类名\n%t 表示线程名称\n%m 表示日志内容，%M 表示方法名称\n%n 表示换行符\n%L 表示打印日志的代码行数\n4、对比 老牌的 Log4j2 凭借着入场早、背靠 Apache 两大优势有着不错的用户支持，官网文档也很完善。\n新生的 Logback 凭借着 SLF4j 的原生实现以及被 Spring Boot 钦点的日志框架(Spring 也提供了Log4j2 的 starter，切换依赖即可完成更换日志框架，前文讲过，此处不再赘述)，同样也拥有着很好的前景。\n社区支持方面，Log4j2 作为 Apache 顶级项目，支持度应该是很不错的，Logback 作为Ceki创业后的产物，也能有很好的保证，二者生态可谓不相上下。\n日志的功能我们从使用者的角度可以分为：配置、使用、以及独有特性。配置文件方面，Log4j 提供了更多的配置文件配置方式，Log4j2 支持 properties、YAML、JSON、XML四种，Logback 则支持 XML 与 groovy 两种方式；\nAppender 方面，两者均支持自定义扩展 Appender ，Log4j2 并且提供了几乎全部场景的 Appender，文件、控制台、JDBC、NoSql、MQ、Syslog、Socket、SMTP等，Logback提供 Appender 略少于 Log4j2，提供了文件、控制台、数据库、Syslog、Socket、SMTP等，动态化输出方面，Log4j2 提供了ScriptAppenderSelector，Logback 则提供了 Evaluator 与 SiftingAppender(两者均可以用于判断并选择对应的 Appender)；\n独有特性方面，Logback 支持 Receivers， 可以接收其他 Logback 的 Socket Appender 输出，Logbak 还拥有 logback-access 模块，可以用来与 Servlet容器(如 Tomcat 和 Jetty)集成，提供 http 访问日志功能；Log4j2 则拥有号称能够减少 JVM 垃圾回收停顿时间的 Garbage-free(无垃圾模式)，Log4j2 API 支持使用 Java 8 lambda，SLF4j 则在 2.0 版本。\n总体来说，Logback 更加简单，并且与self4j 匹配更好（同一作者）。log4j2功能更加强大（filter过滤功能）\n二、日志输出规范 日志级别\nFATAL：系统级的错误，一旦出现，就意味着整个系统不能服务，是最严重的日志级别，一个进程的生命周期中应该只记录一次FATAL级别的日志，即该进程遇到无法恢复的错误而退出时 ERROR: 服务错误日志，项目还能正常使用，但是影响客户正常使用，而对于用户自己操作不当，如请求参数错误等等，是绝对不应该记为ERROR日志的； WARN: 该日志表示系统可能出现问题，也可能没有，这种情况如网络的波动等。对于那些目前还不是错误，然而不及时处理也会变为错误的情况，也可以记为WARN日志. INFO： 系统正常运行日志。某个子系统的初始化，某个请求的成功执行等等；记录一些项目执行的关键节点。INFO日志不宜过多，通常情况下，INFO级别的日志应该不大于TRACE日志的10%； DEBUG or TRACE：精确记录执行的过程，使用什么入参、执行顺序是什么、执行何种操作。 日志输出建议\n日志输出要精简，能够根据前后文推断出来的内容就不要再打了\n日志的目的是为了不重现问题的情况下，根据日志输出对问题进行诊断。\n生产环境的日志级别尽可能的设置高一点，避免大量日志打印\n在执行核心动作时要打日志记录，记录为INFO\n增删改操作需要打印参数日志（以便定位一些异常业务问题）\n条件分支需要打印日志：包括条件值以及重要参数；\n异常信息应该包括两类信息：案发现场信息和异常堆栈信息。如果不处理，那么通过关键字throws/throw 往上抛出，由父级方法处理\n不允许记录日志后又抛出异常，因为这样会多次记录日志\n反例\n1 2 3 4 if (virtualIpPortCrash) { log.error(\u0026#34;接入虚拟IP端口冲突\u0026#34;); throw new BusinessException(\u0026#34;接入虚拟IP端口冲突\u0026#34;); } 不允许出现 e.printStackTrace\n使用 {} 占位符\n建议规范：\n1 2019-12-01 00:00:00.000|pid|log-level|[svc-name,trace-id,span-id,user-id,biz-id]|thread-name|package-name.class-name : log message 打印异常\nlog.error(\u0026ldquo;异常信息: \u0026ldquo;, e); 能打印完整异常堆栈信息，建议使用，不要使用e.printStackTrace(); log.error(\u0026ldquo;异常信息: {}\u0026rdquo;, e.getMessage()); // 最简单的异常信息，没有异常类，没有堆栈 log.error(\u0026ldquo;异常信息: {}\u0026rdquo;, e.toString()); // 最简单的异常信息，有异常类，没有堆栈 三、日志拓展 1、 日志脱敏 链接：https://blog.csdn.net/qq_40885085/article/details/113385261\n","date":"2023-01-29T10:47:25+08:00","permalink":"https://blog.huochai.xyz/posts/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E6%97%A5%E5%BF%97/","title":"日志"},{"content":"核心思想 要想项目能够优雅的运行，需要从解决大数据量、大并发两个角度去解决这个问题\n解决大数据量 因为海量的数据导致增删改查操作变慢，导致客户体验变差（IO问题）\n解决大并发 因为大量请求过来导致CPU 处理不过来，没有及时响应，导致客户体验变差（内存问题）\n","date":"2022-12-08T10:18:15+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%9E%B6%E6%9E%84/%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF/","title":"设计思路"},{"content":"","date":"2022-12-05T18:53:32+08:00","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%8D%95%E4%BE%8B25%E6%A8%A1%E5%BC%8F/","title":"单例25模式"},{"content":"","date":"2022-12-05T02:08:55+08:00","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","title":"单例模式"},{"content":"一、适用点 1 2 3 对象在不同的状态有着不同的操作，并且这些状态是连续的。 在上下文中可以切换对象的状态，或者由前一状态可以自动切换到后一状态 同时需要注意，不同的状态都有操作，只不过是操作的方式不一样 二、结构 ","date":"2022-12-05T01:55:06+08:00","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F/","title":"状态模式"},{"content":"一、适用点 1 2 3 4 5 6 7 保存对象的各种状态。 不是复制对象自身（原型模式），而是将对象的各个属性值赋值给备忘录， 再将备忘录添加到集合中，统一管理，通过读取，写入备忘录来实现保存、恢复 适用集合来保存对象 二、结构 ","date":"2022-12-05T01:51:38+08:00","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F/","title":"备忘录模式"},{"content":"一、适用点 1 2 3 4 5 间接通信。接助中间的媒介来实现消息发送 当有多个对象彼此间相互交互的时候，自然就会想到对象间的耦合度过高， 解决办法就是封装对象间的交互行为，因此就能想到中介者模式就是干这行的。 避免直接通讯的时候，紧耦合的情况 二、结构 1 2 同事（Colleague）：将消息的内容发送给媒体，由媒体进行广播，或者点对点发送 同事需要注册到媒体中 ","date":"2022-12-05T01:49:38+08:00","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E4%B8%AD%E4%BB%8B%E8%80%85%E6%A8%A1%E5%BC%8F/","title":"中介者模式"},{"content":"","date":"2022-12-05T01:05:13+08:00","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","title":"工厂模式"},{"content":"一、使用点 1 不需要知道集合的内部情况，就可以对集合进行遍历。 二、定义 三、结构 四、常见应用场景 ","date":"2022-12-05T00:58:59+08:00","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F/","title":"迭代器模式"},{"content":"一、适用点 1 2 3 4 5 6 对与一个复杂对象，其构建的过程比较繁琐。 建造者模式可以将复杂对象的建造过程抽象出来，使这个抽象过程的不同实现方法可以构建出不同表现的对象 比如产品类中含有多个属性，抽象建造者规范了个属性的计算方法，具体建造者实现了这些方法（为产品的属性赋值），指挥者类调用抽象建造者的方法，并组合成产品，返回给客户。 针对复杂的产品，复杂的对象创建过程。 二、定义 1 按照构建蓝图组装产品。 三、结构 1 2 3 4 5 产品类（Product）：一个具体的产品对象 抽象建造者（Bulider）：创建一个Product对象的各个部分指定的接口 具体建造者(ConcreteBuilder)：实现接口，构建和装配各个 指挥者类：类中含有构建产品的步骤。构建一个Bulider接口对象，它主要用于创建一个复杂的对象， 有两个作用，一：隔离客户与对象的生产过程，二：负责控制产品对象的生产过程。 四、常见应用场景 1 2 使用lombok中的Build注解来实现 建造者模式所涉及到的产品大多数有着较多的共同点 五、对比 1 2 抽象工厂模式是对一系列的产品家族（具有不同属性维度的产品）进行生产的，生产的时候不关心生产的过程，只关心生产的结果。 建造者模式是根据产品设计的篮图来生产的。通过对零件的组装构建产品 ","date":"2022-12-05T00:53:25+08:00","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/","title":"建造者模式"},{"content":"一、适用点 1 2 3 4 5 桥接模式适用于一个对象有着多种维度的属性，如果想要完全的表示这些属性，使用继承体系的话会导致继承过深。 采用组合的形式将独立的属性引入进来。 适用条件：类中存在多个独立变化的维度，且 这些维度都需要独立地进行拓展 桥接模式通过抽象关联代替传统的多层继承，用动态的对象组合关系来取代类之间的静态继承\n二、定义 1 2 3 桥接模式是指将实现和抽象类放在不同的类层次中，使两个层次都能够独立变化 是结构型模式 采用“类的最小设计原则”，采用组合、聚合让不同的类承担不同的责任 三、结构 1 2 3 4 Abstaction:抽象类，作为桥梁，聚合了另一种维度的对象 class2:实现类，可以调用Implementor的方法来完成自身的功能 Implementor:接口，定义了另一种维度的操作，可供外界调用 ImplementorA:接口的实现类 四、常见的应用场景 1 2 3 4 1、JDBC驱动程序 2、消息管理 -消息类型：实时消息、延时消息（Implementor） -消息分类：手机消息、短信消息、QQ消息(Abstraction) ","date":"2022-12-05T00:52:13+08:00","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F/","title":"桥接模式"},{"content":"","date":"2022-12-05T00:50:31+08:00","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/nio/buffer/","title":"Buffer"},{"content":"一、FileChannel 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /** * FileChannel读取数据到buffer */ public static void main(String[] args) throws Exception { // 通过文件创建channel RandomAccessFile randomAccessFile = new RandomAccessFile(\u0026#34;/Users/peilizhi/file/one.txt\u0026#34;, \u0026#34;rw\u0026#34;); final FileChannel channel = randomAccessFile.getChannel(); // 分配一个1024大小到缓冲区 ByteBuffer allocate = ByteBuffer.allocate(1024); int len; // 从通道读取到缓冲区 -1表示结束 while ((len = channel.read(allocate)) \u0026gt; 0) { // 输出缓冲区 System.out.println(\u0026#34;len = \u0026#34; + len); allocate.flip(); while (allocate.hasRemaining()) { System.out.println(\u0026#34;allocate = \u0026#34; + (char) allocate.get()); } allocate.clear(); } //文件关闭的时候，管道同样关闭 randomAccessFile.close(); } 1.1 获取FileChannel 1 2 可以通过 FileInputStream 、FileoutputStream获取FileChannel 或者通过 RandomAccessFile 与一个文件关联，之后再获取数据 1.2 读取数据到Buffer 1 2 ByteBuffer allocate = ByteBuffer.allocate(1024); channel.read(allocate) // 返回读到多少字节，-1表示结束 1.3 写数据到Buffer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 通过文件创建channel RandomAccessFile randomAccessFile = new RandomAccessFile(\u0026#34;/Users/peilizhi/file/one.txt\u0026#34;, \u0026#34;rw\u0026#34;); final FileChannel channel = randomAccessFile.getChannel(); // 写入的内容 String context = \u0026#34;peilizhi\u0026#34;; ByteBuffer byteBuffer = ByteBuffer.allocate(1024); byteBuffer.clear(); // 先放入缓冲区 byteBuffer.put(context.getBytes(StandardCharsets.UTF_8)); // 转换模式,之前是读;现在是写 byteBuffer.flip(); // 如果还有byte while (byteBuffer.hasRemaining()) { channel.write(byteBuffer); } randomAccessFile.close(); 1 2 3 4 5 6 7 8 position() 获取通道中当前的位置 position(long newPosition) 设置通道中的位置 将位置设置为大于文件当前大小的值是合法的，但不会更改文件的大小。 稍后尝试在这样的位置读取字节将立即返回文件结束指示。 稍后尝试在这\t样的位置写入字节将导致文件增长以容纳新字 truncate（）：此频道的文件截断为给定的大小。 如果给定的大小小于文件的当前大小，则文件将被截断，丢弃超出文件新末尾的任何字节。 如果给定的大小大于或等于文件的当前大小，则不会修\t改文件 force（）：强制将管道数据写到磁盘上 transferTo（）、transferFrom（）管道之间数据传递 ","date":"2022-12-05T00:44:36+08:00","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/nio/filechannel/","title":"FileChannel"},{"content":" 1 2 3 4 5 6 7 8 9 所有Socket通道类（DatagramChannel、SocketChannel、ServerSocketChannel）继承AbstractSelectableChannel 可以通过Selector来执行Socket通道的就绪选择 ServerSocketChannel 不具备读和写的功能 Socket 不能被重复使用 Socket通道类 可以被重复使用 一、ServerSocketChannel 1 2 3 ServerSocketChannel 基于通道的socket 监听器 没有bind（） ，需要建立对等的socket 并使用它来监听端口 accept() 获取访问这个端口的socket，可以选择阻塞或者非阻塞的方式。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 ByteBuffer byteBuffer = ByteBuffer.wrap(\u0026#34;hello lizhi\u0026#34;.getBytes(StandardCharsets.UTF_8)); // 绑定的端口 int port = 8888; // 创建一个ServerSocketChannel final ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); // 用于监听8888端口 serverSocketChannel.socket().bind(new InetSocketAddress(port)); // 设置非阻塞模式 serverSocketChannel.configureBlocking(false); while (true) { // 如果是阻塞式的，会一直等待连接 final SocketChannel socketChannel = serverSocketChannel.accept(); if (null == socketChannel) { System.out.println(\u0026#34;不回答\u0026#34;); Thread.sleep(1000); } else { System.out.printf(\u0026#34;%s已经收到消息\\n\u0026#34;, socketChannel.socket().getRemoteSocketAddress()); // 指针回到起点 byteBuffer.rewind(); // 向通道内写数据 socketChannel.write(byteBuffer); socketChannel.close(); } } ","date":"2022-12-04T23:59:47+08:00","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/nio/serversocketchannel/","title":"ServerSocketChannel"},{"content":"解读 SHOW ENGINE INNODB STATUS; 显示的不是当前状态，是过去一段时间范围内innoDB 执行情况\nBACKGROUND THREAD 后台Master线程 SEMAPHORES 信号量信息 LATEST DETECTED DEADLOCK 最近一次死锁信息，只有产生过死锁才会有 TRANSACTIONS 事物信息 FILE I/O IO Thread信息 INSERT BUFFER AND ADAPTIVE HASH INDEX INSERT BUFFER和自适应HASH索引 LOG 日志 BUFFER POOL AND MEMORY BUFFER POOL和内存 INDIVIDUAL BUFFER POOL INFO 如果设置了多个BUFFER POOL实例，这里显示每个BUFFER POOL信息。可通过innodb_buffer_pool_instances参数设置 ROW OPERATIONS‍‍ 行操作统计信息‍‍ END OF INNODB MONITOR OUTPU 输出结束语 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 # 当前日期 ===================================== 2021-12-23 18:53:51 7f0c9cd28700 INNODB MONITOR OUTPUT ===================================== # 自上次输出以来的时间 Per second averages calculated from the last 39 seconds ----------------- BACKGROUND THREAD ----------------- # master Thread 执行情况 # srv_active为之前的每秒的循环，srv_idle为每10秒的的循环；srv_shutdown为停止的循环，通常为0，只在MySQL关闭时才会增加。 # 根据循环次数可大概判断当前数据库负载情况。如果每秒循环次数少，每10秒次数多，证明当前负载很低；如果每秒循环次数多，每10秒次数少，远大于10：1，证明当前负载很高。 srv_master_thread loops: 4346148 srv_active, 0 srv_shutdown, 2170504 srv_idle srv_master_thread log flush and writes: 6516648 ---------- 高并发相关 SEMAPHORES ---------- OS WAIT ARRAY INFO: reservation count 7814572 OS WAIT ARRAY INFO: signal count 12055502 Mutex spin waits 67497239, rounds 115662293, OS waits 610936 RW-shared spins 20467070, rounds 416284062, OS waits 6686750 RW-excl spins 1874510, rounds 19984783, OS waits 189941 Spin rounds per wait: 1.71 mutex, 20.34 RW-shared, 10.66 RW-excl ------------------------ 上次死锁情况 LATEST DETECTED DEADLOCK ------------------------ 2021-12-22 20:11:40 7f0bf43d2700 # 第一个事务 *** (1) TRANSACTION: # ACTIVE 表示事务活动时间 ,inserting:事务当前运行状态，其他状态：fetching rows，updating，deleting，inserting TRANSACTION 1191064881, ACTIVE 24 sec inserting # 有几张表被使用，是否有表锁，有几个表锁 mysql tables in use 1, locked 1 # 事务正在等待锁，锁链表结构的长度，每个结构表示持有的锁。为事务分配的堆内存大小，多少个行锁，有多少 undo 操作 LOCK WAIT 4 lock struct(s), heap size 1184, 4 row lock(s), undo log entries 2 MySQL thread id 8000428, OS thread handle 0x7f0bf6cf4700, query id 1632526539 218.106.117.210 saas update # 正在等待锁的sql语句,有可能不是罪魁祸首 insert into account values(null,\u0026#39;Jay\u0026#39;,100) # 正在等待的锁类型 *** (1) WAITING FOR THIS LOCK TO BE GRANTED: # 锁类型，要加锁的位置 RECORD LOCKS space id 8985 page no 4 n bits 72 index `idx_name` of table `logs`.`account` trx id 1191064881 lock_mode X locks gap before rec insert intention waiting Record lock, heap no 4 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 3; hex 576569; asc Wei;; 1: len 4; hex 80000002; asc ;; # 第二个事务 *** (2) TRANSACTION: # 执行的操作类型 TRANSACTION 1191068252, ACTIVE 13 sec inserting # 当前事务使用1个表，持有1个锁 mysql tables in use 1, locked 1 # LOCK WAIT表示正在等待锁, 6 lock struct(s) = 锁链表的长度为6 每个链表节点代表该事务持有的一个锁结构；heap size=表示事务分配的锁堆内存大小；5 row lock(s) = 该事物持有锁的个数 5 lock struct(s), heap size 1184, 4 row lock(s), undo log entries 2 MySQL thread id 8000380, OS thread handle 0x7f0bf43d2700, query id 1632530059 218.106.117.210 saas update # 执行的操作类型 insert into account values(null,\u0026#39;Yan\u0026#39;,100) *** (2) HOLDS THE LOCK(S): # 锁住的资源 index：加锁的索引 table：锁定记录的表， # page no =事务锁定页的数量，若是表锁，该值为null RECORD LOCKS space id 8985 page no 4 n bits 72 index `idx_name` of table `logs`.`account` trx id 1191068252 lock_mode X locks gap before rec Record lock, heap no 4 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 3; hex 576569; asc Wei;; 1: len 4; hex 80000002; asc ; *** (2) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 8985 page no 4 n bits 72 index `idx_name` of table `logs`.`account` trx id 1191068252 lock_mode X insert intention waiting Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;; # 回归的事务 *** WE ROLL BACK TRANSACTION (1) # 事务信息 ------------ TRANSACTIONS ------------ Trx id counter 1214468655 Purge done for trx\u0026#39;s n:o \u0026lt; 1214468577 undo n:o \u0026lt; 0 state: running but idle History list length 1220 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 0, not started MySQL thread id 8106341, OS thread handle 0x7f0c9cd28700, query id 1678904121 11.192.101.45 saas init /* Query from DMS-WEBSQL-0-Qid_1640256830846 by user 279411300834433704 */ SHOW ENGINE INNODB STATUS ---TRANSACTION 1214467717, not started MySQL thread id 8106333, OS thread handle 0x7f0bf43d2700, query id 1678902294 10.31.145.66 saas ---TRANSACTION 1214467397, not started MySQL thread id 8106335, OS thread handle 0x7f0b8d3d1700, query id 1678901639 10.31.151.204 saas ---TRANSACTION 1214467230, not started MySQL thread id 8106216, OS thread handle 0x7f0c049ea700, query id 1678901353 10.30.45.75 saas、 ---TRANSACTION 1210609693, not started MySQL thread id 3870812, OS thread handle 0x7f0c170c3700, query id 1678901177 10.31.145.188 saas ---TRANSACTION 1094399488, not started MySQL thread id 2697450, OS thread handle 0x7f0c1ffff700, query id 1678894754 192.168.16.1 saas -------- FILE I/O -------- I/O thread 0 state: waiting for completed aio requests (insert buffer thread) I/O thread 1 state: waiting for completed aio requests (log thread) I/O thread 2 state: waiting for completed aio requests (read thread) I/O thread 8 state: waiting for completed aio requests (write thread) Pending normal aio reads: 0 [0, 0, 0, 0] , aio writes: 0 [0, 0, 0, 0] , ibuf aio reads: 0, log i/o\u0026#39;s: 0, sync i/o\u0026#39;s: 0 Pending flushes (fsync) log: 0; buffer pool: 0 226529896 OS file reads, 58068025 OS file writes, 28146659 OS fsyncs 23.23 reads/s, 16384 avg bytes/read, 13.36 writes/s, 5.62 fsyncs/s ------------------------------------- INSERT BUFFER AND ADAPTIVE HASH INDEX ------------------------------------- Ibuf: size 1, free list len 3079, seg size 3081, 794285 merges merged operations: insert 1444947, delete mark 120928, delete 46386 discarded operations: insert 0, delete mark 0, delete 0 Hash table size 276671, node heap has 264 buffer(s) 5353.43 hash searches/s, 1740.62 non-hash searches/s --- LOG --- Log sequence number 59275700043 Log flushed up to 59275700025 Pages flushed up to 59275693466 Last checkpoint at 59275693466 0 pending log writes, 0 pending chkp writes 22166060 log i/o\u0026#39;s done, 4.59 log i/o\u0026#39;s/second # buffer pool 信息 ---------------------- BUFFER POOL AND MEMORY ---------------------- # 分配给缓冲池的总内存(以字节为单位)。 Total memory allocated 137363456; in additional pool allocated 0 # 分配给InnoDB数据字典的总内存(以字节为单位)。 Dictionary memory allocated 10573223 # 分配给缓冲池的页面的总大小。 Buffer pool size 8191 # 缓冲池空闲列表的总页大小。 Free buffers 1022 # buffer pool LRU列表的总页面大小。 Database pages 6905 # buffer pool old LRU子列表的总页面大小。 Old database pages 2528 Modified db pages 32 Pending reads 0 Pending writes: LRU 0, flush list 0, single page 0 Pages made young 94310767, not young 8050267524 10.82 youngs/s, 836.34 non-youngs/s Pages read 226502422, created 614802, written 34141947 23.23 reads/s, 0.10 creates/s, 8.56 writes/s Buffer pool hit rate 999 / 1000, young-making rate 0 / 1000 not 38 / 1000 Pages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/s LRU len: 6905, unzip_LRU len: 0 I/O sum[2140]:cur[2], unzip sum[0]:cur[0] -------------- ROW OPERATIONS -------------- 0 queries inside InnoDB, 0 queries in queue 0 read views open inside InnoDB Main thread process no. 1, id 139692453914368, state: sleeping Number of rows inserted 5027305, updated 15495535, deleted 381933, read 64931462045 0.64 inserts/s, 2.31 updates/s, 0.46 deletes/s, 7336.97 reads/s ---------------------------- END OF INNODB MONITOR OUTPUT ============================ ","date":"2022-12-04T23:58:17+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql-%E5%9F%BA%E7%A1%80/mysql%E6%AD%BB%E9%94%81/","title":"Mysql死锁"},{"content":"1、汉字排序 默认编码是utf8mb4，所以其实数据库存储的并不是汉字文本。按照内部的存储方式\n1 select * from table order by convert(filed using gbk) asc; 2、explain explain 用于查看sql执行的执行的情况\n1 EXPLAIN SELECT * FROM table_name WHERE plan_id =\u0026#39;\u0026#39;; id select_type table type possible_keys key key_len ref rows extra SELECT 查询的标识符 SELECT 查询的类型. 查询的是哪个表 此次查询中可能选用的索引 此次查询中确切使用到的索引. 哪个字段或常数与 key 一起被使用 显示此查询一共扫描了多少行. 这个是一个估计值. 额外的信息 select_type SIMPLE 表示此查询不包含 UNION 查询或子查询 PRIMARY, 表示此查询是最外层的查询 UNION, 表示此查询是 UNION 的第二或随后的查询 UNION RESULT, UNION 的结果 SUBQUERY, 子查询中的第一个 SELECT type 可以根据type 来确定如何查询\nsystem：表中只有一条数据.\nconst: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据\neq_ref: 唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配\n1 EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id ref: 针对于非唯一或非主键索引等值查询, 或者是使用了 最左前缀 规则索引的查询.\n1 2 EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id AND order_info.user_id = 5 # user_id 是联合索引的第一个索引 range： 使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 =, \u0026lt;\u0026gt;, \u0026gt;, \u0026gt;=, \u0026lt;, \u0026lt;=, IS NULL, \u0026lt;=\u0026gt;, BETWEEN, IN() 操作中.\nindex: 表示全索引扫描(full index scan), index 类型则仅仅扫描所有的索引, 而不扫描数据.\n1 2 EXPLAIN SELECT name FROM user_info; # name 是索引 ALL: 表示全表扫描\n性能：\nALL \u0026lt; index \u0026lt; range \u0026lt; ref \u0026lt; eq_ref \u0026lt; const \u0026lt; system\nextra Using filesort: MySQL 需额外的排序操作,查询 CPœU 资源消耗大. Using index: 覆盖索引扫描\u0026quot;, 表示查询在索引树中就可查找所需数据 Using temporary: 查询有使用临时表, 一般出现于排序 count 在统计数量的时候，也进行排序。\n查看表锁使用情况 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 1.查看当前数据库运行的所有事务（一般查不到，除非发生死锁） SELECT * FROM information_schema.INNODB_TRX; # 杀掉查询结果中锁表的trx_mysql_thread_id kill trx_mysql_thread_id # 查询是否锁表 show OPEN TABLES where In_use \u0026gt; 0; # 查询进程 show processlist # 查询到相对应的进程===然后 kill id # 查看正在锁的事务 SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS; # 查看等待锁的事务 SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS; # 查看锁执行情况 show status like \u0026#39;innodb_row_lock_%\u0026#39;; # Innodb_row_lock_current_waits : 当前等待锁的数量 # Innodb_row_lock_time : 系统启动到现在，锁定的总时间长度 # Innodb_row_lock_time_avg : 每次平均锁定的时间 # Innodb_row_lock_time_max : 最长一次锁定时间 # Innodb_row_lock_waits : 系统启动到现在总共锁定的次数 查询sql 操作 1 2 3 4 5 6 7 8 9 show status like \u0026#34;com_insert%\u0026#34;; -- 获得mysql的插入次数; show status like \u0026#34;com_delete%\u0026#34;; -- 获得mysql的删除次数; show status like \u0026#34;com_select%\u0026#34;; -- 获得mysql的查询次数; show status like \u0026#34;uptime\u0026#34;; -- 获得mysql服务器运行时间 show status like \u0026#39;connections\u0026#39;; -- 获得mysql连接次数 函数 ASCII(s) 返回字符串中第一个字符的ACSII码\n1 2 select ASCII(\u0026#39;xaioli\u0026#39;); # 结果： 120 CHAR_LENGTH（s） 返回字符串的长度\n1 2 select CHAR_LENGTH(\u0026#39;xiaoli\u0026#39;); # 结果 6 CONCAT(s1,s2,\u0026hellip;,sn) 将多个字符串合并\n1 2 select CONCAT(\u0026#39;xiaoli\u0026#39;,\u0026#39;xiaohong\u0026#39;); # xiaolixiaohong CONCAT_WS(x,s1,s2,\u0026hellip;,sn)\n通过字符X 将多个字符串合并\n1 2 select CONCAT_WS(\u0026#39;,\u0026#39;,\u0026#39;xiaoli\u0026#39;,\u0026#39;xiaohong\u0026#39;); # xiaoli,xiaohong [sql函数] https://www.runoob.com/mysql/mysql-functions.html Command + click 跳转\n​\ngroup by 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 使用 union all 来代替 or 查询. SELECT * FROM kpi.kpi_plan_info WHERE \u0026lt;include refid=\u0026#34;select_plan_condition\u0026#34;/\u0026gt; \u0026lt;if test=\u0026#34;accountId != null and accountId != \u0026#39;\u0026#39;\u0026#34;\u0026gt; and create_acc_id = #{accountId} \u0026lt;/if\u0026gt; UNION ALL SELECT * FROM kpi.kpi_plan_info WHERE \u0026lt;include refid=\u0026#34;select_plan_condition\u0026#34;/\u0026gt; \u0026lt;if test=\u0026#34;accountId != null and accountId != \u0026#39;\u0026#39;\u0026#34;\u0026gt; and associates_acc_ids LIKE CONCAT(\u0026#39;%\u0026#39;, #{accountId}, \u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; mysql操作查询结果case when then else end\n\u0026ndash;简单Case函数\nCASE column WHEN THEN value WHEN THEN value \u0026hellip;\u0026hellip; ELSE value END\n例： CASE sex WHEN \u0026lsquo;1\u0026rsquo; THEN \u0026lsquo;男\u0026rsquo; WHEN \u0026lsquo;2\u0026rsquo; THEN \u0026lsquo;女\u0026rsquo; ELSE \u0026lsquo;其他\u0026rsquo; END\n\u0026ndash;Case搜索函数 CASE WHEN [,] THEN value WHEN [,] THEN value \u0026hellip;\u0026hellip; ELSE value END\n例： CASE WHEN sex = \u0026lsquo;1\u0026rsquo; THEN \u0026lsquo;男\u0026rsquo; WHEN sex = \u0026lsquo;2\u0026rsquo; THEN \u0026lsquo;女\u0026rsquo; ELSE \u0026lsquo;其他\u0026rsquo; END\n（1）已知数据按照另外一种方式进行分组，分析。 SELECT SUM(population) , CASE country WHEN \u0026lsquo;中国\u0026rsquo; THEN \u0026lsquo;亚洲\u0026rsquo; WHEN \u0026lsquo;印度\u0026rsquo; THEN \u0026lsquo;亚洲\u0026rsquo; WHEN \u0026lsquo;日本\u0026rsquo; THEN \u0026lsquo;亚洲\u0026rsquo; WHEN \u0026lsquo;美国\u0026rsquo; THEN \u0026lsquo;北美洲\u0026rsquo; WHEN \u0026lsquo;加拿大\u0026rsquo; THEN \u0026lsquo;北美洲\u0026rsquo; WHEN \u0026lsquo;墨西哥\u0026rsquo; THEN \u0026lsquo;北美洲\u0026rsquo; ELSE \u0026lsquo;其他\u0026rsquo; END\nFROM country GROUP BY CASE country WHEN \u0026lsquo;中国\u0026rsquo; THEN \u0026lsquo;亚洲\u0026rsquo; WHEN \u0026lsquo;印度\u0026rsquo; THEN \u0026lsquo;亚洲\u0026rsquo; WHEN \u0026lsquo;日本\u0026rsquo; THEN \u0026lsquo;亚洲\u0026rsquo; WHEN \u0026lsquo;美国\u0026rsquo; THEN \u0026lsquo;北美洲\u0026rsquo; WHEN \u0026lsquo;加拿大\u0026rsquo; THEN \u0026lsquo;北美洲\u0026rsquo; WHEN \u0026lsquo;墨西哥\u0026rsquo; THEN \u0026lsquo;北美洲\u0026rsquo; ELSE \u0026lsquo;其他\u0026rsquo; END;\n(2) 更新 UPDATE country set population= CASE WHEN population \u0026gt; 600 THEN population-200 WHEN population\u0026lt;500 THEN population+300 else population END;\n建议加上 else ,否则如果条件都不满足的时候，属性会置为null\n","date":"2022-12-04T23:57:25+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql-%E5%9F%BA%E7%A1%80/mysql%E6%8A%80%E5%B7%A7/","title":"Mysql技巧"},{"content":"事务 隔离级别 事务实现 1、锁 共享锁（share lock） 共享锁也叫读锁，可以允许多个事务读取，但不支持其它事务进行更新操作\n允许持有锁的事务读取一行\n在sql 中手动加锁: select * from table where 1 lock in share mode\n1 2 3 4 5 6 begin; SELECT * FROM student WHERE id =1 lock in share MODE; begin; SELECT * FROM student WHERE id =2 lock in share MODE; # 执行ok ,多个事务可以共享读锁 排他锁(exclusive lock) 写锁，只要一个事务获取到这一行的排他锁之后，其他事务就不能获取这一行的共享锁和排他锁\n允许持有排他锁的事务更新或者删除一行\n新增、修改、删除都会默认加上排他锁\n在sql 中手动加锁： select * from table where 1 for update\n共享锁和排他锁都是行锁\n1 2 3 4 5 BEGIN; UPDATE student SET student_name=\u0026#39;xxxx\u0026#39; WHERE id=2; COMMIT SELECT * FROM student WHERE id =2 for UPDATE; 会针对每一行进行上锁\n事务一持有S 锁【针对同一行】：\n事务二可以获取s锁，不可以获取X 锁 事务一持有X 锁【针对同一行】：\n事务二不可以获取s锁，不可以获取X 锁 当innodb 搜索或扫描一个表索引时，它会在遇到的索引记录上设置共享或排他锁。因此，行级锁实际上是索引记录锁。\n如果表没有创建索引的话，innodb会创建一个默认索引。\n意向锁 意向锁是表锁，是为了快速判断表是否可以加锁，否则的话需要逐行去判断行上是否有事务。\n意向锁指示事务稍后需要表中的一行使用哪种类型的锁(共享或排他)。\n给行加上 共享锁或者排他锁之后，表会自动加上 共享意向锁或者排他意向锁：为了提高表锁效率\n1 2 3 给表加锁 lock tables table_name write; lock tables table_name read; intention shared lock (IS) (IS) ：指示事务稍后会对表中的每一行加上S Lock\nintention exclusive lock (IX) (IS) ：指示事务稍后会对表中的每一行加上X Lock\n1 2 3 4 5 # 为表加上 IS select ... for share; # 为表加上 IX select ... for update; 事务在获取表中某一行的共享锁之前，必须首先获取表上的IS锁或更强的锁。\n在事务可以在表中的行中获取独占锁之前，必须首先在表格上获取IX锁。\nX S IX IS X N N N N S N Y N(意味着后面会加入X锁) Y IX N N Y Y IS N Y Y Y 记录锁(Record lock) 每一条记录，使用等值查询的时候，每一条匹配到的就是上锁。粒度最小.\n可以防止对同一行进行 删除、更新。\n记录锁总是锁定索引记录，即使表没有定义索引。对于这种情况，InnoDB会创建一个隐藏的聚集索引，并使用这个索引进行记录锁定。\n间隙锁(gap lock) 不同索引之间的间隙\n查询的记录不存在，情况是查询语句中有范围，\n间隙锁主要是阻塞 insert,相同的间隙锁之间不冲突\ngap lock 可以有效避免幻读\n间隙锁是索引记录之间的间隙上的锁，或者第一个索引记录之前或最后一个索引记录之后的间隙上的锁。【开区间】\n间隙锁是性能和并发性之间权衡的一部分，\n如果查询条件使用唯一索引的话，gap lock 会退化成 Record lock\n如果id没有被索引或具有非唯一索引，则该语句将锁定前面的间隙。\n冲突锁可以由不同的事务在间隙上持有。例如，事务A可以持有一个间隙上的共享间隙锁(间隙s锁)，而事务B持有同一个间隙上的排他间隙锁(间隙x锁)。\n相同的间隙可以在不同的事务中持有不同的间隙锁（S或者X 都可以）\n临键锁(Next-key lock) 左开右闭区见。临键锁=记录锁+间隙锁\n外键检查约束以及重复键检查会使用间隙锁封锁区间\nnext-key锁是索引记录锁加上索引记录之前的间隙锁。\n如果一个会话对索引中的记录R有一个共享或排他锁，那么另一个会话不能在紧挨着索引顺序的R之前的间隙插入一个新的索引记录。\n","date":"2022-12-04T23:56:46+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql-%E5%9F%BA%E7%A1%80/mysql%E4%BA%8B%E5%8A%A1/","title":"Mysql事务"},{"content":"文件类型 参数文件 日志文件 Socket 文件 pid 文件 Mysql 表结构文件 存储引擎文件 参数文件 mysql 实例在启动的时候，会查找一些配置参数文件。用来寻找数据库的各种文件所在位置以及指定某些初始化参数。如果没有找到就会找编译Mysql 时指定的默认值和源代码中指定参数的默认值。如果没有找到mysql 架构，还是会启动失败\n参数 参数就是文本类型的，key/value 形式。\n1 2 3 4 5 # 查看数据库中所有参数 show variables # like 指定具体的参数key show variables like \u0026#39;\u0026#39; 参数类型\n动态 Global:修改了Global 当前session 内不会生效，新开的session 会生效，重启mysql 之后，就会恢复到配置文件的参数 Session： 修改了Session ，当前Session 立即生效，新Session 不会生效 静态【不可修改】 日志文件 错误日志 二进制日志 慢查询日志 查询日志 错误日志 错误日志记录mysql 启动、运行、关闭过程。\n1 2 show variables like \u0026#39;log_error\u0026#39;; /usr/local/mysql/data/mysqld.local.err 慢查询日志 Mysql 中启动时设置一个阀值，将运行时间大于这个一阀值 的sql 记录到慢查询日志中\n1 2 3 4 5 # 设置阀值 单位毫秒 show variables like \u0026#39;long_query_time\u0026#39;; # 运行sql 是否使用索引 默认关闭 show variables like \u0026#39;log_queries_not_using_indexes\u0026#39;; mysql 5.1 后，慢查询记录到表中 slow_log\n1 2 3 4 5 6 7 8 9 10 # 展示建表语句 show create table mysql.slow_log; # 查看慢查询输出格式 show variables like \u0026#39;log_output\u0026#39;; set global slow_query_log=\u0026#39;ON\u0026#39;;-- 启用慢查询 ,加上global，不然会报错的; # 查看慢sql 表 SELECT * from mysql.slow_log Mysqldumpslow\n1 2 3 4 5 6 7 8 9 10 11 mysqldumpslow [ OPTS... ] [ LOGS... ] -- 后跟参数以及log文件的绝对地址; 例： mysqldumpslow -s c -t 10 /var/run/mysqld/mysqld-slow.log # 取出使用最多的10条慢查询 mysqldumpslow -s t -t 3 /var/run/mysqld/mysqld-slow.log # 取出查询时间最慢的3条慢查询 mysqldumpslow -s t -t 10 -g “left join” /database/mysql/slow-log # 得到按照时间排序的前10条里面含有左连接的查询语句 mysqldumpslow -s r -t 10 -g \u0026#39;left join\u0026#39; /var/run/mysqld/mysqld-slow.log # 按照扫描行数最多的 1 2 3 4 5 6 7 8 9 10 11 12 13 14 CREATE TABLE `slow_log` ( `start_time` timestamp(6) NOT NULL DEFAULT CURRENT_TIMESTAMP(6) ON UPDATE CURRENT_TIMESTAMP(6), `user_host` mediumtext NOT NULL, `query_time` time(6) NOT NULL, `lock_time` time(6) NOT NULL, `rows_sent` int NOT NULL, `rows_examined` int NOT NULL, `db` varchar(512) NOT NULL, `last_insert_id` int NOT NULL, `insert_id` int NOT NULL, `server_id` int unsigned NOT NULL, `sql_text` mediumblob NOT NULL, `thread_id` bigint unsigned NOT NULL ) ENGINE=CSV DEFAULT CHARSET=utf8mb3 COMMENT=\u0026#39;Slow log\u0026#39; 通过long_query_io 将超过指定逻辑IO 次数的sql 记录到slow log 中，默认是100，\nslow_query_type:\n0: 不将s q l 记录到slow log 中 1: 根据运行时间将s q l 记录到slow log 中 2: 根据逻辑i o 次数将s ql 记录到slow log 中 3: 根据运行时间、逻辑i o 次数将s ql 记录到slow log 中 查询日志 查询日志记录了所有对mysql 数据库的请求，无论这些请求是否正确\nmysql 5.1 之后将记录放在general_log 表中\n1 select * from mysql.general_log; 二进制文件 二进制文件记录了对mysql 数据库执行的更新操作，但不包括 select 和show 操作，若操作没有对数据库产生影响，也有可能会写入二进制文件\n用户想要记录 select 和show 操作了，可以使用查询日志\n二进制文件名称一般为 主机名.二进制序列号：在配置文件中指明 binlog 为文件名，binlog.index为二进制索引文件，用来存储过往生成的二进制日志序列号\n二进制文件作用：\n恢复 复制：通过复制保证两个数据库同步 审计：根据二进制文件内容来判断是否有对数据库进行注入攻击 参数：\nMax_binglog_size: 单个二进制文件最大值 bing_cache_size : 有事务的时候，操作会记录到缓存中，提交之后将缓存中的内容写入到二进制文件，【基于会话的】，当数据库事务内容大于bing_cache_size，会写到临时文件中， Sync_binlog = [N ] 表示每写缓存多少次就同步到磁盘。默认是0 Bingo-do-db,binlog-ignore-db 表现需要写入或者忽略的那些库的日志 binlog_format:记录二进制的格式 STATEMENT: 逻辑s ql 语句 ROW: 记录表的行更改情况 MIXED： 两者结合 binlog_format=ROW可以为数据库恢复和复制更可靠，但会增大文件大小\n查看二进制文件：\nmysqlbinlog xx0001\npid 文件 mysql 启动时会将自己的进程ID写入文件中\ninnodb 存储引擎文件 表空间文件 innodb将数据存储按照表空间的形式存放。默认有一个10MB 的共享表空间，名称为ibdata1 的文件。\n可以为每张表设置独立的表空间，命名为: 表名.ibd\n1 2 # 查看每张表是否开启独立表空间 show variables like \u0026#39;innodb_file_per_table\u0026#39;; 在每张表的表空间中记录了：存储的数据，索引，插入缓冲BITMAP\n重做日志文件 在innodb 存储引擎目标中有两个文件ib_logfile0，ib_logfile1。是重做日志文件，用于记录每个事务的提交。\n每组重做日志文件以循环写入的方式运行，先写第一个文件，写满之后就会写第二个文件，第二个文件写满之后就会重复写第一个文件\nInnodb_log_file_size: 指定重做日志文件大小 Innodb_log_files_in_group: 指定每个组重做日志文件数量 对比重复日志文件与二进制文件\n二进制文件 重做日志文件 写入时机 每次提交时写 在事务进行中写入 内容 记录innodb 、MyisAM、Heap引擎的操作 只记录innodb 引擎的相关操作 格式 改日志的逻辑操作 每个页的更新的物理操作 重做日志文件条目结构\nredo_log_type space page_no redo_log_body 重做日志类型 表空间id(压缩方式) 页的偏移量 重做日志数据部分，需要根据特殊函数修复 写入重做日志的时机：\nmaster thread 每秒的操作：不论事务是否提交\nInnodb_flush_log_at_trx_commit参数：\n0： 事务提交时不写入，等待主线程操作\n1: 提交时同步刷新到磁盘中\n查看binlog日志\n1、先进入到data 目录\n2、使用命令查看文件\n1 mysqlbinlog --no-defaults --base64-output=decode-rows -v binlog.000024|more ","date":"2022-12-04T23:56:22+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql-%E5%9F%BA%E7%A1%80/mysql%E6%96%87%E4%BB%B6/","title":"Mysql文件"},{"content":"索引组织表 表如果按照主键的顺序存放的话，这个表就叫做索引组织表。\nInnodb存储引擎中每个表都有一个索引，如果不显示声明索引的话，会按照下面规则创建\n选择创建表时第一个定义的 唯一非空索引 没有 唯一非空索引 时会自动创建一个6字节大小的指针作为索引，（如果有唯一联合索引的时候也会创建6字节大小的指针） 可以通过 _rowid 来查看主键的值，只适合单独的列作为主键，不适合多个列的情况\n1 select *,_rowid from tablename; 逻辑结构 表空间(Tablespace) -\u0026gt; **段 **(Segment)-\u0026gt; 区(Exent)-\u0026gt;页（page）-\u0026gt; 行（row）\n表空间 所有的数据都存在表空间里面\ninnodb存储引擎有一个默认的表空间（ibdata1）,默认都放在共享表空间中\n如果开启 innodb_file_per_table 属性的话，每一个表都有独立的表空间: table name.idb\n1 show variables like \u0026#39;innodb_file_per_table\u0026#39;; 每张表的表空间里面值存储：数据、索引、插入缓冲Bitmap 页\n其他的如 undo信息、插入缓冲索引页、系统事务数据、二次写缓冲 还是存放在共享表空间里面\n1 2 3 4 5 6 7 # 未创建表时 idbata1.size = 12582912 # 创建表 CREATE TABLE `table1` ( `id` int NOT NULL, `name` varchar(45) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci 创建表时不会增加ibdata1 的容量\n段 段可以分为：数据段、索引段、回滚段。数据段在B+树的叶子节点，索引段在B+树的非叶子节点\n在每个段开始的时候，前32个零散的页用于存放数据，之后每一次申请64个页\n区 区是由连续的页组成，默认是1M,页可以被压缩\n1 show variables like \u0026#39;innodb_page_size\u0026#39;; 页 一个页的大小默认是16KB，可以压缩，设置完成之后不能表中不能再修改页的大小\n开启 innodb_file_per_table 属性 之后，每个表的大小是 96KB\n页分为：\n数据页 索引页 undo页 系统页 事务数据页 插入缓冲位图页 插入缓冲空闲列表页 未压缩的二进制大对象页 压缩的二进制大对象页（compressed BLOB Page） ","date":"2022-12-04T23:56:01+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql-%E5%9F%BA%E7%A1%80/mysql%E8%A1%A8/","title":"Mysql表"},{"content":"B+树的索引不是找到具体的行， 而是行说在的页。\n","date":"2022-12-04T23:55:37+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql-%E5%9F%BA%E7%A1%80/mysql%E7%B4%A2%E5%BC%95/","title":"Mysql索引"},{"content":"在Mysql 5.5 之后是默认存储引擎\n是第一个支持ACID 事务的存储引擎\n特点 行锁设置、MVCC 、支持外键、提供一致性非锁定读\n结构 内存池 共多个线程共享数据 缓存磁盘中的文件，，方便快速读取 重做日志缓冲 后台线程 刷新缓存池中的数据，保证数据是最近的 将缓存池中的数据存进磁盘 Master Thread 1 2 功能：将缓存池中的数据异步刷新到磁盘中 负责：脏页的刷新，合并插入缓存，UNDO 页的回收 IO Thread InnoDB 使用大量的 AIO 来处理写IO请求\n1 包括： write、read 、insert buffer、log IO 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 查看innodb 版本 show VARIABLES like \u0026#39;innodb_version\u0026#39;; # 查看innodb 线程 SHOW VARIABLES like \u0026#39;%_threads\u0026#39;; innodb_ddl_threads\t4 innodb_log_writer_threads\tON innodb_parallel_read_threads\t4 innodb_purge_threads\t4 innodb_read_io_threads\t4 innodb_write_io_threads\t4 max_delayed_threads\t20 max_insert_delayed_threads\t20 myisam_repair_threads\t1 mysqlx_min_worker_threads\t2 # 查看innodb 情况 show ENGINE INnodb STATUS; Purge Thread 1 mysql 事务提交之后，所使用的undo log 可能就不需要了，Purge thread 会回收已经分配的undo log Page Cleaner Thread 1 处理脏页刷新操作。 缓存池 缓存池是介于磁盘和cpu 的缓冲区域，能够有效的提交访问速度\n被实现成页面链表\n查询数据先查询缓存池内的数据，没有查到的话就查数据库，之后将数据Fix 进缓存池，之后修改的时候先修改缓存池，并且在合适的时候将数据写进磁盘\n1 2 # 查看缓存池的大小 show VARIABLES like \u0026#39;INNODB_buffer_pool_size\u0026#39;; 缓存池中有数据页、索引页、undo页，插入缓存、自适应哈希索引、Innodb存储的锁信息、数据字典信息\n内存的结构：\nLRU、Free、Flush List 每一页默认大小为16k\nLRU：最近最少使用策略。将最近读到的页放入到队列的开头，将很久之前读到的数据就在队尾，当队列不能存放新的页时候，清除队尾中的页\nInnoDB 使用的是优化的LRU,读到的页并不放在队列开头，而是放在队列的 5/8位置(midpoint )处，并且可以通过参数设置innodb_old_blocks_time用于表示页读到mi d 位置处还需要多久才放入到热端。\n这么做是为了避免有一些s q l 操作（扫描整个表）频繁将数据放入到开头，其实这些数据并不是访问次数最多的，只是临时查到了；\n1 2 3 4 5 # 查看midpoint 位置 show variables like \u0026#39;innodb_old_blocks_pct\u0026#39;; # 查看多少时间放入到热端,值越大，前面的数据越不容易刷出 show variables like \u0026#39;innodb_old_block_time\u0026#39;; 数据库刚启动的时候，LRU 队列的是空的，数据都在Free list 中，当需要从缓存中进行分页时候，首先从Free list查看是否有可用的空闲页，有则将该页将Free list 中删除，并加入到LRU List 中，否则根据LRU 算法淘汰末尾的页，将该内存空间分配给新的页\nInnodb 支持压缩页技术，将原本的16k 压缩成2k,4k,8k.压缩页组成的队列是 unzip_LRU，unzip_LRU 包含在LRU List 中\n在LRU 列表中被修改的页就是脏页，脏页存在Flush list 中\n重做日志缓存 在内存中还有一部分区域用于 存储重做日志，Innodb 首先将重做日志存入内存中的重做日志缓存，之后再写入重做日志文件。\n1 2 # 查看重做日志缓存大小 show variables like \u0026#39;innodb_log_buffer_size\u0026#39;; 16M 重做日志缓存不需要特别大，因为将缓存中的内容刷新到重做日志文件的频率很快\n刷新到重做日志的时机：\nMaster Thread 每一秒将重做日志缓存 写入到重做日志文件 事务提交 的时候 重做日志缓存空间中剩余空间小于1/2 时 checkout point 数据库先写重做日志文件，再写入磁盘。来满足事务的持久性\n在数据库宕机的时候，可以将重做日志日志文件写入到磁盘，保证数据不丢失,checkout point 保证写入的数据不会太多，只刷新checkout 之后的操作。\ncheckout解决：\n缩短数据库恢复时间 缓存池不够时，将脏页刷进磁盘 重做日志不可用时，刷新脏页 如果缓存没有空余的空间时，淘汰很久没用的页，如果页是脏页，就强制执行checkout point，写入磁盘\n重做日志文件是循环覆盖的，如果被覆盖的内容还是需要使用的，就强制执行checkout point，写入磁盘\nCheckout point 可以分为两种： Sharp Checkout(关闭数据库时执行)、Fuzzy Checkout\n执行Fuzzy Checkout 的时机\nMaster thread ：每十秒将脏页以一定的比例写入到磁盘\nFlush_LRU_List： LRU 要留100页空余可用，不够时，尾部页移除，如果是脏页就Checkout point\n重做日志不可用\nDirty page too much\n1 2 # 缓存池中脏页的最大占比 show variables like \u0026#39;innodb_max_dirty_pages_pct\u0026#39;; 90% Master Thread Master Thread 具有最高线程优先级。内部有多个loop ：loop、backgroup loop、flush loop、suspend loop\nLoop:\n每一秒做的事 重做日志缓存刷新到磁盘，尽管事务还没有提交【总是】 合并插入缓存【可能】：前一秒内IO 操作\u0026lt; 5 至多刷新100个脏页到磁盘【可能】 ： 实际脏页数\u0026gt; 最大脏页百分比 没有活动，切换到backgroud loop【可能】 每十秒做的事 刷新100个脏页到磁盘【可能】： 10秒内Io 次数\u0026lt;200 合并至多5个插入缓存【总是】 将日志缓存刷新到磁盘【总是】 删除无用的undo 页【总是】对表的更新、删除操作，原来的行被标记删除，如果后续没有使用，就执行删除 刷新100个脏页到磁盘【总是】 Backgroup loop:(数据库空闲或则数据库关闭)\n删除无用的undo 页【总是】 合并20个插入缓存【总是】 跳回主循环【总是】 不断刷新100页直到满足条件（会跳到flush loop） flush loop 如果没什么可做的话会进入suspend loop 会将Master Thread 暂时挂起，等待事件发生。\n关键特性 插入缓存 聚集索引：以主键建立的索引，索引的顺序与主键的顺序是一致的。一个表只能有一个聚集索引\n非聚集索引：除了主键以外的索引。\nInner buffer 并不存在缓存中，而是实际的物理页。\n对于非聚集索引的插入或者更新操作，不是直接插入到索引页，先判断插入到非聚餐索引页是否存在缓冲池，如果在就直接插入，如果不在就先放在insert buffer 对象中，再以一定的频率和情况进行insert buffer 和辅助索引页字节点 merge 操作\n使用Insert buffer 条件\n索引是辅助索引 索引不唯一 如果在写密集的情况下，insert buffer 会占用过多的缓冲池，可以控制最多占比\nchange buffer InnoDB对 Insert、de lete、update 都做缓冲，分别是；Insert Buffer ,Delete Buffer, Purge Buffer.\nUpdate 分为两步：\n原数据标记删除 真正删除原数据 Delete Buffer 对应第一步，Purge Buffer对应第二步\nInsert Buffer 、Change Buffer 都是B+ 树\nMerge Insert Buffer Merge Insert Buffer 就是将插入缓存 合并到实际的缓存中\nMerge Insert Buffer 的操作时机：\n辅助索引页被读到缓存 Insert Buffer Bitmap 页追踪到改辅助索引页已无可用空间 两次写 部分写失效：数据库正在写入某页到表中，并且只写了一部分，此时数据库发生宕机。\n此时可以通过重做日志文件来恢复，但是重做日志中记录的是对页的物理操作，比如偏移量，如果页已经失效，那么偏移量就没有意义啦。\ndouble wirte 分为两部分，一部分是内存中的double write buffer ，大小是2mb .另一个物理磁盘上共享空间上连续的128页，2MB.\n在对脏页进行刷新对时候，通过mempy 将脏页复制到内存中的double write buffer，之后double write buffer 分两次1MB 顺序写到共享空间，之后调用fsync 函数同步磁盘\n自适应哈希索引 哈希是一种快速的查询方式，时间一般O（1），B+树的查询次数与树的高度有关。\nInnodb 会根据查询自动建立哈希索引，需要对页的连续访问模式是一样的，并且只支持等值查询\n异步io 异步io不会等待i o的执行结果。异步i o可以将多个i o进行合并\n刷新邻接页 当有脏页需要刷新时，会检查与它相临的页是否是脏页，如果是就一起刷新。\n可以将多个i o 合并成一个io\n启动、关闭、恢复 在关闭mysql 时，innodb_fast_shutdown 影响着innodb 的行为，默认为1\ninnodb_fast_shutdown：\n0：Innodb完成所有 full purge ,merge insert buffer .将脏页刷新到磁盘。在innodb 升级时必须调成0 1: 不需要 full purge ,merge insert buffer，但是将脏页刷新到磁盘 2: 不需要 full purge ,merge insert buffer，不将脏页刷新到磁盘，将操作写到日志文件中，数据库启动的时候，进行恢复操作 Innodb_force_recovery 影响innodb 恢复情况。默认是0\n1: 忽略检查到的corrupt 页 2: 阻止master thread 3: 不进行事务回滚 4: 不进行插入缓存合并 5: 不查看undo log ,忽略位提交的事务 6: 不进行前滚操作 Innodb_force_recovery \u0026gt; 0 ,不能执行 insert、update 、delete\n","date":"2022-12-04T23:55:18+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql-%E5%9F%BA%E7%A1%80/mysql%E5%86%85%E5%AD%98/","title":"Mysql内存"},{"content":"数据库：各种存储数据的文件集合\n实例：访问数据库文件的程序\nMysql数据库是单进程多线程。数据库的实例就在系统上表现为一个进程\n在启动Mysql 的时候会根据配置文件来启动，如果没有找到配置文件的话，就按照编译时的默认参数来启动数据库，Oracle 则会提示失败。\n1 2 3 mysql --help |grep my.cnf /etc/my.cnf /etc/mysql/my.cnf /usr/local/mysql/etc/my.cnf ~/.my.cnf mysql 启动时会以最后一个配置文件中定义的参数为准。\n1 2 3 4 5 # 查看数据存储的位置： show variables like \u0026#39;datadir\u0026#39;; 查看权限为 drwxr-x--- 35 _mysql _mysql 1120 12 18 18:16 data 存储引擎是基于表的，不是基于数据库的\n体系结构\n在创建表的时候可以指定 存储引擎\n1 create table table_name engine=InnoDB 链接数据库的时候本质是 进程通讯，使用TCP/IP\n1 2 # 指定服务器、用户、密码 mysql -h ip -u root -p 在链接的时候需要查看权限视图，检查用户是否可以登陆（可以登陆的ip，密码）\n1 2 use mysql; select host,user,password form user; show variables like \u0026rsquo;\u0026rsquo; : 可以查看一些配置项\ninnodb 架构图：\n","date":"2022-12-04T23:55:00+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql-%E5%9F%BA%E7%A1%80/mysql%E6%A6%82%E5%BF%B5/","title":"Mysql概念"},{"content":"一、定义 1 2 数据库：物理操作文件或者其他形式文件的集合。文件包括：frm,MYD,MYI,存在二级存储器的文件 实例：后台进程以及共享内存组成。数据库实例才是真正操作文件的。是程序，处于用户与数据库之间 Mysql数据库是单进程多线程\n1 2 3 4 5 在Mysql数据库启动时会查找配置文件，根据配置文件内容启动程序，如果没有配置文件时候就按照编译时的默认参数来启动 mysql --help|grep my.cnf 指令用于查看启动配置文件的位置 etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf 安装顺序加载配置文件，以最后加载到的配置项为准 1 2 配置文件中有datadir配置项，用于指定数据库文件所在路径（是一个链接） 目录的用户是Mysql、组都是Mysql 二、结构 1 2 3 4 5 6 7 8 9 组成： 连接池组件 管理服务和工作组件 SQL接口组件 查询分析组件 优化器组件 缓存组件 插件式存储引擎 物理文件 存储引擎是基于表的，不是基于数据库的\n三、InnoDB 1 2 3 支持事务，行锁，支持外键，非锁定读（读数据时不会产生锁） 采用聚簇存储，存储主键和行数据 插入缓存，二次写、自适应哈希 四、Myisam 1 2 3 不支持事务、表锁，不支持外键、支持全文索引 缓存池只缓存索引文件，不缓存数据文件 文件以.myd,.myi组成,.myd存储数据、.myi存储索引 五、连接 1 连接方式有管道、TCP/IP、UNIX套接字、命名管道 5.1、TCP/IP 1 2 TCP/IP是常见的网络连接，由客户端向服务器发起连接请求。在请求的时候需要根据权限视图来检查登录情况。 视图中制定了 host（请求地址，%代表所有），user,passwd等 5.2 UNIX套接字 1 2 3 4 在Linux、UNIX环境中可以通过UNIX套接字来连接 首先查看Unix文件位置： show variables like \u0026#39;socket\u0026#39;; 连接 mysql -udavid -S 文件位置 六、体系 1 2 内存块：缓存磁盘上的数据、为线程、进程提供公共的数据结构、重做日志缓存 后台线程：刷新内存池的数据，保证缓存池中的数据是最新的，将已存在的数据写入到磁盘空间 1、Master Thread 1 将缓存池中的数据异步刷新到磁盘：脏页的刷新、UNDO页的回收、合并插入缓存 2、IO Thread 1 2 3 InnoDB存储引擎中大量使用AIO(Async IO)来处理Io请求，IO Thread用于处理IO请求的回调 分别是write、read、insert buffer 、log IO Thread 通过show VARIABLES like \u0026#39;innodb_version\u0026#39;\\G查看线程数 3、Purge Thread 1 用于回收已经使用并分配的undo页 SHOW ENGINE INNDB STATUS \\G： 可以查看存储引擎的信息\n七、内存 1 2 3 4 5 6 InnoDB是基于磁盘存储的，并将内容按照页的方式进行管理。使用缓存来解决内存与磁盘之间读写的差异。 在数据库进行读取页操作的时候，首先将读取到的页存放在缓冲池中，称为页FIX在缓冲池，下次读取相同的页的时候， 首先判断页在不在缓冲池，如果在就读取缓冲池，不在就读取数据库 数据库中页的修改操作，首先修改缓冲池中的页，然后再以一定的频率刷新到磁盘。 1 缓冲池缓存的数据页型有：索引页，数据页，undo页，插入缓冲、自适应哈希索引、InnODB存储的锁信息、数据字典 1 2 3 4 5 6 7 缓冲池中存在三种队列：LRU、Free、Flush. LRU队列存在查询过的页（有脏页） Free队列存放未查询过的页 Flush存放脏页（修改过的页） LRU队列采用谁先被访问谁在队列头的策略。但是有新的页进入队列的时候不是放在队列头，而是放在队列37%的位置（midpoint）[参数是innodb_old_blocks_pct]。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 重做日志缓冲 InnoDB首次将重做日志信息写入到重做日志缓存，之后按照一定频率将其刷新到重做日志文件（每一秒刷新一次） 刷新条件： Master Thread 每一秒将重做日志缓冲刷新到重做日志文件 每一事务提交时 当重做日志缓冲池剩余空间小于50% 脏页数量太多 [为了避免数据丢失，先将数据写入到重做日志，再写入页中] 在数据库发生宕机之后，只需将Checkpoint 后的重做日志文件进行恢复，不需要完全恢复。 InnoDB存储引擎，使用LSN标记版本 （8字节数字）\nCheckpoint就是将缓存中的脏页刷回磁盘\n1 2 3 有两种刷新方式： Sharp Checkpoint: 在数据库关闭时将所有脏页都刷回磁盘 Fuzzy Checkpoint: 每次只刷新一部分脏页 插入缓冲 聚集索引：数据行的物理顺序与列值的顺序是一样的。一张表只有一个聚集索引\n非聚集索引：数据行的物理顺序与列值的顺序是不一样的\n如果我们查询的值在索引的范围内，就只需做一次查询，如果查询的结果中还有其他的值，就需要再查询所有【二次查询】\n1 2 3 4 5 6 7 8 9 10 Insert Buffer 和数据页一样，都是物理页的组成部分 如果采用自增主键的方式，插入会很快 两个条件： 索引是辅助索引 索引不唯一 将多个插入合并到一个插入 对Insert、Delete、Update，操作的时候，先写入缓存，在合适的时机将 Insert Buffer合并到索引中。 时机是： 辅助索引页被读取到缓冲池中、Master Thread 、Insert Buffer Bitmap页追踪到改辅助索引页已无可使用空间 两次写 1 2 3 4 5 6 7 doublewrite有两部分组成：一部分是内存中的doublewirte buffer 大小为2M，另一部分为物理磁盘上共享表空间上连续的128页，大小为2M 第一次写是将被损坏的页写入磁盘 第二次写是将重做日志中失败的内容写入磁盘 skip_innodb_doublewrite 开关来控制是否开启两次写 自适应哈希（AHI） 1 2 3 innodb会自动为查询频繁的数据建立索引。能建立哈希索引带速度提升的时候，会自动创建自适应哈希 自适应哈希适合等值查询，并且要求访问的模式是一样的（查询时，参数出现的位置要固定） 异步IO 1 2 3 4 Innodb引擎不需要等待一个请求彻底执行完成之后，在返回结果。 并且在查询的时候也可以进行Merge iO操作，将查询连续的页作为一次查询 read ahead 方式的读取是通过AIO完成的，脏页的刷新（磁盘的写入）都是通过AIO实现的 刷新邻接页 1 在执行脏页刷新的时候，如果邻接的页也是脏页的话，也就merge io ，一起刷新 启动、关闭、恢复 1 2 3 4 innodb_fast_shutdown 影响在Mysql关闭的时候，Innodb引擎的处理。默认值是1 0：在数据库关闭的时候，Innodb执行所有full purge and merge insert purge,并将所有脏页刷回磁盘；【在innodb升级的时候，必须调为0】 1：不执行full purge and merge insert purge，仅执行将所有脏页刷回磁盘 2：不执行full purge and merge insert purge也不执行将所有脏页刷回磁盘。仅将操作写入日志，在下次启动时进行恢复。 尽量不要使用Kill指令\n","date":"2022-12-04T23:54:36+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql-%E5%9F%BA%E7%A1%80/mysql%E4%BD%93%E7%B3%BB/","title":"Mysql体系"},{"content":"一、使用Brew 安装 1 2 3 brew tap mongodb/brew // 下载 后面指定版本 brew install mongodb 执行 echo \u0026rsquo;export PATH=\u0026quot;/usr/local/opt/mongodb-community@4.4/bin:$PATH\u0026quot;\u0026rsquo; \u0026raquo; ~/.zshrc\n二、启动 1 brew services start mongodb 如果想要使用 mongod 来启动并制定配置文件位置\n在.bash_profile添加配置\n1 2 # MongoDB Aliases alias mongod=\u0026#34;mongod --config /usr/local/etc/mongod.conf --fork\u0026#34; 启动问题\n1 2 如果启动时提示：Data directory /data/db not found. Create the missing directory or specify another path using (1) the --dbpath command line option, or (2) by adding the \u0026#39;storage.dbPath\u0026#39; option in the configuration file.\u0026#34;}} 在配置文件中指定了新的data位置。 三、配置文件 1 2 3 4 5 6 7 8 systemLog: destination: file path: /usr/local/var/log/mongodb/mongo.log logAppend: true storage: dbPath: /usr/local/var/mongodb net: bindIp: 127.0.0.1 四、创建员工 4.0 启动mongo 4.1 已非授权模式登陆 1 mongo 4.2 切换到admin数据库 1 use admin 4.3 创建用户 1 2 3 4 5 db.createUser({ user: \u0026#34;huochai\u0026#34;, pwd: \u0026#34;Asdf1234\u0026#34;, roles:[ \u0026#34;dbOwner\u0026#34; ] }) 4.4 认证 1 db.auth(\u0026#34;huochai\u0026#34;,\u0026#34;Asdf1234\u0026#34;) 4.5 登陆客户端 url mongodb://huochai:Asdf1234@127.0.01:27017\n数据库之间的账号是独立的，需要在新建的数据库中在重新创建用户\nmongodb://appraisal:appraisal@101.200.156.46:27018/appraisal?authSource=appraisal\n","date":"2022-12-04T23:52:54+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mongo/mongo%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85/","title":"Mongo下载安装"},{"content":"依赖注入框架可以创建线程安全的、基于事务的 SqlSession 和映射器，并将它们直接注入到你的 bean 中，因此可以直接忽略它们的生命周期。\nSqlSessionFactoryBuilder 这个类可以被实例化、使用和丢弃，一旦创建了 SqlSessionFactory，就不再需要它了。 因此 SqlSessionFactoryBuilder 实例的最佳作用域是方法作用域（也就是局部方法变量）。\nSqlSessionFactory **SqlSessionFactory 一旦被创建就应该在应用的运行期间一直存在，**没有任何理由丢弃它或重新创建另一个实例。 使用 SqlSessionFactory 的最佳实践是在应用运行期间不要重复创建多次，多次重建 SqlSessionFactory 被视为一种代码“坏习惯”。因此 SqlSessionFactory 的最佳作用域是应用作用域。 有很多方法可以做到，最简单的就是使用单例模式或者静态单例模式。\nSqlSession 每个线程都应该有它自己的 SqlSession 实例。SqlSession 的实例不是线程安全的，因此是不能被共享的，所以它的最佳的作用域是请求或方法作用域。 绝对不能将 SqlSession 实例的引用放在一个类的静态域，甚至一个类的实例变量也不行。 也绝不能将 SqlSession 实例的引用放在任何类型的托管作用域中。\n这个关闭操作很重要，为了确保每次都能执行关闭操作，你应该把这个关闭操作放到 finally 块中。\n请求执行完成之后需要关闭，必须关闭\n映射器实例 映射器是一些绑定映射语句的接口。映射器接口的实例是从 SqlSession 中获得的。\n","date":"2022-12-04T23:52:16+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mybatis/mybatis%E4%BD%9C%E7%94%A8%E5%9F%9F/","title":"Mybatis作用域"},{"content":"一、 安装 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;x.x.x\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 二、简单使用 每个基于 MyBatis 的应用都是以一个 SqlSessionFactory 的实例为核心的。SqlSessionFactory 的实例可以通过 SqlSessionFactoryBuilder 获得。而 SqlSessionFactoryBuilder 则可以从 XML 配置文件或一个预先配置的 Configuration 实例来构建出 SqlSessionFactory 实例。\n2.1 如何创建SqlSessionFactory 答：采用工厂方法，先创建SqlSessionFactoryBuilder，之后再构建SqlSessionFactory。\n2.2 如果创建SqlSessionFactoryBuilder 答：xml 配置文件或者java配置类\n2.2.1 xml配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;/\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;${driver}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;${url}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;${username}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;${password}\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper resource=\u0026#34;org/mybatis/example/BlogMapper.xml\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;/configuration\u0026gt; 1 可以将xml理解成java对象，里面有environments、mappers等属性 1 2 3 4 // 通过读取文件来创建 String resource = \u0026#34;org/mybatis/example/mybatis-config.xml\u0026#34;; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); XML 配置文件中包含了对 MyBatis 系统的核心设置，包括获取数据库连接实例的数据源（DataSource）以及决定事务作用域和控制方式的事务管理器（TransactionManager）。\n2.2.2 java配置类 1 2 3 4 5 6 7 8 9 10 11 12 DataSource dataSource = BlogDataSourceFactory.getBlogDataSource(); TransactionFactory transactionFactory = new JdbcTransactionFactory(); // 创建环境 Environment environment = new Environment(\u0026#34;development\u0026#34;, transactionFactory, dataSource); // 构造配置 Configuration configuration = new Configuration(environment); configuration.addMapper(BlogMapper.class); // 创建SqlSessionFactory，根据配置对象创建 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(configuration); 2.3 如果使用SqlSessionFactory 答：创建SqlSession。大多数工厂类的作用\n2.4 SqlSession作用 答：SqlSession 提供了在数据库执行 SQL 命令所需的所有方法。你可以通过 SqlSession 实例来直接执行已映射的 SQL 语句。【是执行已映射的SQL语句】\n1 2 3 4 5 6 7 // 获取SqlSession try (SqlSession session = sqlSessionFactory.openSession()) { // 使用 指定语句的参数和返回值相匹配的接口（比如 BlogMapper.class） BlogMapper mapper = session.getMapper(BlogMapper.class); // 执行已映射的SQL Blog blog = mapper.selectBlog(101); } 2.5 如何映射SQL语句 答：可以使用XML定义或者注解定义\n2.5.1 XML定义 1 2 3 4 5 6 7 8 9 10 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;!---定义命名空间---\u0026gt; \u0026lt;mapper namespace=\u0026#34;org.mybatis.example.BlogMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;selectBlog\u0026#34; resultType=\u0026#34;Blog\u0026#34;\u0026gt; select * from Blog where id = #{id} \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 它在命名空间 “org.mybatis.example.BlogMapper” 中定义了一个名为 “selectBlog” 的映射语句\n该命名就可以直接映射到在命名空间中同名的映射器类，并将已映射的 select 语句匹配到对应名称、参数和返回类型的方法。\n就是建立xml文件与java映射器类 之间的关系。通常命名空间可以指定映射器类的全类型\n1 2 命名空间的作用有两个，一个是利用更长的全限定名来将不同的语句隔离开来，同时也实现了你上面见到的接口绑定。 一个映射器类就是一个sql语句的小单元 2.5.2 注解定义 1 2 3 4 5 6 // 同命名空间 package org.mybatis.example; public interface BlogMapper { @Select(\u0026#34;SELECT * FROM blog WHERE id = #{id}\u0026#34;) Blog selectBlog(int id); } ","date":"2022-12-04T23:51:40+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mybatis/mybatis%E4%BD%BF%E7%94%A8/","title":"Mybatis使用"},{"content":"一、概念 Configuration MyBatis所有的配置信息都保存在Configuration对象之中，配置文件中的大部分配置都会存储到该类中\nSqlSession 作为MyBatis工作的主要顶层API，表示和数据库交互时的会话，完成必要数据库增删改查功能\nExecutor MyBatis执行器，是MyBatis 调度的核心，负责SQL语句的生成和查询缓存的维护\nBaseExecutor:是一个抽象类，这种通过抽象的实现接口的方式是的体现，是Executor 的默认实现\nSimpleExecutor:是 MyBatis 中默认使用的执行器，每执行一次 update 或 select，就开启一个Statement 对象，用完就直接关闭 Statement 对象 ReuseExecutor:可重用执行器，这里的重用指的是重复使用Statement，它会在内部使用一个 Map 把创建的Statement 都缓存起来，每次执行 SQL 命令的时候，都会去判断是否存在基于该 SQL 的 Statement 对象，如果存在Statement 对象并且对应的 connection 还没有关闭的情况下就继续使用之前的 Statement 对象，并将其缓存起来 BatchExecutor:批处理执行器，用于将多个 SQL 一次性输出到数据库 CachingExecutor:缓存执行器，先从缓存中查询结果，如果存在就返回之前的结果；如果不存在，再委托给Executor delegate 去数据库中取，delegate 可以是上面任何一个执行器。\nStatementHandler 封装了JDBC Statement操作，负责对JDBC statement 的操作，如设置参数等\nBaseStatementHandler:本身是一个抽象类，用于简化StatementHandler 接口实现的难度，属于适配器设计模式体现，它主要有三个实现类：\nSimpleStatementHandler:java.sql.Statement对象创建处理器,管理 Statement 对象并向数据库中推送不需要预编译的SQL语句。 PreparedStatementHandler:java.sql.PrepareStatement对象的创建处理器，管理Statement对象并向数据中推送需要预编译的SQL语句。 CallableStatementHandler: java.sql.CallableStatement对象的创建处理器，管理 Statement 对象并调用数据库中的存储过程。 RoutingStatementHandler: 实际上整合了SimpleStatementHandler、PreparedStatementHandler、CallableStatementHandler。\nParameterHandler 负责对用户传递的参数转换成JDBC Statement 所对应的数据类型\nsetParameters: 用于对 PreparedStatement 的参数赋值 ResultSetHandler 负责将JDBC返回的ResultSet结果集对象转换成List类型的集合\nTypeHandler 负责java数据类型和jdbc数据类型(也可以说是数据表列类型)之间的映射和转换\nMappedStatement MappedStatement维护一条\u0026lt;select|update|delete|insert\u0026gt;节点的封装\nSqlSource 负责根据用户传递的parameterObject，动态地生成SQL语句，将信息封装到BoundSql对象中\nBoundSql 表示动态生成的SQL语句以及相应的参数信息\nExecutor对象在创建SqlSession对象的时候创建，并且缓存在Configuration对象里，负责管理一级缓存和二级缓存，并提供是事务管理的相关操作。Executor对象的主要功能是调用StatementHandler访问数据库，并将查询结果存入缓存中（如果配置了缓存的话)。StatementHandler首先通过ParammeterHandler完成SQL的实参绑定，然后通过java.sql.Statement对象执行sql语句并得到结果集ResultSet，最后通过ResultSetHandler完成结果集的映射，得到对象并返回。\nSimpleStatementHandler 和 PreparedStatementHandler 的区别是 SQL 语句是否包含变量。是否通过外部进行参数传入\n二、准备 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * @author peilizhi * @date 2021/10/9 12:52 **/ @Data public class Demo { private Long id; private String name; private Integer age; } /** * @author peilizhi * @date 2021/10/9 12:53 **/ public interface DemoMapper { Demo selectDemoById(Integer id); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 配置文件 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;properties resource=\u0026#34;mysql.properties\u0026#34;/\u0026gt; \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;/\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;${mysql.driverClass}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;${mysql.url}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;${mysql.username}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;${mysql.password}\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;!--resource--\u0026gt; \u0026lt;mapper resource=\u0026#34;mapper/DemoMapper.xml\u0026#34;/\u0026gt; \u0026lt;!--class--\u0026gt; \u0026lt;!-- \u0026lt;mapper class=\u0026#34;com.wsdsg.spring.boot.analyze.mapper.UserMapper\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!--url--\u0026gt; \u0026lt;!--\u0026lt;mapper url=\u0026#34;D:\\coder_soft\\idea_workspace\\ecard_bus\\spring-boot-analyze\\target\\classes\\UserMapper.xml\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!--package--\u0026gt; \u0026lt;!--\u0026lt;package name=\u0026#34;com.wsdsg.spring.boot.analyze.mapper\u0026#34; /\u0026gt;--\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;/configuration\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 /** * @author peilizhi * @date 2021/10/9 12:59 **/ public class DemoTest { public static void main(String[] args) throws IOException { // 不可引用容器中的内容 String resource = \u0026#34;mybatis-config.xml\u0026#34;; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); try (SqlSession session = sqlSessionFactory.openSession()) { /*UserMapper mapper = session.getMapper(UserMapper.class); User user = mapper.selectUserById(1); System.out.println(user);*/ Object o = session.selectOne(\u0026#34;com.huochai.repository.mapper.DemoMapper.selectDemoById\u0026#34;, 1); System.out.println(\u0026#34;我是第一次查询的\u0026#34; + o); System.out.println(\u0026#34;-------------------------------我是分割线---------------------\u0026#34;); Object z = session.selectOne(\u0026#34;com.huochai.repository.mapper.DemoMapper.selectDemoById\u0026#34;, 1); System.out.println(\u0026#34;我是第二次查询的\u0026#34; + z); /*User user = new User(); user.setAge(15); user.setName(\u0026#34;achuan\u0026#34;); int insert = session.insert(\u0026#34;com.wsdsg.spring.boot.analyze.mapper.UserMapper.addOneUser\u0026#34;, user); session.commit(); System.out.println(insert); */ } } } configuration（配置） properties（属性） settings（设置） typeAliases（类型别名） typeHandlers（类型处理器） objectFactory（对象工厂） plugins（插件） environments（环境配置） environment（环境变量） transactionManager（事务管理器） dataSource（数据源） databaseIdProvider（数据库厂商标识） mappers（映射器） 初始化：解析xml文件里面的标签，构建configuration对象。并放在SqlSessionFactory 中\n三、流程 Mybatis 解析xml文件的时候广泛使用构建者模式，因为对象比较复杂\n3.1、读取配置文件 3.2 构建会话工厂对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) { try { XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties); return build(parser.parse()); } catch (Exception e) { throw ExceptionFactory.wrapException(\u0026#34;Error building SqlSession.\u0026#34;, e); } finally { ErrorContext.instance().reset(); try { inputStream.close(); } catch (IOException e) { // Intentionally ignore. Prefer previous error. } } } // 将解析好的Configuration 加入到SqlSessionFactory中 public SqlSessionFactory build(Configuration config) { return new DefaultSqlSessionFactory(config); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public XMLConfigBuilder(InputStream inputStream, String environment, Properties props) { this(new XPathParser(inputStream, true, props, new XMLMapperEntityResolver()), environment, props); } private XMLConfigBuilder(XPathParser parser, String environment, Properties props) { // 创建一个Configuration 对象 super(new Configuration()); // 用于记录解析xml时出错的 ErrorContext.instance().resource(\u0026#34;SQL Mapper Configuration\u0026#34;); this.configuration.setVariables(props); this.parsed = false; this.environment = environment; this.parser = parser; } 在做解析文件的时候，可以创建一个对象用于记录解析过程中出现的问题\n3.2.1 创建XMLConfigBuilder 1 2 XMLConfigBuilder 这个对象的作用就是解析主配置文件用的。 先说明一下，我们可以看出主配置文件的最外层节点是\u0026lt;configuration\u0026gt;标签，mybatis的初始化就是把这个标签以及他的所有子标签进行解析，把解析好的数据封装在Configuration这个类中。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class XMLConfigBuilder extends BaseBuilder { // 是否解析过 private boolean parsed; // 用来解析xml文件的 包括检测xml文件格式 private final XPathParser parser; // 环境ID，不同的环境对应不同的数据源 private String environment; // 反射工场 private final ReflectorFactory localReflectorFactory = new DefaultReflectorFactory(); } public abstract class BaseBuilder { // protected final Configuration configuration; protected final TypeAliasRegistry typeAliasRegistry; protected final TypeHandlerRegistry typeHandlerRegistry; } Mybatis初始化就是读取配置文件，构建Configuration类\nConfiguration 是mybatis 的核心类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // 与mybatis-config.xml配置文件相对应 public class Configuration { // 创建时就进行初始化 protected final TypeAliasRegistry typeAliasRegistry = new TypeAliasRegistry(); public Configuration() { // 事务 typeAliasRegistry.registerAlias(\u0026#34;JDBC\u0026#34;, JdbcTransactionFactory.class); typeAliasRegistry.registerAlias(\u0026#34;MANAGED\u0026#34;, ManagedTransactionFactory.class); // 数据源 typeAliasRegistry.registerAlias(\u0026#34;JNDI\u0026#34;, JndiDataSourceFactory.class); typeAliasRegistry.registerAlias(\u0026#34;POOLED\u0026#34;, PooledDataSourceFactory.class); typeAliasRegistry.registerAlias(\u0026#34;UNPOOLED\u0026#34;, UnpooledDataSourceFactory.class); // 缓存 typeAliasRegistry.registerAlias(\u0026#34;PERPETUAL\u0026#34;, PerpetualCache.class); typeAliasRegistry.registerAlias(\u0026#34;FIFO\u0026#34;, FifoCache.class); typeAliasRegistry.registerAlias(\u0026#34;LRU\u0026#34;, LruCache.class); typeAliasRegistry.registerAlias(\u0026#34;SOFT\u0026#34;, SoftCache.class); typeAliasRegistry.registerAlias(\u0026#34;WEAK\u0026#34;, WeakCache.class); // 供应商的DataBaseId 提供者 typeAliasRegistry.registerAlias(\u0026#34;DB_VENDOR\u0026#34;, VendorDatabaseIdProvider.class); // mybatis 默认的XML 驱动为XMLLanguageDriver,用了解析动态sql typeAliasRegistry.registerAlias(\u0026#34;XML\u0026#34;, XMLLanguageDriver.class); typeAliasRegistry.registerAlias(\u0026#34;RAW\u0026#34;, RawLanguageDriver.class); // 日志类型 typeAliasRegistry.registerAlias(\u0026#34;SLF4J\u0026#34;, Slf4jImpl.class); typeAliasRegistry.registerAlias(\u0026#34;COMMONS_LOGGING\u0026#34;, JakartaCommonsLoggingImpl.class); typeAliasRegistry.registerAlias(\u0026#34;LOG4J\u0026#34;, Log4jImpl.class); typeAliasRegistry.registerAlias(\u0026#34;LOG4J2\u0026#34;, Log4j2Impl.class); typeAliasRegistry.registerAlias(\u0026#34;JDK_LOGGING\u0026#34;, Jdk14LoggingImpl.class); typeAliasRegistry.registerAlias(\u0026#34;STDOUT_LOGGING\u0026#34;, StdOutImpl.class); typeAliasRegistry.registerAlias(\u0026#34;NO_LOGGING\u0026#34;, NoLoggingImpl.class); // 代理工厂 typeAliasRegistry.registerAlias(\u0026#34;CGLIB\u0026#34;, CglibProxyFactory.class); typeAliasRegistry.registerAlias(\u0026#34;JAVASSIST\u0026#34;, JavassistProxyFactory.class); // 设置默认的XML 驱动 languageRegistry.setDefaultDriverClass(XMLLanguageDriver.class); languageRegistry.register(RawLanguageDriver.class); } } TypeAliasRegistry 是一种类型注册器。Registry 后缀的对象可以理解成一个Map 里面存储一些别名\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 public class TypeAliasRegistry { private final Map\u0026lt;String, Class\u0026lt;?\u0026gt;\u0026gt; TYPE_ALIASES = new HashMap\u0026lt;String, Class\u0026lt;?\u0026gt;\u0026gt;(); public TypeAliasRegistry() { registerAlias(\u0026#34;string\u0026#34;, String.class); registerAlias(\u0026#34;byte\u0026#34;, Byte.class); registerAlias(\u0026#34;long\u0026#34;, Long.class); registerAlias(\u0026#34;short\u0026#34;, Short.class); registerAlias(\u0026#34;int\u0026#34;, Integer.class); registerAlias(\u0026#34;integer\u0026#34;, Integer.class); registerAlias(\u0026#34;double\u0026#34;, Double.class); registerAlias(\u0026#34;float\u0026#34;, Float.class); registerAlias(\u0026#34;boolean\u0026#34;, Boolean.class); registerAlias(\u0026#34;byte[]\u0026#34;, Byte[].class); registerAlias(\u0026#34;long[]\u0026#34;, Long[].class); registerAlias(\u0026#34;short[]\u0026#34;, Short[].class); registerAlias(\u0026#34;int[]\u0026#34;, Integer[].class); registerAlias(\u0026#34;integer[]\u0026#34;, Integer[].class); registerAlias(\u0026#34;double[]\u0026#34;, Double[].class); registerAlias(\u0026#34;float[]\u0026#34;, Float[].class); registerAlias(\u0026#34;boolean[]\u0026#34;, Boolean[].class); registerAlias(\u0026#34;_byte\u0026#34;, byte.class); registerAlias(\u0026#34;_long\u0026#34;, long.class); registerAlias(\u0026#34;_short\u0026#34;, short.class); registerAlias(\u0026#34;_int\u0026#34;, int.class); registerAlias(\u0026#34;_integer\u0026#34;, int.class); registerAlias(\u0026#34;_double\u0026#34;, double.class); registerAlias(\u0026#34;_float\u0026#34;, float.class); registerAlias(\u0026#34;_boolean\u0026#34;, boolean.class); registerAlias(\u0026#34;_byte[]\u0026#34;, byte[].class); registerAlias(\u0026#34;_long[]\u0026#34;, long[].class); registerAlias(\u0026#34;_short[]\u0026#34;, short[].class); registerAlias(\u0026#34;_int[]\u0026#34;, int[].class); registerAlias(\u0026#34;_integer[]\u0026#34;, int[].class); registerAlias(\u0026#34;_double[]\u0026#34;, double[].class); registerAlias(\u0026#34;_float[]\u0026#34;, float[].class); registerAlias(\u0026#34;_boolean[]\u0026#34;, boolean[].class); registerAlias(\u0026#34;date\u0026#34;, Date.class); registerAlias(\u0026#34;decimal\u0026#34;, BigDecimal.class); registerAlias(\u0026#34;bigdecimal\u0026#34;, BigDecimal.class); registerAlias(\u0026#34;biginteger\u0026#34;, BigInteger.class); registerAlias(\u0026#34;object\u0026#34;, Object.class); registerAlias(\u0026#34;date[]\u0026#34;, Date[].class); registerAlias(\u0026#34;decimal[]\u0026#34;, BigDecimal[].class); registerAlias(\u0026#34;bigdecimal[]\u0026#34;, BigDecimal[].class); registerAlias(\u0026#34;biginteger[]\u0026#34;, BigInteger[].class); registerAlias(\u0026#34;object[]\u0026#34;, Object[].class); registerAlias(\u0026#34;map\u0026#34;, Map.class); registerAlias(\u0026#34;hashmap\u0026#34;, HashMap.class); registerAlias(\u0026#34;list\u0026#34;, List.class); registerAlias(\u0026#34;arraylist\u0026#34;, ArrayList.class); registerAlias(\u0026#34;collection\u0026#34;, Collection.class); registerAlias(\u0026#34;iterator\u0026#34;, Iterator.class); registerAlias(\u0026#34;ResultSet\u0026#34;, ResultSet.class); } 3.2.2 解析xml 文件 parser.parse():\n1 2 3 4 5 6 7 8 9 10 public Configuration parse() { if (this.parsed) { throw new BuilderException(\u0026#34;Each XMLConfigBuilder can only be used once.\u0026#34;); } else { this.parsed = true; // 利用已经创建好的XPathParser解析xml 文件 this.parseConfiguration(this.parser.evalNode(\u0026#34;/configuration\u0026#34;)); return this.configuration; } } 1 首先判断是否解析过配置文件，如果解析过就抛异常，默认是未解析的 3.2.2.1 判断是否解析过配置文件 解析过就抛出异常\n3.2.2.2 设置已经解析 3,2.2.3 解析configuration标签 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 private void parseConfiguration(XNode root) { try { // 解析properties标签 this.propertiesElement(root.evalNode(\u0026#34;properties\u0026#34;)); // 校验settings 标签中的设置是否都能被mybatis 识别 Properties settings = this.settingsAsProperties(root.evalNode(\u0026#34;settings\u0026#34;)); this.loadCustomVfs(settings); // 解析typeAliases 标签 this.typeAliasesElement(root.evalNode(\u0026#34;typeAliases\u0026#34;)); this.pluginElement(root.evalNode(\u0026#34;plugins\u0026#34;)); this.objectFactoryElement(root.evalNode(\u0026#34;objectFactory\u0026#34;)); this.objectWrapperFactoryElement(root.evalNode(\u0026#34;objectWrapperFactory\u0026#34;)); this.reflectorFactoryElement(root.evalNode(\u0026#34;reflectorFactory\u0026#34;)); this.settingsElement(settings); this.environmentsElement(root.evalNode(\u0026#34;environments\u0026#34;)); this.databaseIdProviderElement(root.evalNode(\u0026#34;databaseIdProvider\u0026#34;)); this.typeHandlerElement(root.evalNode(\u0026#34;typeHandlers\u0026#34;)); this.mapperElement(root.evalNode(\u0026#34;mappers\u0026#34;)); } catch (Exception var3) { throw new BuilderException(\u0026#34;Error parsing SQL Mapper Configuration. Cause: \u0026#34; + var3, var3); } } 就是将xml 文件里面的标签转换成XMLConfigBuilder 中 Configuration 的属性\nproperties 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 properties: 属性,属性可以在外部进行配置，并可以进行动态替换。你既可以在典型的 Java 属性文件中配置这些属性，也可以在 properties 元素的子元素中设置。例如： \u0026lt;properties resource=\u0026#34;org/mybatis/example/config.properties\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;dev_user\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;F2Fa3!33TYyg\u0026#34;/\u0026gt; \u0026lt;/properties\u0026gt; 可以在文件中动态替换参数 \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;${driver}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;${url}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;${username}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;${password}\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; 也可以设置属性 public SqlSessionFactory build(InputStream inputStream, Properties properties) { return build(inputStream, null, properties); } 首先读取在 properties 元素体内指定的属性。 然后根据 properties 元素中的 resource 属性读取类路径下属性文件，或根据 url 属性指定的路径读取属性文件，并覆盖之前读取过的同名属性。 最后读取作为方法参数传递的属性，并覆盖之前读取过的同名属性。 properties 元素中的 resource 属性读取类路径下属性文件，或根据 url 属性指定的路径读取属性文件，并覆盖之前读取过的同名属性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 private void propertiesElement(XNode context) throws Exception { if (context != null) { // \u0026lt;properties\u0026gt; 中配置的属性 Properties defaults = context.getChildrenAsProperties(); // resource 或者url 中的属性 String resource = context.getStringAttribute(\u0026#34;resource\u0026#34;); String url = context.getStringAttribute(\u0026#34;url\u0026#34;); if (resource != null \u0026amp;\u0026amp; url != null) { throw new BuilderException(\u0026#34;The properties element cannot specify both a URL and a resource based property file reference. Please specify one or the other.\u0026#34;); } if (resource != null) { defaults.putAll(Resources.getResourceAsProperties(resource)); } else if (url != null) { defaults.putAll(Resources.getUrlAsProperties(url)); } // 构造方法传入的参数 Properties vars = configuration.getVariables(); if (vars != null) { defaults.putAll(vars); } parser.setVariables(defaults); // 设置Configuration 对象的Properties 属性 configuration.setVariables(defaults); } } 通过方法参数传递的属性具有最高优先级，resource/url 属性中指定的配置文件次之，最低优先级的则是 properties 元素中指定的属性。\ntypeAliases 1 2 3 4 5 6 7 8 9 10 11 12 13 typeAliases:类型别名 ,类型别名可为 Java 类型设置一个缩写名字。 它仅用于 XML 配置，意在降低冗余的全限定类名书写 \u0026lt;typeAliases\u0026gt; \u0026lt;typeAlias alias=\u0026#34;Author\u0026#34; type=\u0026#34;domain.blog.Author\u0026#34;/\u0026gt; \u0026lt;typeAlias alias=\u0026#34;Blog\u0026#34; type=\u0026#34;domain.blog.Blog\u0026#34;/\u0026gt; \u0026lt;typeAlias alias=\u0026#34;Comment\u0026#34; type=\u0026#34;domain.blog.Comment\u0026#34;/\u0026gt; \u0026lt;typeAlias alias=\u0026#34;Post\u0026#34; type=\u0026#34;domain.blog.Post\u0026#34;/\u0026gt; \u0026lt;typeAlias alias=\u0026#34;Section\u0026#34; type=\u0026#34;domain.blog.Section\u0026#34;/\u0026gt; \u0026lt;typeAlias alias=\u0026#34;Tag\u0026#34; type=\u0026#34;domain.blog.Tag\u0026#34;/\u0026gt; 每一个在包 中的 Java Bean，在没有注解的情况下，会使用 Bean 的首字母小写的非限定类名来作为它的别名 \u0026lt;package name=\u0026#34;domain.blog\u0026#34;/\u0026gt; \u0026lt;/typeAliases\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 private void typeAliasesElement(XNode parent) { if (parent != null) { for (XNode child : parent.getChildren()) { // 为包中对象设置别名 if (\u0026#34;package\u0026#34;.equals(child.getName())) { String typeAliasPackage = child.getStringAttribute(\u0026#34;name\u0026#34;); configuration.getTypeAliasRegistry().registerAliases(typeAliasPackage); } else { String alias = child.getStringAttribute(\u0026#34;alias\u0026#34;); String type = child.getStringAttribute(\u0026#34;type\u0026#34;); try { Class\u0026lt;?\u0026gt; clazz = Resources.classForName(type); if (alias == null) { // 自动获取类的简要名称 typeAliasRegistry.registerAlias(clazz); } else { typeAliasRegistry.registerAlias(alias, clazz); } } catch (ClassNotFoundException e) { throw new BuilderException(\u0026#34;Error registering typeAlias for \u0026#39;\u0026#34; + alias + \u0026#34;\u0026#39;. Cause: \u0026#34; + e, e); } } } } } plugins 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 plugins: MyBatis 允许你在映射语句执行过程中的某一点进行拦截调用。默认情况下，MyBatis 允许使用插件来拦截的方法调用包括： Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) ParameterHandler (getParameterObject, setParameters) ResultSetHandler (handleResultSets, handleOutputParameters) StatementHandler (prepare, parameterize, batch, update, query) /** * @author peilizhi * @date 2021/11/30 00:36 **/ @Intercepts({ @Signature(type = Executor.class, method = \u0026#34;query\u0026#34;, args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class}), @Signature(type = Executor.class, method = \u0026#34;query\u0026#34;, args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class, CacheKey.class, BoundSql.class}),} ) public class MyInterceptor implements Interceptor { /** * 拦截时要执行的方法 */ @Override public Object intercept(Invocation invocation) throws Throwable { System.out.println(\u0026#34;被拦截方法执行之前，做的辅助服务······\u0026#34;); Object proceed = invocation.proceed(); System.out.println(\u0026#34;被拦截方法执行之后，做的辅助服务······\u0026#34;); return proceed; } /** * 用于封装目标对象，可以返回本身，也可以返回其代理 * * @param target 目标对象 * 表示被拦截的对象，此处为 Executor 的实例对象 * 作用：如果被拦截对象所在的类有实现接口，就为当前拦截对象生成一个代理对象 * 如果被拦截对象所在的类没有指定接口，这个对象之后的行为就不会被代理操作 */ @Override public Object plugin(Object target) { return Plugin.wrap(target, this); } /** * 用于在 Mybatis 配置文件中指定一些属性的。 */ @Override public void setProperties(Properties properties) { } } \u0026lt;!-- mybatis-config.xml --\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin interceptor=\u0026#34;org.mybatis.example.ExamplePlugin\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;someProperty\u0026#34; value=\u0026#34;100\u0026#34;/\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; MyBatis 允许你在映射语句执行过程中的某一点进行拦截调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 plugins: MyBatis 允许你在映射语句执行过程中的某一点进行拦截调用。默认情况下，MyBatis 允许使用插件来拦截的方法调用包括： Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) ParameterHandler (getParameterObject, setParameters) ResultSetHandler (handleResultSets, handleOutputParameters) StatementHandler (prepare, parameterize, batch, update, query) /** * @author peilizhi * @date 2021/11/30 00:36 **/ @Intercepts({ @Signature(type = Executor.class, method = \u0026#34;query\u0026#34;, args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class}), @Signature(type = Executor.class, method = \u0026#34;query\u0026#34;, args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class, CacheKey.class, BoundSql.class}),} ) public class MyInterceptor implements Interceptor { /** * 拦截时要执行的方法 */ @Override public Object intercept(Invocation invocation) throws Throwable { System.out.println(\u0026#34;被拦截方法执行之前，做的辅助服务······\u0026#34;); Object proceed = invocation.proceed(); System.out.println(\u0026#34;被拦截方法执行之后，做的辅助服务······\u0026#34;); return proceed; } /** * 用于封装目标对象，可以返回本身，也可以返回其代理 * * @param target 目标对象 * 表示被拦截的对象，此处为 Executor 的实例对象 * 作用：如果被拦截对象所在的类有实现接口，就为当前拦截对象生成一个代理对象 * 如果被拦截对象所在的类没有指定接口，这个对象之后的行为就不会被代理操作 */ @Override public Object plugin(Object target) { return Plugin.wrap(target, this); } /** * 用于在 Mybatis 配置文件中指定一些属性的。 */ @Override public void setProperties(Properties properties) { } } \u0026lt;!-- mybatis-config.xml --\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin interceptor=\u0026#34;org.mybatis.example.ExamplePlugin\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;someProperty\u0026#34; value=\u0026#34;100\u0026#34;/\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; 这可能会极大影响 MyBatis 的行为，务请慎之又慎。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 private void pluginElement(XNode parent) throws Exception { if (parent != null) { for (XNode child : parent.getChildren()) { // 获取拦截器类名 String interceptor = child.getStringAttribute(\u0026#34;interceptor\u0026#34;); // 获取拦截器下的属性 Properties properties = child.getChildrenAsProperties(); // 从类别名注册器中获取，如果没有获取到就创建Class 对象，之后生成实例 Interceptor interceptorInstance = (Interceptor) resolveClass(interceptor).newInstance(); interceptorInstance.setProperties(properties); configuration.addInterceptor(interceptorInstance); } } } objectFactory 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 每次 MyBatis 创建结果对象的新实例时，它都会使用一个对象工厂（ObjectFactory）实例来完成实例化工作。 默认的对象工厂需要做的仅仅是实例化目标类，要么通过默认无参构造方法，要么通过存在的参数映射来调用带有参数的构造方法。 如果想覆盖对象工厂的默认行为，可以通过创建自己的对象工厂来实现。 public class ExampleObjectFactory extends DefaultObjectFactory { /** * 覆盖默认对象工厂实例化对象的操作 * @param type * @param \u0026lt;T\u0026gt; * @return */ @Override public \u0026lt;T\u0026gt; T create(Class\u0026lt;T\u0026gt; type) { System.out.println(\u0026#34;在创建对象时执行了我\u0026#34;); return create(type, null, null); } @Override public void setProperties(Properties properties) { // no props for default } } \u0026lt;objectFactory type=\u0026#34;org.mybatis.example.ExampleObjectFactory\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;someProperty\u0026#34; value=\u0026#34;100\u0026#34;/\u0026gt; \u0026lt;/objectFactory\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 private void objectFactoryElement(XNode context) throws Exception { if (context != null) { // 读取接口中type指定的对象工厂 String type = context.getStringAttribute(\u0026#34;type\u0026#34;); // 获取对象工厂设置的参数 Properties properties = context.getChildrenAsProperties(); // 实力化工厂对象 ObjectFactory factory = (ObjectFactory) resolveClass(type).newInstance(); factory.setProperties(properties); // 保存 configuration.setObjectFactory(factory); } } objectWrapperFactory 1 2 3 4 5 6 7 8 9 // 读取配置中的定义并且注册到Configuration中 // objectWrapperFactory 用于感知创建对象 private void objectWrapperFactoryElement(XNode context) throws Exception { if (context != null) { String type = context.getStringAttribute(\u0026#34;type\u0026#34;); ObjectWrapperFactory factory = (ObjectWrapperFactory) resolveClass(type).newInstance(); configuration.setObjectWrapperFactory(factory); } } 1 2 3 4 5 6 7 8 // 读取配置中的定义并且注册到Configuration中 private void reflectorFactoryElement(XNode context) throws Exception { if (context != null) { String type = context.getStringAttribute(\u0026#34;type\u0026#34;); ReflectorFactory factory = (ReflectorFactory) resolveClass(type).newInstance(); configuration.setReflectorFactory(factory); } } reflectorFactory 1 2 3 4 5 6 7 private void reflectorFactoryElement(XNode context) throws Exception { if (context != null) { String type = context.getStringAttribute(\u0026#34;type\u0026#34;); ReflectorFactory factory = (ReflectorFactory) resolveClass(type).newInstance(); configuration.setReflectorFactory(factory); } } settings settings:它们会改变 MyBatis 的运行时行为\n设置名 描述 有效值 默认值 cacheEnabled 全局性地开启或关闭所有映射器配置文件中已配置的任何缓存。 true | false true 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 校验\u0026lt;Settings\u0026gt;标签中的属性是否都能被识别 private Properties settingsAsProperties(XNode context) { if (context == null) { return new Properties(); } Properties props = context.getChildrenAsProperties(); // Check that all settings are known to the configuration class MetaClass metaConfig = MetaClass.forClass(Configuration.class, localReflectorFactory); for (Object key : props.keySet()) { if (!metaConfig.hasSetter(String.valueOf(key))) { throw new BuilderException(\u0026#34;The setting \u0026#34; + key + \u0026#34; is not known. Make sure you spelled it correctly (case sensitive).\u0026#34;); } } return props; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 private void settingsElement(Properties props) throws Exception { // 设置配置 configuration.setAutoMappingBehavior(AutoMappingBehavior.valueOf(props.getProperty(\u0026#34;autoMappingBehavior\u0026#34;, \u0026#34;PARTIAL\u0026#34;))); configuration.setAutoMappingUnknownColumnBehavior(AutoMappingUnknownColumnBehavior.valueOf(props.getProperty(\u0026#34;autoMappingUnknownColumnBehavior\u0026#34;, \u0026#34;NONE\u0026#34;))); configuration.setCacheEnabled(booleanValueOf(props.getProperty(\u0026#34;cacheEnabled\u0026#34;), true)); configuration.setProxyFactory((ProxyFactory) createInstance(props.getProperty(\u0026#34;proxyFactory\u0026#34;))); configuration.setLazyLoadingEnabled(booleanValueOf(props.getProperty(\u0026#34;lazyLoadingEnabled\u0026#34;), false)); configuration.setAggressiveLazyLoading(booleanValueOf(props.getProperty(\u0026#34;aggressiveLazyLoading\u0026#34;), false)); configuration.setMultipleResultSetsEnabled(booleanValueOf(props.getProperty(\u0026#34;multipleResultSetsEnabled\u0026#34;), true)); configuration.setUseColumnLabel(booleanValueOf(props.getProperty(\u0026#34;useColumnLabel\u0026#34;), true)); configuration.setUseGeneratedKeys(booleanValueOf(props.getProperty(\u0026#34;useGeneratedKeys\u0026#34;), false)); configuration.setDefaultExecutorType(ExecutorType.valueOf(props.getProperty(\u0026#34;defaultExecutorType\u0026#34;, \u0026#34;SIMPLE\u0026#34;))); configuration.setDefaultStatementTimeout(integerValueOf(props.getProperty(\u0026#34;defaultStatementTimeout\u0026#34;), null)); configuration.setDefaultFetchSize(integerValueOf(props.getProperty(\u0026#34;defaultFetchSize\u0026#34;), null)); configuration.setMapUnderscoreToCamelCase(booleanValueOf(props.getProperty(\u0026#34;mapUnderscoreToCamelCase\u0026#34;), false)); configuration.setSafeRowBoundsEnabled(booleanValueOf(props.getProperty(\u0026#34;safeRowBoundsEnabled\u0026#34;), false)); configuration.setLocalCacheScope(LocalCacheScope.valueOf(props.getProperty(\u0026#34;localCacheScope\u0026#34;, \u0026#34;SESSION\u0026#34;))); configuration.setJdbcTypeForNull(JdbcType.valueOf(props.getProperty(\u0026#34;jdbcTypeForNull\u0026#34;, \u0026#34;OTHER\u0026#34;))); configuration.setLazyLoadTriggerMethods(stringSetValueOf(props.getProperty(\u0026#34;lazyLoadTriggerMethods\u0026#34;), \u0026#34;equals,clone,hashCode,toString\u0026#34;)); configuration.setSafeResultHandlerEnabled(booleanValueOf(props.getProperty(\u0026#34;safeResultHandlerEnabled\u0026#34;), true)); configuration.setDefaultScriptingLanguage(resolveClass(props.getProperty(\u0026#34;defaultScriptingLanguage\u0026#34;))); @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Class\u0026lt;? extends TypeHandler\u0026gt; typeHandler = (Class\u0026lt;? extends TypeHandler\u0026gt;)resolveClass(props.getProperty(\u0026#34;defaultEnumTypeHandler\u0026#34;)); configuration.setDefaultEnumTypeHandler(typeHandler); configuration.setCallSettersOnNulls(booleanValueOf(props.getProperty(\u0026#34;callSettersOnNulls\u0026#34;), false)); configuration.setUseActualParamName(booleanValueOf(props.getProperty(\u0026#34;useActualParamName\u0026#34;), true)); configuration.setReturnInstanceForEmptyRow(booleanValueOf(props.getProperty(\u0026#34;returnInstanceForEmptyRow\u0026#34;), false)); configuration.setLogPrefix(props.getProperty(\u0026#34;logPrefix\u0026#34;)); @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Class\u0026lt;? extends Log\u0026gt; logImpl = (Class\u0026lt;? extends Log\u0026gt;)resolveClass(props.getProperty(\u0026#34;logImpl\u0026#34;)); configuration.setLogImpl(logImpl); configuration.setConfigurationFactory(resolveClass(props.getProperty(\u0026#34;configurationFactory\u0026#34;))); } environments 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 environments:环境配置 尽管可以配置多个环境，但每个 SqlSessionFactory 实例只能选择一种环境。 每个数据库对应一个 SqlSessionFactory 实例 \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;...\u0026#34; value=\u0026#34;...\u0026#34;/\u0026gt; \u0026lt;/transactionManager\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;${driver}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;${url}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;${username}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;${password}\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; MyBatis 中有两种类型的事务管理器（也就是 type=\u0026#34;[JDBC|MANAGED]\u0026#34;）： JDBC – 这个配置直接使用了 JDBC 的提交和回滚设施，它依赖从数据源获得的连接来管理事务作用域。 MANAGED – 这个配置几乎没做什么。它从不提交或回滚一个连接，而是让容器来管理事务的整个生命周期（比如 JEE 应用服务器的上下文）。 默认情况下它会关闭连接。然而一些容器并不希望连接被关闭，因此需要将 closeConnection 属性设置为 false 来阻止默认的关闭行为 如果你正在使用 Spring + MyBatis，则没有必要配置事务管理器，因为 Spring 模块会使用自带的管理器来覆盖前面的配置。 dataSource 元素使用标准的 JDBC 数据源接口来配置 JDBC 连接对象的资源。 有三种内建的数据源类型（也就是 type=\u0026#34;[UNPOOLED|POOLED|JNDI]\u0026#34;）： UNPOOLED– 这个数据源的实现会每次请求时打开和关闭连接 driver – 这是 JDBC 驱动的 Java 类全限定名（并不是 JDBC 驱动中可能包含的数据源类）。 url – 这是数据库的 JDBC URL 地址。 username – 登录数据库的用户名。 password – 登录数据库的密码。 defaultTransactionIsolationLevel – 默认的连接事务隔离级别。 defaultNetworkTimeout – 等待数据库操作完成的默认网络超时时间（单位：毫秒） POOLED– 这种数据源的实现利用“池”的概念将 JDBC 连接对象组织起来，避免了创建新的连接实例时所必需的初始化和认证时间。 这种处理方式很流行，能使并发 Web 应用快速响应请求。还有更多属性用来配置 POOLED 的数据源： poolMaximumActiveConnections – 在任意时间可存在的活动（正在使用）连接数量，默认值：10 poolMaximumIdleConnections – 任意时间可能存在的空闲连接数。 poolMaximumCheckoutTime – 在被强制返回之前，池中连接被检出（checked out）时间，默认值：20000 毫秒（即 20 秒） poolTimeToWait – 这是一个底层设置，如果获取连接花费了相当长的时间，连接池会打印状态日志并重新尝试获取一个连接（避免在误配置的情况下一直失败且不打印日志），默认值：20000 毫秒（即 20 秒）。 poolMaximumLocalBadConnectionTolerance – 这是一个关于坏连接容忍度的底层设置， 作用于每一个尝试从缓存池获取连接的线程。 如果这个线程获取到的是一个坏的连接，那么这个数据源允许这个线程尝试重新获取一个新的连接，但是这个重新尝试的次数不应该超过 poolMaximumIdleConnections 与 poolMaximumLocalBadConnectionTolerance 之和。 默认值：3（新增于 3.4.5） poolPingQuery – 发送到数据库的侦测查询，用来检验连接是否正常工作并准备接受请求。默认是“NO PING QUERY SET”，这会导致多数数据库驱动出错时返回恰当的错误消息。 poolPingEnabled – 是否启用侦测查询。若开启，需要设置 poolPingQuery 属性为一个可执行的 SQL 语句（最好是一个速度非常快的 SQL 语句），默认值：false。 poolPingConnectionsNotUsedFor – 配置 poolPingQuery 的频率。可以被设置为和数据库连接超时时间一样，来避免不必要的侦测，默认值：0（即所有连接每一时刻都被侦测 — 当然仅当 poolPingEnabled 为 true 时适用）。 JNDI – 这个数据源实现是为了能在如 EJB 或应用服务器这类容器中使用，容器可以集中或在外部配置数据源，然后放置一个 JNDI 上下文的数据源引用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 private void environmentsElement(XNode context) throws Exception { if (context != null) { // 如果在构建XMLConfigBuilder时没有指定选择的环境，就从xml中获取默认的环境 if (environment == null) { environment = context.getStringAttribute(\u0026#34;default\u0026#34;); } // 解析多个环境 for (XNode child : context.getChildren()) { String id = child.getStringAttribute(\u0026#34;id\u0026#34;); // 当前环境是否为xml中指定的环境，不是就不解析 if (isSpecifiedEnvironment(id)) { TransactionFactory txFactory = transactionManagerElement(child.evalNode(\u0026#34;transactionManager\u0026#34;)); DataSourceFactory dsFactory = dataSourceElement(child.evalNode(\u0026#34;dataSource\u0026#34;)); DataSource dataSource = dsFactory.getDataSource(); // 组装事物、数据源 Environment.Builder environmentBuilder = new Environment.Builder(id) .transactionFactory(txFactory) .dataSource(dataSource); configuration.setEnvironment(environmentBuilder.build()); } } } } // 将获取事务工厂 private TransactionFactory transactionManagerElement(XNode context) throws Exception { if (context != null) { String type = context.getStringAttribute(\u0026#34;type\u0026#34;); Properties props = context.getChildrenAsProperties(); TransactionFactory factory = (TransactionFactory) resolveClass(type).newInstance(); factory.setProperties(props); return factory; } throw new BuilderException(\u0026#34;Environment declaration requires a TransactionFactory.\u0026#34;); } // 获取数据源 private DataSourceFactory dataSourceElement(XNode context) throws Exception { if (context != null) { String type = context.getStringAttribute(\u0026#34;type\u0026#34;); Properties props = context.getChildrenAsProperties(); DataSourceFactory factory = (DataSourceFactory) resolveClass(type).newInstance(); factory.setProperties(props); return factory; } throw new BuilderException(\u0026#34;Environment declaration requires a DataSourceFactory.\u0026#34;); } databaseIdProvider 1 2 3 4 databaseIdProvider:数据库厂商标识 MyBatis 可以根据不同的数据库厂商执行不同的语句，这种多厂商的支持是基于映射语句中的 databaseId 属性。 MyBatis 会加载带有匹配当前数据库 databaseId 属性和所有不带 databaseId 属性的语句。 如果同时找到带有 databaseId 和不带 databaseId 的相同语句，则后者会被舍弃。 支持多厂商数据库 \u0026lt;databaseIdProvider type=\u0026#34;DB_VENDOR\u0026#34; /\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 private void databaseIdProviderElement(XNode context) throws Exception { DatabaseIdProvider databaseIdProvider = null; if (context != null) { String type = context.getStringAttribute(\u0026#34;type\u0026#34;); // awful patch to keep backward compatibility if (\u0026#34;VENDOR\u0026#34;.equals(type)) { type = \u0026#34;DB_VENDOR\u0026#34;; } Properties properties = context.getChildrenAsProperties(); databaseIdProvider = (DatabaseIdProvider) resolveClass(type).newInstance(); databaseIdProvider.setProperties(properties); } Environment environment = configuration.getEnvironment(); if (environment != null \u0026amp;\u0026amp; databaseIdProvider != null) { String databaseId = databaseIdProvider.getDatabaseId(environment.getDataSource()); configuration.setDatabaseId(databaseId); } } typeHandlers 1 typeHandlers:类型处理器,MyBatis 在设置预处理语句（PreparedStatement）中的参数或从结果集中取出一个值时， 都会用类型处理器将获取到的值以合适的方式转换成 Java 类型。 类型处理器 Java 类型 JDBC 类型 BooleanTypeHandler java.lang.Boolean, boolean 数据库兼容的 BOOLEAN ByteTypeHandler java.lang.Byte, byte 数据库兼容的 NUMERIC 或 BYTE ShortTypeHandler java.lang.Short, short 数据库兼容的 NUMERIC 或 SMALLINT IntegerTypeHandler java.lang.Integer, int 数据库兼容的 NUMERIC 或 INTEGER LongTypeHandler java.lang.Long, long 数据库兼容的 NUMERIC 或 BIGINT FloatTypeHandler java.lang.Float, float 数据库兼容的 NUMERIC 或 FLOAT DoubleTypeHandler java.lang.Double, double 数据库兼容的 NUMERIC 或 DOUBLE BigDecimalTypeHandler java.math.BigDecimal 数据库兼容的 NUMERIC 或 DECIMAL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 重写已有的类型处理器或创建你自己的类型处理器来处理不支持的或非标准的类型.实现 org.apache.ibatis.type.TypeHandler 接口， 或继承一个很便利的类 org.apache.ibatis.type.BaseTypeHandler， 并且可以（可选地）将它映射到一个 JDBC 类型 /*** * 将 JdbcType 转化成String 类型 **/ @MappedJdbcTypes(JdbcType.VARCHAR) public class ExampleTypeHandler extends BaseTypeHandler\u0026lt;String\u0026gt; { @Override public void setNonNullParameter(PreparedStatement ps, int i, String parameter, JdbcType jdbcType) throws SQLException { ps.setString(i, parameter); } @Override public String getNullableResult(ResultSet rs, String columnName) throws SQLException { return rs.getString(columnName); } @Override public String getNullableResult(ResultSet rs, int columnIndex) throws SQLException { return rs.getString(columnIndex); } @Override public String getNullableResult(CallableStatement cs, int columnIndex) throws SQLException { return cs.getString(columnIndex); } } 通过类型处理器的泛型，MyBatis 可以得知该类型处理器处理的 Java 类型，不过这种行为可以通过两种方法改变： 在类型处理器的配置元素（typeHandler 元素）上增加一个 javaType 属性（比如：javaType=\u0026#34;String\u0026#34;）； 在类型处理器的类上增加一个 @MappedTypes 注解指定与其关联的 Java 类型列表。 如果在 javaType 属性中也同时指定，则注解上的配置将被忽略。 可以通过两种方式来指定关联的 JDBC 类型： 在类型处理器的配置元素上增加一个 jdbcType 属性（比如：jdbcType=\u0026#34;VARCHAR\u0026#34;）； 在类型处理器的类上增加一个 @MappedJdbcTypes 注解指定与其关联的 JDBC 类型列表。 如果在 jdbcType 属性中也同时指定，则注解上的配置将被忽略。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // 获取javaType、jdbcType、handler对应的对象 // 无论是哪一种组合都有重载的方法使类型处理器 注册到typeHandlerRegistry 中 private void typeHandlerElement(XNode parent) throws Exception { if (parent != null) { for (XNode child : parent.getChildren()) { // 如果指定类型处理器所在的包 if (\u0026#34;package\u0026#34;.equals(child.getName())) { String typeHandlerPackage = child.getStringAttribute(\u0026#34;name\u0026#34;); typeHandlerRegistry.register(typeHandlerPackage); } else { String javaTypeName = child.getStringAttribute(\u0026#34;javaType\u0026#34;); String jdbcTypeName = child.getStringAttribute(\u0026#34;jdbcType\u0026#34;); String handlerTypeName = child.getStringAttribute(\u0026#34;handler\u0026#34;); Class\u0026lt;?\u0026gt; javaTypeClass = resolveClass(javaTypeName); JdbcType jdbcType = resolveJdbcType(jdbcTypeName); Class\u0026lt;?\u0026gt; typeHandlerClass = resolveClass(handlerTypeName); if (javaTypeClass != null) { if (jdbcType == null) { typeHandlerRegistry.register(javaTypeClass, typeHandlerClass); } else { typeHandlerRegistry.register(javaTypeClass, jdbcType, typeHandlerClass); } } else { typeHandlerRegistry.register(typeHandlerClass); } } } } } // 注册包中的类型处理器 public void register(String packageName) { ResolverUtil\u0026lt;Class\u0026lt;?\u0026gt;\u0026gt; resolverUtil = new ResolverUtil\u0026lt;Class\u0026lt;?\u0026gt;\u0026gt;(); resolverUtil.find(new ResolverUtil.IsA(TypeHandler.class), packageName); Set\u0026lt;Class\u0026lt;? extends Class\u0026lt;?\u0026gt;\u0026gt;\u0026gt; handlerSet = resolverUtil.getClasses(); for (Class\u0026lt;?\u0026gt; type : handlerSet) { //Ignore inner classes and interfaces (including package-info.java) and abstract classes if (!type.isAnonymousClass() \u0026amp;\u0026amp; !type.isInterface() \u0026amp;\u0026amp; !Modifier.isAbstract(type.getModifiers())) { register(type); } } } mappers 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 mappers:映射器 \u0026lt;!-- 使用相对于类路径的资源引用 --\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper resource=\u0026#34;org/mybatis/builder/AuthorMapper.xml\u0026#34;/\u0026gt; \u0026lt;mapper resource=\u0026#34;org/mybatis/builder/BlogMapper.xml\u0026#34;/\u0026gt; \u0026lt;mapper resource=\u0026#34;org/mybatis/builder/PostMapper.xml\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;!-- 使用完全限定资源定位符（URL） --\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper url=\u0026#34;file:///var/mappers/AuthorMapper.xml\u0026#34;/\u0026gt; \u0026lt;mapper url=\u0026#34;file:///var/mappers/BlogMapper.xml\u0026#34;/\u0026gt; \u0026lt;mapper url=\u0026#34;file:///var/mappers/PostMapper.xml\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;!-- 使用映射器接口实现类的完全限定类名 --\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper class=\u0026#34;org.mybatis.builder.AuthorMapper\u0026#34;/\u0026gt; \u0026lt;mapper class=\u0026#34;org.mybatis.builder.BlogMapper\u0026#34;/\u0026gt; \u0026lt;mapper class=\u0026#34;org.mybatis.builder.PostMapper\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;!-- 将包内的映射器接口实现全部注册为映射器 --\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;package name=\u0026#34;org.mybatis.builder\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; Cache 标签 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 默认情况下，只启用了本地的会话缓存，它仅仅对一个会话中的数据进行缓存。 要启用全局的二级缓存，只需要在你的 SQL 映射文件中添加一行： 映射语句文件中的所有 select 语句的结果将会被缓存。 映射语句文件中的所有 insert、update 和 delete 语句会刷新缓存。 缓存会使用最近最少使用算法（LRU, Least Recently Used）算法来清除不需要的缓存。 缓存不会定时进行刷新（也就是说，没有刷新间隔）。 缓存会保存列表或对象（无论查询方法返回哪种）的 1024 个引用。 缓存会被视为读/写缓存，这意味着获取到的对象并不是共享的，可以安全地被调用者修改，而不干扰其他调用者或线程所做的潜在修改。 只要影响本名称空间内的sql 语句 \u0026lt;cache eviction=\u0026#34;FIFO\u0026#34; 设置的值应该是一个以毫秒为单位的合理时间量 flushInterval=\u0026#34;60000\u0026#34; size=\u0026#34;512\u0026#34; readOnly（只读）属性可以被设置为 true 或 false。只读的缓存会给所有调用者返回缓存对象的相同实例。 因此这些对象不能被修改。这就提供了可观的性能提升。而可读写的缓存会（通过序列化）返回缓存对象的拷贝。 速度上会慢一些，但是更安全，因此默认值是 false。 readOnly=\u0026#34;true\u0026#34;/\u0026gt; 这个更高级的配置创建了一个 FIFO 缓存，每隔 60 秒刷新，最多可以存储结果对象或列表的 512 个引用，而且返回的对象被认为是只读的， 可用的清除策略有： LRU – 最近最少使用：移除最长时间不被使用的对象。 FIFO – 先进先出：按对象进入缓存的顺序来移除它们。 SOFT – 软引用：基于垃圾回收器状态和软引用规则移除对象。 WEAK – 弱引用：更积极地基于垃圾收集器状态和弱引用规则移除对象。 默认的清除策略是 LRU。 1 2 3 4 \u0026lt;select ... flushCache=\u0026#34;false\u0026#34; useCache=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;insert ... flushCache=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;update ... flushCache=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;delete ... flushCache=\u0026#34;true\u0026#34;/\u0026gt; cache-ref 1 2 3 对某一命名空间的语句，只会使用该命名空间的缓存进行缓存或刷新。 但你可能会想要在多个命名空间中共享相同的缓存配置和实例。要实现这种需求，你可以使用 cache-ref 元素来引用另一个缓存。 \u0026lt;cache-ref namespace=\u0026#34;com.someone.application.data.SomeMapper\u0026#34;/\u0026gt; this.mapperElement(root.evalNode(\u0026ldquo;mappers\u0026rdquo;)); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 private void mapperElement(XNode parent) throws Exception { if (parent != null) { // 遍历xml中添加的mapper 标签 for (XNode child : parent.getChildren()) { if (\u0026#34;package\u0026#34;.equals(child.getName())) { String mapperPackage = child.getStringAttribute(\u0026#34;name\u0026#34;); configuration.addMappers(mapperPackage); } else { String resource = child.getStringAttribute(\u0026#34;resource\u0026#34;); String url = child.getStringAttribute(\u0026#34;url\u0026#34;); String mapperClass = child.getStringAttribute(\u0026#34;class\u0026#34;); if (resource != null \u0026amp;\u0026amp; url == null \u0026amp;\u0026amp; mapperClass == null) { ErrorContext.instance().resource(resource); try(InputStream inputStream = Resources.getResourceAsStream(resource)) { XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments()); mapperParser.parse(); } } else if (resource == null \u0026amp;\u0026amp; url != null \u0026amp;\u0026amp; mapperClass == null) { ErrorContext.instance().resource(url); try(InputStream inputStream = Resources.getUrlAsStream(url)){ XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, url, configuration.getSqlFragments()); mapperParser.parse(); } } else if (resource == null \u0026amp;\u0026amp; url == null \u0026amp;\u0026amp; mapperClass != null) { Class\u0026lt;?\u0026gt; mapperInterface = Resources.classForName(mapperClass); configuration.addMapper(mapperInterface); } else { throw new BuilderException(\u0026#34;A mapper element may only specify a url, resource or class, but not more than one.\u0026#34;); } } } } } 1 2 3 通过循环来遍历xml 中的多个mapper 标签 如果含有package 标签，表示将包内所有映射器接口注册为映射器 根据不同的引入mapper方式来解析。如果是resource 、url 标签，流程大致相同 1 2 3 4 5 6 7 8 9 10 // 指定配置文件 if (resource != null \u0026amp;\u0026amp; url == null \u0026amp;\u0026amp; mapperClass == null) { ErrorContext.instance().resource(resource); // 获取配置文件对应的字节流 try(InputStream inputStream = Resources.getResourceAsStream(resource)) { //通过XMLMapperBuilder解析XXXMapper.xml，可以看到这里构建的XMLMapperBuilde还传入了configuration,所以之后肯定是会将mapper封装到configuration对象中去的。 XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments()); mapperParser.parse(); } } 1 2 3 4 实例化一个错误上下文对象,这个对象的作用就是把错误信息封装起来，如果出现错误就会调用这个对象的toString方法,里面详细描述了错误的位置 这个resource参数就是String类型的xml的名字 创建一个XMLMapperBuilder ，用于解析xml 形式的mapper mapperParser.parse(); 1 2 3 4 5 6 7 8 9 10 11 12 13 class XMLMapperBuilder public void parse() { if (!configuration.isResourceLoaded(resource)) { configurationElement(parser.evalNode(\u0026#34;/mapper\u0026#34;)); configuration.addLoadedResource(resource); bindMapperForNamespace(); } // 重新解析之前解析不了的节点 ，因为文件配置的顺序的问题导致有的标签解析不到，前面的标签依赖后面的标签 parsePendingResultMaps(); parsePendingCacheRefs(); parsePendingStatements(); } 1 一开始就一个判断这个xml是否被解析过了，configuration对象会维护一个Set\u0026lt;String\u0026gt; loadedResources，这个集合中存放了所有已经被解析过的xml的名字 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 private void configurationElement(XNode context) { try { // 获取命名空间 String namespace = context.getStringAttribute(\u0026#34;namespace\u0026#34;); if (namespace == null || namespace.isEmpty()) { throw new BuilderException(\u0026#34;Mapper\u0026#39;s namespace cannot be empty\u0026#34;); } builderAssistant.setCurrentNamespace(namespace); // \u0026lt;cache-ref\u0026gt;：cache只对特定的Namespace使用，即每个namespace使用一个cache实例，如果要多个namespace使用同一个cache实例，则可以使用cache-ref来引用 cacheRefElement(context.evalNode(\u0026#34;cache-ref\u0026#34;)); // \u0026lt;cache\u0026gt;：当前Mapper的缓存配置，二级缓存 cacheElement(context.evalNode(\u0026#34;cache\u0026#34;)); parameterMapElement(context.evalNodes(\u0026#34;/mapper/parameterMap\u0026#34;)); resultMapElements(context.evalNodes(\u0026#34;/mapper/resultMap\u0026#34;)); sqlElement(context.evalNodes(\u0026#34;/mapper/sql\u0026#34;)); buildStatementFromContext(context.evalNodes(\u0026#34;select|insert|update|delete\u0026#34;)); } catch (Exception e) { throw new BuilderException(\u0026#34;Error parsing Mapper XML. The XML location is \u0026#39;\u0026#34; + resource + \u0026#34;\u0026#39;. Cause: \u0026#34; + e, e); } cacheRefElement 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 private void cacheRefElement(XNode context) { if (context != null) { // 在Configuration.cacheRefMap 这个map对象中存储 当前命名空间与缓存命名空间之间的关系 // key: 当前命名空间，value：指向的命名空间 configuration.addCacheRef(builderAssistant.getCurrentNamespace(), context.getStringAttribute(\u0026#34;namespace\u0026#34;)); // 新建对象 CacheRefResolver cacheRefResolver = new CacheRefResolver(builderAssistant, context.getStringAttribute(\u0026#34;namespace\u0026#34;)); try { cacheRefResolver.resolveCacheRef(); } catch (IncompleteElementException e) { configuration.addIncompleteCacheRef(cacheRefResolver); } } } public Cache useCacheRef(String namespace) { if (namespace == null) { throw new BuilderException(\u0026#34;cache-ref element requires a namespace attribute.\u0026#34;); } try { unresolvedCacheRef = true; Cache cache = configuration.getCache(namespace); if (cache == null) { throw new IncompleteElementException(\u0026#34;No cache for namespace \u0026#39;\u0026#34; + namespace + \u0026#34;\u0026#39; could be found.\u0026#34;); } // 设置当前的缓存空间 currentCache = cache; unresolvedCacheRef = false; return cache; } catch (IllegalArgumentException e) { throw new IncompleteElementException(\u0026#34;No cache for namespace \u0026#39;\u0026#34; + namespace + \u0026#34;\u0026#39; could be found.\u0026#34;, e); } } cacheElement 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // 解析cache 标签 private void cacheElement(XNode context) throws Exception { if (context != null) { // 获取自定义缓存 String type = context.getStringAttribute(\u0026#34;type\u0026#34;, \u0026#34;PERPETUAL\u0026#34;); // 获取缓存的类对象 Class\u0026lt;? extends Cache\u0026gt; typeClass = typeAliasRegistry.resolveAlias(type); // 获取清除策略 String eviction = context.getStringAttribute(\u0026#34;eviction\u0026#34;, \u0026#34;LRU\u0026#34;); // 获取清除策略的类对象 Class\u0026lt;? extends Cache\u0026gt; evictionClass = typeAliasRegistry.resolveAlias(eviction); // 获取刷新间隔 Long flushInterval = context.getLongAttribute(\u0026#34;flushInterval\u0026#34;); // 获取引用数目 Integer size = context.getIntAttribute(\u0026#34;size\u0026#34;); // 获取是否只读 boolean readWrite = !context.getBooleanAttribute(\u0026#34;readOnly\u0026#34;, false); boolean blocking = context.getBooleanAttribute(\u0026#34;blocking\u0026#34;, false); Properties props = context.getChildrenAsProperties(); // builderAssistant.useNewCache(typeClass, evictionClass, flushInterval, size, readWrite, blocking, props); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public Cache useNewCache(Class\u0026lt;? extends Cache\u0026gt; typeClass, Class\u0026lt;? extends Cache\u0026gt; evictionClass, Long flushInterval, Integer size, boolean readWrite, boolean blocking, Properties props) { // 创建对象 Cache cache = new CacheBuilder(currentNamespace) .implementation(valueOrDefault(typeClass, PerpetualCache.class)) .addDecorator(valueOrDefault(evictionClass, LruCache.class)) .clearInterval(flushInterval) .size(size) .readWrite(readWrite) .blocking(blocking) .properties(props) .build(); // 添加到配置中 configuration.addCache(cache); // 声明当前的缓存 currentCache = cache; return cache; } resultMapElements 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 // 解析/mapper/resultMap 标签 private void resultMapElements(List\u0026lt;XNode\u0026gt; list) throws Exception { // 遍历每一条x ml for (XNode resultMapNode : list) { try { resultMapElement(resultMapNode); } catch (IncompleteElementException e) { // ignore, it will be retried } } } private ResultMap resultMapElement(XNode resultMapNode) throws Exception { return resultMapElement(resultMapNode, Collections.\u0026lt;ResultMapping\u0026gt; emptyList()); } private ResultMap resultMapElement(XNode resultMapNode, List\u0026lt;ResultMapping\u0026gt; additionalResultMappings) throws Exception { ErrorContext.instance().activity(\u0026#34;processing \u0026#34; + resultMapNode.getValueBasedIdentifier()); String id = resultMapNode.getStringAttribute(\u0026#34;id\u0026#34;, resultMapNode.getValueBasedIdentifier()); String type = resultMapNode.getStringAttribute(\u0026#34;type\u0026#34;, resultMapNode.getStringAttribute(\u0026#34;ofType\u0026#34;, resultMapNode.getStringAttribute(\u0026#34;resultType\u0026#34;, resultMapNode.getStringAttribute(\u0026#34;javaType\u0026#34;)))); // 是否继承其他mapper ,其他mapper 为父类 String extend = resultMapNode.getStringAttribute(\u0026#34;extends\u0026#34;); // 是否开启自动映射 Boolean autoMapping = resultMapNode.getBooleanAttribute(\u0026#34;autoMapping\u0026#34;); // 获取结果对应的类型 Class\u0026lt;?\u0026gt; typeClass = resolveClass(type); Discriminator discriminator = null; List\u0026lt;ResultMapping\u0026gt; resultMappings = new ArrayList\u0026lt;ResultMapping\u0026gt;(); resultMappings.addAll(additionalResultMappings); List\u0026lt;XNode\u0026gt; resultChildren = resultMapNode.getChildren(); // 遍历子标签 for (XNode resultChild : resultChildren) { // 处理构造器标签 if (\u0026#34;constructor\u0026#34;.equals(resultChild.getName())) { processConstructorElement(resultChild, typeClass, resultMappings); } else if (\u0026#34;discriminator\u0026#34;.equals(resultChild.getName())) { discriminator = processDiscriminatorElement(resultChild, typeClass, resultMappings); } else { List\u0026lt;ResultFlag\u0026gt; flags = new ArrayList\u0026lt;ResultFlag\u0026gt;(); if (\u0026#34;id\u0026#34;.equals(resultChild.getName())) { flags.add(ResultFlag.ID); } resultMappings.add(buildResultMappingFromContext(resultChild, typeClass, flags)); } } ResultMapResolver resultMapResolver = new ResultMapResolver(builderAssistant, id, typeClass, extend, discriminator, resultMappings, autoMapping); try { return resultMapResolver.resolve(); } catch (IncompleteElementException e) { // 将解析失败的标签记录下，后续补偿解析 configuration.addIncompleteResultMap(resultMapResolver); throw e; } } sqlElement 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 private void sqlElement(List\u0026lt;XNode\u0026gt; list) throws Exception { // 如果指定了数据库id if (configuration.getDatabaseId() != null) { sqlElement(list, configuration.getDatabaseId()); } // 没有指定 sqlElement(list, null); } // 就是记录 sql的id private void sqlElement(List\u0026lt;XNode\u0026gt; list, String requiredDatabaseId) throws Exception { for (XNode context : list) { String databaseId = context.getStringAttribute(\u0026#34;databaseId\u0026#34;); String id = context.getStringAttribute(\u0026#34;id\u0026#34;); id = builderAssistant.applyCurrentNamespace(id, false); if (databaseIdMatchesCurrent(id, databaseId, requiredDatabaseId)) { // key: sql_id value: sql 语句 sqlFragments.put(id, context); } } } buildStatementFromContext 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 // 首先判断有没有数据库ID private void buildStatementFromContext(List\u0026lt;XNode\u0026gt; list) { if (configuration.getDatabaseId() != null) { buildStatementFromContext(list, configuration.getDatabaseId()); } buildStatementFromContext(list, null); } // 逐个遍历xml private void buildStatementFromContext(List\u0026lt;XNode\u0026gt; list, String requiredDatabaseId) { for (XNode context : list) { final XMLStatementBuilder statementParser = new XMLStatementBuilder(configuration, builderAssistant, context, requiredDatabaseId); try { statementParser.parseStatementNode(); } catch (IncompleteElementException e) { configuration.addIncompleteStatement(statementParser); } } } // 先获取属性之后添加到 public void parseStatementNode() { String id = context.getStringAttribute(\u0026#34;id\u0026#34;); String databaseId = context.getStringAttribute(\u0026#34;databaseId\u0026#34;); if (!databaseIdMatchesCurrent(id, databaseId, this.requiredDatabaseId)) { return; } Integer fetchSize = context.getIntAttribute(\u0026#34;fetchSize\u0026#34;); Integer timeout = context.getIntAttribute(\u0026#34;timeout\u0026#34;); String parameterMap = context.getStringAttribute(\u0026#34;parameterMap\u0026#34;); String parameterType = context.getStringAttribute(\u0026#34;parameterType\u0026#34;); Class\u0026lt;?\u0026gt; parameterTypeClass = resolveClass(parameterType); String resultMap = context.getStringAttribute(\u0026#34;resultMap\u0026#34;); String resultType = context.getStringAttribute(\u0026#34;resultType\u0026#34;); String lang = context.getStringAttribute(\u0026#34;lang\u0026#34;); LanguageDriver langDriver = getLanguageDriver(lang); Class\u0026lt;?\u0026gt; resultTypeClass = resolveClass(resultType); String resultSetType = context.getStringAttribute(\u0026#34;resultSetType\u0026#34;); StatementType statementType = StatementType.valueOf(context.getStringAttribute(\u0026#34;statementType\u0026#34;, StatementType.PREPARED.toString())); ResultSetType resultSetTypeEnum = resolveResultSetType(resultSetType); String nodeName = context.getNode().getNodeName(); //根据节点名，得到SQL操作的类型 SqlCommandType sqlCommandType = SqlCommandType.valueOf(nodeName.toUpperCase(Locale.ENGLISH)); //判断是否是查询 boolean isSelect = sqlCommandType == SqlCommandType.SELECT; //是否刷新缓存 默认:增删改刷新 查询不刷新 boolean flushCache = context.getBooleanAttribute(\u0026#34;flushCache\u0026#34;, !isSelect); //是否使用二级缓存 默认值:查询使用 增删改不使用 boolean useCache = context.getBooleanAttribute(\u0026#34;useCache\u0026#34;, isSelect); boolean resultOrdered = context.getBooleanAttribute(\u0026#34;resultOrdered\u0026#34;, false); // Include Fragments before parsing XMLIncludeTransformer includeParser = new XMLIncludeTransformer(configuration, builderAssistant); includeParser.applyIncludes(context.getNode()); // Parse selectKey after includes and remove them. processSelectKeyNodes(id, parameterTypeClass, langDriver); // Parse the SQL (pre: \u0026lt;selectKey\u0026gt; and \u0026lt;include\u0026gt; were parsed and removed) // 解析Sql（重要） 根据sql文本来判断是否需要动态解析 如果没有动态sql语句且 只有#{}的时候 直接静态解析使用?占位 当有 ${} 不解析 SqlSource sqlSource = langDriver.createSqlSource(configuration, context, parameterTypeClass); String resultSets = context.getStringAttribute(\u0026#34;resultSets\u0026#34;); String keyProperty = context.getStringAttribute(\u0026#34;keyProperty\u0026#34;); String keyColumn = context.getStringAttribute(\u0026#34;keyColumn\u0026#34;); KeyGenerator keyGenerator; //设置主键自增规则 String keyStatementId = id + SelectKeyGenerator.SELECT_KEY_SUFFIX; keyStatementId = builderAssistant.applyCurrentNamespace(keyStatementId, true); if (configuration.hasKeyGenerator(keyStatementId)) { keyGenerator = configuration.getKeyGenerator(keyStatementId); } else { keyGenerator = context.getBooleanAttribute(\u0026#34;useGeneratedKeys\u0026#34;, configuration.isUseGeneratedKeys() \u0026amp;\u0026amp; SqlCommandType.INSERT.equals(sqlCommandType)) ? Jdbc3KeyGenerator.INSTANCE : NoKeyGenerator.INSTANCE; } builderAssistant.addMappedStatement(id, sqlSource, statementType, sqlCommandType, fetchSize, timeout, parameterMap, parameterTypeClass, resultMap, resultTypeClass, resultSetTypeEnum, flushCache, useCache, resultOrdered, keyGenerator, keyProperty, keyColumn, databaseId, langDriver, resultSets); } 解析sql语句 XMLLanguageDriver 类的解析方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @Override public SqlSource createSqlSource(Configuration configuration, XNode script, Class\u0026lt;?\u0026gt; parameterType) { XMLScriptBuilder builder = new XMLScriptBuilder(configuration, script, parameterType); return builder.parseScriptNode(); } public SqlSource parseScriptNode() { MixedSqlNode rootSqlNode = parseDynamicTags(context); SqlSource sqlSource = null; if (isDynamic) { //如果是${}会直接不解析，等待执行的时候直接赋值 sqlSource = new DynamicSqlSource(configuration, rootSqlNode); } else { // 用占位符方式来解析 #{} --\u0026gt; ? sqlSource = new RawSqlSource(configuration, rootSqlNode, parameterType); } return sqlSource; } public DynamicSqlSource(Configuration configuration, SqlNode rootSqlNode) { this.configuration = configuration; this.rootSqlNode = rootSqlNode; } public RawSqlSource(Configuration configuration, String sql, Class\u0026lt;?\u0026gt; parameterType) { SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration); Class\u0026lt;?\u0026gt; clazz = parameterType == null ? Object.class : parameterType; // 解析 sqlSource = sqlSourceParser.parse(sql, clazz, new HashMap\u0026lt;String, Object\u0026gt;()); } public SqlSource parse(String originalSql, Class\u0026lt;?\u0026gt; parameterType, Map\u0026lt;String, Object\u0026gt; additionalParameters) { ParameterMappingTokenHandler handler = new ParameterMappingTokenHandler(configuration, parameterType, additionalParameters); GenericTokenParser parser = new GenericTokenParser(\u0026#34;#{\u0026#34;, \u0026#34;}\u0026#34;, handler); String sql = parser.parse(originalSql); return new StaticSqlSource(configuration, sql, handler.getParameterMappings()); } 这里会生成一个GenericTokenParser，这个对象可以传入一个openToken和closeToken，如果是#{}，那么openToken就是#{，closeToken就是 }，然后通过parse方法中的handler.handleToken()方法进行替换。\n在这之前由于已经进行过SQL是否含有#{}的判断了，所以在这里如果是只有${}，那么handler就是BindingTokenParser的实例化对象，如果存在#{}，那么handler就是ParameterMappingTokenHandler的实例化对象。\n每一条sql 对应一个MappedStatement\n对外部 resultMap 的命名引用。结果映射是 MyBatis 最强大的特性，resultType 和 resultMap 之间只能同时使用一个。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 constructor - 用于在实例化类时，注入结果到构造方法中 idArg - ID 参数；标记出作为 ID 的结果可以帮助提高整体性能 arg - 将被注入到构造方法的一个普通结果 \u0026lt;!--基础，处理简单列--\u0026gt; id – 一个 ID 结果；标记出作为 ID 的结果可以帮助提高整体性能 result – 注入到字段或 JavaBean 属性的普通结果 association – 一个复杂类型的关联；许多结果将包装成这种类型 嵌套结果映射 – 关联可以是 resultMap 元素，或是对其它结果映射的引用 collection – 一个复杂类型的集合 嵌套结果映射 – 集合可以是 resultMap 元素，或是对其它结果映射的引用 discriminator – 使用结果值来决定使用哪个 resultMap case – 基于某些值的结果映射 嵌套结果映射 – case 也是一个结果映射，因此具有相同的结构和元素；或者引用其它的结果映射 \u0026lt;resultMap\u0026gt; 属性： id\t当前命名空间中的一个唯一标识，用于标识一个结果映射。 type\t类的完全限定名, 或者一个类型别名（关于内置的类型别名，可以参考上面的表格）。 autoMapping\t如果设置这个属性，MyBatis 将会为本结果映射开启或者关闭自动映射。 这个属性会覆盖全局的属性 autoMappingBehavior。\t默认值：未设置（unset）。 \u0026lt;id\u0026gt;\u0026amp;\u0026lt;result\u0026gt; 属性： property\t映射到列结果的字段或属性。如果 JavaBean 有这个名字的属性（property），会先使用该属性。否则 MyBatis 将会寻找给定\t字段（field）。 无论是哪一种情形，你都可以使用常见的点式分隔形式进行复杂属性导航。 比如，你可以这样映射一些简单的东 西：“username”，或者映射到一些复杂的东西上：“address.street.number”。 column\t数据库中的列名，或者是列的别名。一般情况下，这和传递给 resultSet.getString(columnName) 方法的参数一样。 javaType\t一个 Java 类的全限定名，或一个类型别名（关于内置的类型别名，可以参考上面的表格）。 如果你映射到一个 JavaBean，MyBatis 通常可以推断类型。然而，如果你映射到的是 HashMap，那么你应该明确地指定 javaType 来保证行为与期望的相一致。 jdbcType\tJDBC 类型，所支持的 JDBC 类型参见这个表格之后的“支持的 JDBC 类型”。 只需要在可能执行插入、更新和删除的且允许空值的列上 指定 JDBC 类型。这是 JDBC 的要求而非 MyBatis 的要求。如果你直接面向 JDBC 编程，你需要对可以为空值的列指定这个类型。 typeHandler\t我们在前面讨论过默认的类型处理器。使用这个属性，你可以覆盖默认的类型处理器。 这个属性值是一个类型处理器实现类的全限定名，或者是类型别名。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 // 处理构造器标签 private void processConstructorElement(XNode resultChild, Class\u0026lt;?\u0026gt; resultType, List\u0026lt;ResultMapping\u0026gt; resultMappings) throws Exception { List\u0026lt;XNode\u0026gt; argChildren = resultChild.getChildren(); for (XNode argChild : argChildren) { List\u0026lt;ResultFlag\u0026gt; flags = new ArrayList\u0026lt;ResultFlag\u0026gt;(); flags.add(ResultFlag.CONSTRUCTOR); if (\u0026#34;idArg\u0026#34;.equals(argChild.getName())) { flags.add(ResultFlag.ID); } resultMappings.add(buildResultMappingFromContext(argChild, resultType, flags)); } } private ResultMapping buildResultMappingFromContext(XNode context, Class\u0026lt;?\u0026gt; resultType, List\u0026lt;ResultFlag\u0026gt; flags) throws Exception { String property; if (flags.contains(ResultFlag.CONSTRUCTOR)) { property = context.getStringAttribute(\u0026#34;name\u0026#34;); } else { property = context.getStringAttribute(\u0026#34;property\u0026#34;); } // 获取标签属性 String column = context.getStringAttribute(\u0026#34;column\u0026#34;); String javaType = context.getStringAttribute(\u0026#34;javaType\u0026#34;); String jdbcType = context.getStringAttribute(\u0026#34;jdbcType\u0026#34;); String nestedSelect = context.getStringAttribute(\u0026#34;select\u0026#34;); String nestedResultMap = context.getStringAttribute(\u0026#34;resultMap\u0026#34;, processNestedResultMappings(context, Collections.\u0026lt;ResultMapping\u0026gt; emptyList())); String notNullColumn = context.getStringAttribute(\u0026#34;notNullColumn\u0026#34;); String columnPrefix = context.getStringAttribute(\u0026#34;columnPrefix\u0026#34;); String typeHandler = context.getStringAttribute(\u0026#34;typeHandler\u0026#34;); String resultSet = context.getStringAttribute(\u0026#34;resultSet\u0026#34;); String foreignColumn = context.getStringAttribute(\u0026#34;foreignColumn\u0026#34;); boolean lazy = \u0026#34;lazy\u0026#34;.equals(context.getStringAttribute(\u0026#34;fetchType\u0026#34;, configuration.isLazyLoadingEnabled() ? \u0026#34;lazy\u0026#34; : \u0026#34;eager\u0026#34;)); Class\u0026lt;?\u0026gt; javaTypeClass = resolveClass(javaType); @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Class\u0026lt;? extends TypeHandler\u0026lt;?\u0026gt;\u0026gt; typeHandlerClass = (Class\u0026lt;? extends TypeHandler\u0026lt;?\u0026gt;\u0026gt;) resolveClass(typeHandler); JdbcType jdbcTypeEnum = resolveJdbcType(jdbcType); // 构造对象 return builderAssistant.buildResultMapping(resultType, property, column, javaTypeClass, jdbcTypeEnum, nestedSelect, nestedResultMap, notNullColumn, columnPrefix, typeHandlerClass, flags, resultSet, foreignColumn, lazy); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 开始解析 xxMaper.xml 文件 先判断是否有名称空间，否则抛异常 处理 标签 cache-ref:引用其它命名空间的缓存配置。 cache: 该命名空间的缓存配置。 parameterMap： 被废弃 resultMap：结果映射 sql：这个元素可以用来定义可重用的 SQL 代码片段，以便在其它语句中使用 select|insert|update|delete sql 动作 sql语句是否指定了特定数据库厂商 生成XMLStatementBuilder 每一个XMLStatementBuilder 对应一条sql 解析sql 标签内每一个属性，封装成MappedStatement 对象，每个MappedStatement 都对应一条sql 标签 将MappedStatement 加入到Configuration key:sql标签的id.value MappedStatement实例 configuration.addLoadedResource(resource); 1 2 3 public void addLoadedResource(String resource) { // 保存已经解析的xml loadedResources.add(resource); bindMapperForNamespace(); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 private void bindMapperForNamespace() { String namespace = builderAssistant.getCurrentNamespace(); if (namespace != null) { Class\u0026lt;?\u0026gt; boundType = null; try { // 获取名称空间对象 boundType = Resources.classForName(namespace); } catch (ClassNotFoundException e) { // ignore, bound type is not required } if (boundType != null \u0026amp;\u0026amp; !configuration.hasMapper(boundType)) { // Spring may not know the real resource name so we set a flag // to prevent loading again this resource from the mapper interface // look at MapperAnnotationBuilder#loadXmlResource configuration.addLoadedResource(\u0026#34;namespace:\u0026#34; + namespace); configuration.addMapper(boundType); } } 1 2 3 4 5 获取当前xml 文件中的名称空间 mapper接口的全限定名 反射出实例对象 判断configuration 中是否含有这个对象 将名称空间保存 将对象保存起来，key:mapper的class对象，value:通过动态代理生产的class对象的代理对象。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public \u0026lt;T\u0026gt; void addMapper(Class\u0026lt;T\u0026gt; type) { if (type.isInterface()) { if (hasMapper(type)) { throw new BindingException(\u0026#34;Type \u0026#34; + type + \u0026#34; is already known to the MapperRegistry.\u0026#34;); } boolean loadCompleted = false; try { knownMappers.put(type, new MapperProxyFactory\u0026lt;\u0026gt;(type)); // It\u0026#39;s important that the type is added before the parser is run // otherwise the binding may automatically be attempted by the // mapper parser. If the type is already known, it won\u0026#39;t try. MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type); // 将MappedStatement 加入到configuration中 parser.parse(); loadCompleted = true; } finally { if (!loadCompleted) { knownMappers.remove(type); } } } } 每个sql标签解析成mapperstatement对象装进集合，然后把mapper接口的class对象以及代理对象装进集合\nthis.mapperElement(root.evalNode(\u0026ldquo;mappers\u0026rdquo;)); 1 2 3 4 else if (resource == null \u0026amp;\u0026amp; url == null \u0026amp;\u0026amp; mapperClass != null) { Class\u0026lt;?\u0026gt; mapperInterface = Resources.classForName(mapperClass); configuration.addMapper(mapperInterface); } 1 2 3 4 5 6 反射出实例对象 将对象保存起来，key:mapper的class对象，value:通过动态代理生产的class对象的代理对象。 构建注解解析类 判断是否解析过mapper类 根据类名查找配置文件 解析配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public \u0026lt;T\u0026gt; void addMapper(Class\u0026lt;T\u0026gt; type) { if (type.isInterface()) { if (hasMapper(type)) { throw new BindingException(\u0026#34;Type \u0026#34; + type + \u0026#34; is already known to the MapperRegistry.\u0026#34;); } boolean loadCompleted = false; try { knownMappers.put(type, new MapperProxyFactory\u0026lt;\u0026gt;(type)); // It\u0026#39;s important that the type is added before the parser is run // otherwise the binding may automatically be attempted by the // mapper parser. If the type is already known, it won\u0026#39;t try. MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type); parser.parse(); loadCompleted = true; } finally { if (!loadCompleted) { knownMappers.remove(type); } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class MapperAnnotationBuilder public void parse() { String resource = type.toString(); if (!configuration.isResourceLoaded(resource)) { loadXmlResource(); configuration.addLoadedResource(resource); assistant.setCurrentNamespace(type.getName()); parseCache(); parseCacheRef(); for (Method method : type.getMethods()) { if (!canHaveStatement(method)) { continue; } if (getAnnotationWrapper(method, false, Select.class, SelectProvider.class).isPresent() \u0026amp;\u0026amp; method.getAnnotation(ResultMap.class) == null) { parseResultMap(method); } try { parseStatement(method); } catch (IncompleteElementException e) { configuration.addIncompleteMethod(new MethodResolver(this, method)); } } } parsePendingMethods(); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 private void loadXmlResource() { // Spring may not know the real resource name so we check a flag // to prevent loading again a resource twice // this flag is set at XMLMapperBuilder#bindMapperForNamespace if (!configuration.isResourceLoaded(\u0026#34;namespace:\u0026#34; + type.getName())) { String xmlResource = type.getName().replace(\u0026#39;.\u0026#39;, \u0026#39;/\u0026#39;) + \u0026#34;.xml\u0026#34;; // #1347 InputStream inputStream = type.getResourceAsStream(\u0026#34;/\u0026#34; + xmlResource); if (inputStream == null) { // Search XML mapper that is not in the module but in the classpath. try { inputStream = Resources.getResourceAsStream(type.getClassLoader(), xmlResource); } catch (IOException e2) { // ignore, resource is not required } } if (inputStream != null) { XMLMapperBuilder xmlParser = new XMLMapperBuilder(inputStream, assistant.getConfiguration(), xmlResource, configuration.getSqlFragments(), type.getName()); xmlParser.parse(); } } } this.mapperElement(root.evalNode(\u0026ldquo;mappers\u0026rdquo;));3 1 2 3 4 5 6 if (\u0026#34;package\u0026#34;.equals(child.getName())) { // 获取包的名称 String mapperPackage = child.getStringAttribute(\u0026#34;name\u0026#34;); configuration.addMappers(mapperPackage); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 public void addMappers(String packageName, Class\u0026lt;?\u0026gt; superType) { ResolverUtil\u0026lt;Class\u0026lt;?\u0026gt;\u0026gt; resolverUtil = new ResolverUtil\u0026lt;Class\u0026lt;?\u0026gt;\u0026gt;(); resolverUtil.find(new ResolverUtil.IsA(superType), packageName); // 找到包下面所有的类 Set\u0026lt;Class\u0026lt;? extends Class\u0026lt;?\u0026gt;\u0026gt;\u0026gt; mapperSet = resolverUtil.getClasses(); for (Class\u0026lt;?\u0026gt; mapperClass : mapperSet) { addMapper(mapperClass); } } public \u0026lt;T\u0026gt; void addMapper(Class\u0026lt;T\u0026gt; type) { // 包下面是不是接口，不是不处理 if (type.isInterface()) { // 是否已经处理过 if (hasMapper(type)) { throw new BindingException(\u0026#34;Type \u0026#34; + type + \u0026#34; is already known to the MapperRegistry.\u0026#34;); } // 记录没有处理过 boolean loadCompleted = false; try { // 放入到已处理Map中 knownMappers.put(type, new MapperProxyFactory\u0026lt;T\u0026gt;(type)); // It\u0026#39;s important that the type is added before the parser is run // otherwise the binding may automatically be attempted by the // mapper parser. If the type is already known, it won\u0026#39;t try. MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type); parser.parse(); loadCompleted = true; } finally { if (!loadCompleted) { knownMappers.remove(type); } } } } public MapperAnnotationBuilder(Configuration configuration, Class\u0026lt;?\u0026gt; type) { // 更改资源路径 String resource = type.getName().replace(\u0026#39;.\u0026#39;, \u0026#39;/\u0026#39;) + \u0026#34;.java (best guess)\u0026#34;; this.assistant = new MapperBuilderAssistant(configuration, resource); this.configuration = configuration; this.type = type; sqlAnnotationTypes.add(Select.class); sqlAnnotationTypes.add(Insert.class); sqlAnnotationTypes.add(Update.class); sqlAnnotationTypes.add(Delete.class); sqlProviderAnnotationTypes.add(SelectProvider.class); sqlProviderAnnotationTypes.add(InsertProvider.class); sqlProviderAnnotationTypes.add(UpdateProvider.class); sqlProviderAnnotationTypes.add(DeleteProvider.class); } @SelectProvider：这种是直接用于接口中的方法，来代替书写sql\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 @Documented @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface InsertProvider { // 用于指定获取 sql 语句的类 Class\u0026lt;?\u0026gt; type(); // 指定类中要执行获取 sql 语句的方法 String method(); } public interface AutoConstructorMapper { @SelectProvider(type = SubjectSqlProvider.class, method = \u0026#34;getSubjectTestProvider\u0026#34;) PrimitiveSubject getSubjectTestProvider(@Param(\u0026#34;id\u0026#34;) int id); } /** * 方法入参必须为 Map * 方法的权限修饰符 必须是 public * 方法返回的必须是拼接好的 sql 字符串 * 用于外部引用sql */ public class SubjectSqlProvider { public String getSubjectTestProvider(Map\u0026lt;String, Object\u0026gt; params) { return new SQL() .SELECT(\u0026#34;*\u0026#34;) .FROM(\u0026#34;subject\u0026#34;) .WHERE(\u0026#34;id = \u0026#34; + params.get(\u0026#34;id\u0026#34;)) .toString(); } } 1 2 解析通过包定义方式 与解析类的方式相同 3.2 获取session会话 1 2 3 4 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); // 返回的是DefaultSqlSessionFactory SqlSession session = sqlSessionFactory.openSession(); 1 2 3 4 1、创建事务工厂 2、实例化一个事务对象 3、生成一个执行器Executor 4、根据类型生成执行器 SIMPLE, REUSE, BATCH 通过SqlSession，您可以执行sql命令、获取映射器和管理事务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class DefaultSqlSessionFactory /*** * 默认使用 ExecutorType.SIMPLE; */ @Override public SqlSession openSession(ExecutorType execType, TransactionIsolationLevel level) { return openSessionFromDataSource(execType, level, false); } ？ 什么时候设置的ExecutorType：默认值 private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) { Transaction tx = null; try { // 获取解析好的环境 final Environment environment = configuration.getEnvironment(); // 从环境中获取事务工厂 final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); // 创建一个事务 tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); } catch (Exception e) { closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(\u0026#34;Error opening session. Cause: \u0026#34; + e, e); } finally { ErrorContext.instance().reset(); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public Executor newExecutor(Transaction transaction, ExecutorType executorType) { // 设置默认值 executorType = executorType == null ? this.defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Object executor; // 配置指定的 if (ExecutorType.BATCH == executorType) { executor = new BatchExecutor(this, transaction); } else if (ExecutorType.REUSE == executorType) { executor = new ReuseExecutor(this, transaction); } else { executor = new SimpleExecutor(this, transaction); } // 是否开启缓存 if (this.cacheEnabled) { executor = new CachingExecutor((Executor)executor); } // 如果拦截器链中执行执行器 Executor executor = (Executor)this.interceptorChain.pluginAll(executor); return executor; } 1 2 3 4 5 SimpleExecutor: 简单执行器，是 MyBatis 中默认使用的执行器，每执行一次 update 或 select，就开启一个 Statement 对象，用完就直接关闭 Statement 对象(可以是 Statement 或者是 PreparedStatment 对象) ReuseExecutor: 可重用执行器，这里的重用指的是重复使用 Statement，它会在内部使用一个 Map 把创建的 Statement 都缓存起来，每次执行 SQL 命令的时候，都会去判断是否存在基于该 SQL 的 Statement 对象，如果存在 Statement 对象并且对应的 connection 还没有关闭的情况下就继续使用之前的 Statement 对象，并将其缓存起来。 BatchExecutor: 批处理执行器，用于将多个SQL一次性输出到数据库 3.3 sql执行 3.3.1 获取sqlSession SqlSession实际上是我们操作数据库的一个真实对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 try (SqlSession session = sqlSessionFactory.openSession()) { } private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) { Transaction tx = null; try { // 获取之前解析好的环境参数 final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); // 创建执行器 final Executor executor = configuration.newExecutor(tx, execType); // 构造sqlSession return new DefaultSqlSession(configuration, executor, autoCommit); } catch (Exception e) { closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(\u0026#34;Error opening session. Cause: \u0026#34; + e, e); } finally { ErrorContext.instance().reset(); } } // 都会创建一个事物工厂，就算没有手动配置，也会创建一个默认的ManagedTransactionFactory private TransactionFactory getTransactionFactoryFromEnvironment(Environment environment) { if (environment == null || environment.getTransactionFactory() == null) { return new ManagedTransactionFactory(); } return environment.getTransactionFactory(); } // 根据配置创建执行器 public Executor newExecutor(Transaction transaction, ExecutorType executorType) { executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; if (ExecutorType.BATCH == executorType) { executor = new BatchExecutor(this, transaction); } else if (ExecutorType.REUSE == executorType) { executor = new ReuseExecutor(this, transaction); } else { executor = new SimpleExecutor(this, transaction); } if (cacheEnabled) { executor = new CachingExecutor(executor); } executor = (Executor) interceptorChain.pluginAll(executor); return executor; } 3.3.2 获取mapper对象 1 2 3 // 使用 DefaultSqlSession的getMapper 方法 // 这时每次都生成新的执行器 StudentMapper mapper = session.getMapper(StudentMapper.class); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @Override public \u0026lt;T\u0026gt; T getMapper(Class\u0026lt;T\u0026gt; type) { return configuration.\u0026lt;T\u0026gt;getMapper(type, this); } public \u0026lt;T\u0026gt; T getMapper(Class\u0026lt;T\u0026gt; type, SqlSession sqlSession) { // 获取工厂 final MapperProxyFactory\u0026lt;T\u0026gt; mapperProxyFactory = (MapperProxyFactory\u0026lt;T\u0026gt;) knownMappers.get(type); if (mapperProxyFactory == null) { throw new BindingException(\u0026#34;Type \u0026#34; + type + \u0026#34; is not known to the MapperRegistry.\u0026#34;); } try { // 通过反射创建代理对象 return mapperProxyFactory.newInstance(sqlSession); } catch (Exception e) { throw new BindingException(\u0026#34;Error getting mapper instance. Cause: \u0026#34; + e, e); } } public T newInstance(SqlSession sqlSession) { // 代理对象 final MapperProxy\u0026lt;T\u0026gt; mapperProxy = new MapperProxy\u0026lt;T\u0026gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); } 从knownMappers 中获取工厂，knownMappers是在解析xml文件的时候将mapper.xml里面MappedStatement 的类型缓存起来\n3.3.3 执行 1 List\u0026lt;StudentPO\u0026gt; studentPOS = mapper.selectAll(); 根据反射规则，实际执行的时候会转换到代理对象的invoke（）上\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { try { if (Object.class.equals(method.getDeclaringClass())) { // 判断方法所属的类 //是不是调用的Object默认的方法 //如果是 则不代理，不改变原先方法的行为 return method.invoke(this, args); } else if (isDefaultMethod(method)) { //对于默认方法的处理 //判断是否为default方法，即接口中定义的默认方法。 //如果是接口中的默认方法则把方法绑定到代理对象中然后调用。 return invokeDefaultMethod(proxy, method, args); } } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); } // mybatis 实际执行位置 final MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args); } private MapperMethod cachedMapperMethod(Method method) { //动态代理会有缓存，computeIfAbsent 如果缓存中有则直接从缓存中拿 //如果缓存中没有，则new一个然后放入缓存中 //因为动态代理是很耗资源的 MapperMethod mapperMethod = methodCache.get(method); if (mapperMethod == null) { mapperMethod = new MapperMethod(mapperInterface, method, sqlSession.getConfiguration()); methodCache.put(method, mapperMethod); } return mapperMethod; } mapperMethod.execute(sqlSession, args):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 // 判断实际sql 是那种类型，根据不同的类型有不同的处理 public Object execute(SqlSession sqlSession, Object[] args) { Object result; switch (command.getType()) { case INSERT: { Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.insert(command.getName(), param)); break; } case UPDATE: { Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); break; } case DELETE: { Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); break; } case SELECT: if (method.returnsVoid() \u0026amp;\u0026amp; method.hasResultHandler()) { // 执行没有返回值的 executeWithResultHandler(sqlSession, args); result = null; } else if (method.returnsMany()) { // 执行多个返回值 result = executeForMany(sqlSession, args); } else if (method.returnsMap()) { // 执行返回是map的 result = executeForMap(sqlSession, args); } else if (method.returnsCursor()) { // 执行返回是cursor result = executeForCursor(sqlSession, args); } else { Object param = method.convertArgsToSqlCommandParam(args); // 执行查询单个的 result = sqlSession.selectOne(command.getName(), param); } break; case FLUSH: result = sqlSession.flushStatements(); break; default: throw new BindingException(\u0026#34;Unknown execution method for: \u0026#34; + command.getName()); } if (result == null \u0026amp;\u0026amp; method.getReturnType().isPrimitive() \u0026amp;\u0026amp; !method.returnsVoid()) { throw new BindingException(\u0026#34;Mapper method \u0026#39;\u0026#34; + command.getName() + \u0026#34; attempted to return null from a method with a primitive return type (\u0026#34; + method.getReturnType() + \u0026#34;).\u0026#34;); } return result; } executeForMany(sqlSession, args);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 private \u0026lt;E\u0026gt; Object executeForMany(SqlSession sqlSession, Object[] args) { List\u0026lt;E\u0026gt; result; Object param = method.convertArgsToSqlCommandParam(args); if (method.hasRowBounds()) { // 分页的情况 RowBounds rowBounds = method.extractRowBounds(args); result = sqlSession.\u0026lt;E\u0026gt;selectList(command.getName(), param, rowBounds); } else { // 不分页的情况 result = sqlSession.\u0026lt;E\u0026gt;selectList(command.getName(), param); } // issue #510 Collections \u0026amp; arrays support if (!method.getReturnType().isAssignableFrom(result.getClass())) { // 如果xml中定义的返回不是list,这里转换成list if (method.getReturnType().isArray()) { return convertToArray(result); } else { return convertToDeclaredCollection(sqlSession.getConfiguration(), result); } } return result; } @Override public \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; selectList(String statement, Object parameter, RowBounds rowBounds) { try { // 之前解析配置文件的时候将MappedStatement 放到configuration里面 MappedStatement ms = configuration.getMappedStatement(statement); // executor 可以是BaseExecutor ，也可以是CachingExecutor ，CachingExecutor 是使用缓存的情况 return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); } catch (Exception e) { throw ExceptionFactory.wrapException(\u0026#34;Error querying database. Cause: \u0026#34; + e, e); } finally { ErrorContext.instance().reset(); } } CachingExecutor#query\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @Override public \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException { // 获取sql 语句 BoundSql boundSql = ms.getBoundSql(parameterObject); CacheKey key = createCacheKey(ms, parameterObject, rowBounds, boundSql); return query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); } @Override public \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException { // 二级缓存 Cache cache = ms.getCache(); if (cache != null) { // 二级缓存不为空 // 有需要的话就刷新缓存 flushCacheIfRequired(ms); if (ms.isUseCache() \u0026amp;\u0026amp; resultHandler == null) { ensureNoOutParams(ms, boundSql); @SuppressWarnings(\u0026#34;unchecked\u0026#34;) List\u0026lt;E\u0026gt; list = (List\u0026lt;E\u0026gt;) tcm.getObject(cache, key); if (list == null) { // 缓存中数据为空，查询一级缓存，delegate默认是BaseExecutor list = delegate.\u0026lt;E\u0026gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); // 放入二级缓存 tcm.putObject(cache, key, list); // issue #578 and #116 } return list; } } // 直接查询一级缓存 return delegate.\u0026lt;E\u0026gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); } BaseExecutor#query\n一级缓存查询\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 ErrorContext.instance().resource(ms.getResource()).activity(\u0026#34;executing a query\u0026#34;).object(ms.getId()); if (closed) { throw new ExecutorException(\u0026#34;Executor was closed.\u0026#34;); } if (queryStack == 0 \u0026amp;\u0026amp; ms.isFlushCacheRequired()) { clearLocalCache(); } List\u0026lt;E\u0026gt; list; try { queryStack++; // 一级缓存 list = resultHandler == null ? (List\u0026lt;E\u0026gt;) localCache.getObject(key) : null; if (list != null) { //对于存储过程有输出资源的处理 handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); } else { //如果缓存为空，则从数据库拿 list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); } } finally { queryStack--; } if (queryStack == 0) { for (DeferredLoad deferredLoad : deferredLoads) { deferredLoad.load(); } // issue #601 deferredLoads.clear(); if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) { // issue #482 clearLocalCache(); } } return list; private \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException { List\u0026lt;E\u0026gt; list; // 先暂时在一级缓存中占个位置 localCache.putObject(key, EXECUTION_PLACEHOLDER); try { // 由子类去实现 list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); } finally { localCache.removeObject(key); } localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) { // 向一级缓存中放入实际的结果 localOutputParameterCache.putObject(key, parameter); } return list; } SimpleExecutor#doQuery\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @Override public \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException { Statement stmt = null; try { Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); //#{} -\u0026gt; ? 的SQL在这里初始化 stmt = prepareStatement(handler, ms.getStatementLog()); return handler.\u0026lt;E\u0026gt;query(stmt, resultHandler); } finally { closeStatement(stmt); } } public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) { // 实际上创建的是RoutingStatementHandler StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); // 执行插件 statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler; } private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException { Statement stmt; // 获取链接 Connection connection = getConnection(statementLog); // 创建Statement stmt = handler.prepare(connection, transaction.getTimeout()); // 参数填充 handler.parameterize(stmt); return stmt; } PreparedStatementHandler#parameterize\n1 2 3 4 5 @Override public void parameterize(Statement statement) throws SQLException { // 调用parameterHandler 来设置参数 parameterHandler.setParameters((PreparedStatement) statement); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @Override public void setParameters(PreparedStatement ps) { ErrorContext.instance().activity(\u0026#34;setting parameters\u0026#34;).object(mappedStatement.getParameterMap().getId()); // 参数列表 List\u0026lt;ParameterMapping\u0026gt; parameterMappings = boundSql.getParameterMappings(); if (parameterMappings != null) { for (int i = 0; i \u0026lt; parameterMappings.size(); i++) { ParameterMapping parameterMapping = parameterMappings.get(i); if (parameterMapping.getMode() != ParameterMode.OUT) { Object value; //拿到xml中#{} 参数的名字 例如 #{id} propertyName==id String propertyName = parameterMapping.getProperty(); if (boundSql.hasAdditionalParameter(propertyName)) { // issue #448 ask first for additional params value = boundSql.getAdditionalParameter(propertyName); } else if (parameterObject == null) { value = null; } else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) { value = parameterObject; } else { //metaObject存储了参数名和参数值的对应关系 MetaObject metaObject = configuration.newMetaObject(parameterObject); value = metaObject.getValue(propertyName); } TypeHandler typeHandler = parameterMapping.getTypeHandler(); JdbcType jdbcType = parameterMapping.getJdbcType(); if (value == null \u0026amp;\u0026amp; jdbcType == null) { jdbcType = configuration.getJdbcTypeForNull(); } try { //在这里给preparedStatement赋值，使用TypeHandler ，不同的类型有不同的赋值实现 typeHandler.setParameter(ps, i + 1, value, jdbcType); } catch (TypeException e) { throw new TypeException(\u0026#34;Could not set parameters for mapping: \u0026#34; + parameterMapping + \u0026#34;. Cause: \u0026#34; + e, e); } catch (SQLException e) { throw new TypeException(\u0026#34;Could not set parameters for mapping: \u0026#34; + parameterMapping + \u0026#34;. Cause: \u0026#34; + e, e); } } } } } PreparedStatementHandler#query\n1 2 3 4 5 6 7 8 @Override public \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; query(Statement statement, ResultHandler resultHandler) throws SQLException { PreparedStatement ps = (PreparedStatement) statement; // 执行sql ps.execute(); // 处理结果 return resultSetHandler.\u0026lt;E\u0026gt; handleResultSets(ps); 无论是如何定义sql语句【注解、xml文件、Mapper方法】最终都可能是转化成SqlSession 的方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 \u0026lt;T\u0026gt; T selectOne(String statement); // 检索从语句键和参数映射的单行。 \u0026lt;T\u0026gt; T selectOne(String statement, Object parameter); // 从语句键和参数中检索映射对象列表。 \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; selectList(String statement); // 在指定的行范围内，从语句键和参数中检索映射对象列表 \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; selectList(String statement, Object parameter, RowBounds rowBounds); // selectMap 是一种特殊情况，它旨在根据结果对象中的一个属性将结果列表转换为 Map。 例如。 为 selectMap(\u0026#34;selectAuthors\u0026#34;,\u0026#34;id\u0026#34;) 返回 Map[Integer,Author] \u0026lt;K, V\u0026gt; Map\u0026lt;K, V\u0026gt; selectMap(String statement, String mapKey); // Cursor 提供与 List 相同的结果，除了它使用 Iterator 延迟获取数据。 \u0026lt;T\u0026gt; Cursor\u0026lt;T\u0026gt; selectCursor(String statement); // 使用ResultHandler检索从语句键和参数映射的ResultHandler 。 void select(String statement, Object parameter, ResultHandler handler); // 执行插入语句。 int insert(String statement); // 执行更新语句。 将返回受影响的行数。 int update(String statement); // 执行删除语句。 将返回受影响的行数 int delete(String statement); // 刷新批处理语句并提交数据库连接。 请注意，如果没有调用更新/删除/插入，则不会提交数据库连接。 强制提交调用commit(boolean) void commit(); // 丢弃挂起的批处理语句并回滚数据库连接。 请注意，如果没有调用更新/删除/插入，则不会回滚数据库连接。 强制回滚调用rollback(boolean) void rollback(); // 清除本地会话缓存 void clearCache(); // 检索内部数据库连接 Connection getConnection(); 3.3.4 封装返回值 DefaultResultSetHandler#handleResultSets\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 @Override public List\u0026lt;Object\u0026gt; handleResultSets(Statement stmt) throws SQLException { ErrorContext.instance().activity(\u0026#34;handling results\u0026#34;).object(mappedStatement.getId()); //resultMap可以通过多个标签指定多个值，所以存在多个结果集 final List\u0026lt;Object\u0026gt; multipleResults = new ArrayList\u0026lt;Object\u0026gt;(); int resultSetCount = 0; //拿到当前第一个结果集 ResultSetWrapper rsw = getFirstResultSet(stmt); // 拿到所有的resultMap List\u0026lt;ResultMap\u0026gt; resultMaps = mappedStatement.getResultMaps(); //resultMap的数量 int resultMapCount = resultMaps.size(); validateResultMapsCount(rsw, resultMapCount); //循环处理每一个结果集 while (rsw != null \u0026amp;\u0026amp; resultMapCount \u0026gt; resultSetCount) { //开始封装结果集 list.get(index) 获取结果集 ResultMap resultMap = resultMaps.get(resultSetCount); // 传入resultMap处理结果集 rsw 当前结果集 handleResultSet(rsw, resultMap, multipleResults, null); rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; } String[] resultSets = mappedStatement.getResultSets(); if (resultSets != null) { while (rsw != null \u0026amp;\u0026amp; resultSetCount \u0026lt; resultSets.length) { ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]); if (parentMapping != null) { String nestedResultMapId = parentMapping.getNestedResultMapId(); ResultMap resultMap = configuration.getResultMap(nestedResultMapId); handleResultSet(rsw, resultMap, null, parentMapping); } rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; } } return collapseSingleResultList(multipleResults); } private void handleResultSet(ResultSetWrapper rsw, ResultMap resultMap, List\u0026lt;Object\u0026gt; multipleResults, ResultMapping parentMapping) throws SQLException { try { if (parentMapping != null) { handleRowValues(rsw, resultMap, null, RowBounds.DEFAULT, parentMapping); } else { if (resultHandler == null) { DefaultResultHandler defaultResultHandler = new DefaultResultHandler(objectFactory); // 处理行数据 handleRowValues(rsw, resultMap, defaultResultHandler, rowBounds, null); multipleResults.add(defaultResultHandler.getResultList()); } else { handleRowValues(rsw, resultMap, resultHandler, rowBounds, null); } } } finally { // issue #228 (close resultsets) closeResultSet(rsw.getResultSet()); } } public void handleRowValues(ResultSetWrapper rsw, ResultMap resultMap, ResultHandler\u0026lt;?\u0026gt; resultHandler, RowBounds rowBounds, ResultMapping parentMapping) throws SQLException { if (resultMap.hasNestedResultMaps()) { //存在内嵌的结果集 ensureNoRowBounds(); checkResultHandler(); handleRowValuesForNestedResultMap(rsw, resultMap, resultHandler, rowBounds, parentMapping); } else { // 不存在内嵌的结果集 handleRowValuesForSimpleResultMap(rsw, resultMap, resultHandler, rowBounds, parentMapping); } } private void handleRowValuesForSimpleResultMap(ResultSetWrapper rsw, ResultMap resultMap, ResultHandler\u0026lt;?\u0026gt; resultHandler, RowBounds rowBounds, ResultMapping parentMapping) throws SQLException { DefaultResultContext\u0026lt;Object\u0026gt; resultContext = new DefaultResultContext\u0026lt;Object\u0026gt;(); skipRows(rsw.getResultSet(), rowBounds); while (shouldProcessMoreRows(resultContext, rowBounds) \u0026amp;\u0026amp; rsw.getResultSet().next()) { //遍历结果集 ResultMap discriminatedResultMap = resolveDiscriminatedResultMap(rsw.getResultSet(), resultMap, null); //拿到行数据，将行数据包装成一个Object Object rowValue = getRowValue(rsw, discriminatedResultMap); storeObject(resultHandler, resultContext, rowValue, parentMapping, rsw.getResultSet()); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 private Object getRowValue(ResultSetWrapper rsw, ResultMap resultMap) throws SQLException { final ResultLoaderMap lazyLoader = new ResultLoaderMap(); //创建一个空对象装行数据 Object rowValue = createResultObject(rsw, resultMap, lazyLoader, null); if (rowValue != null \u0026amp;\u0026amp; !hasTypeHandlerForResultObject(rsw, resultMap.getType())) { // 通过反射操作返回值 final MetaObject metaObject = configuration.newMetaObject(rowValue); boolean foundValues = this.useConstructorMappings; // 是否使用自动装配，自动装配就是没显示配置resultMap if (shouldApplyAutomaticMappings(resultMap, false)) { foundValues = applyAutomaticMappings(rsw, resultMap, metaObject, null) || foundValues; } foundValues = applyPropertyMappings(rsw, resultMap, metaObject, lazyLoader, null) || foundValues; foundValues = lazyLoader.size() \u0026gt; 0 || foundValues; rowValue = foundValues || configuration.isReturnInstanceForEmptyRow() ? rowValue : null; } return rowValue; } private boolean applyAutomaticMappings(ResultSetWrapper rsw, ResultMap resultMap, MetaObject metaObject, String columnPrefix) throws SQLException { List\u0026lt;UnMappedColumnAutoMapping\u0026gt; autoMapping = createAutomaticMappings(rsw, resultMap, metaObject, columnPrefix); boolean foundValues = false; if (!autoMapping.isEmpty()) { for (UnMappedColumnAutoMapping mapping : autoMapping) { // 通过类型处理器获取返回结果 final Object value = mapping.typeHandler.getResult(rsw.getResultSet(), mapping.column); if (value != null) { foundValues = true; } if (value != null || (configuration.isCallSettersOnNulls() \u0026amp;\u0026amp; !mapping.primitive)) { // gcode issue #377, call setter on nulls (value is not \u0026#39;found\u0026#39;) // 在这里赋值 metaObject.setValue(mapping.property, value); } } } return foundValues; } 在赋值的时候，因为我们的返回类型可以是bean，也可以是map,处理时需要兼顾两种情况\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public void setValue(String name, Object value) { PropertyTokenizer prop = new PropertyTokenizer(name); if (prop.hasNext()) { MetaObject metaValue = metaObjectForProperty(prop.getIndexedName()); if (metaValue == SystemMetaObject.NULL_META_OBJECT) { if (value == null \u0026amp;\u0026amp; prop.getChildren() != null) { // don\u0026#39;t instantiate child path if value is null return; } else { // 最终都会调用objectWrapper.set方法 metaValue = objectWrapper.instantiatePropertyValue(name, prop, objectFactory); } } metaValue.setValue(prop.getChildren(), value); } else { // 如果返回的是map就调用MapWrapper的set方法，如果是Bean就调用BeanWrapper的set方法 objectWrapper.set(prop, value); } } ​\t四、整合springboot 4.1 引入配置类 springboot会找寻 MATE-INF里面的spring.factories里面的autoConfig\n1 2 3 # Auto Configure org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration MybatisAutoConfiguration\n会装配SqlSessionFactory，SqlSessionTemplate\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 @Configuration @ConditionalOnClass({SqlSessionFactory.class, SqlSessionFactoryBean.class}) @ConditionalOnBean({DataSource.class}) @EnableConfigurationProperties({MybatisProperties.class}) @AutoConfigureAfter({DataSourceAutoConfiguration.class}) public class MybatisAutoConfiguration { private static final Logger logger = LoggerFactory.getLogger(MybatisAutoConfiguration.class); private final MybatisProperties properties; private final Interceptor[] interceptors; private final ResourceLoader resourceLoader; private final DatabaseIdProvider databaseIdProvider; private final List\u0026lt;ConfigurationCustomizer\u0026gt; configurationCustomizers; public MybatisAutoConfiguration(MybatisProperties properties, ObjectProvider\u0026lt;Interceptor[]\u0026gt; interceptorsProvider, ResourceLoader resourceLoader, ObjectProvider\u0026lt;DatabaseIdProvider\u0026gt; databaseIdProvider, ObjectProvider\u0026lt;List\u0026lt;ConfigurationCustomizer\u0026gt;\u0026gt; configurationCustomizersProvider) { this.properties = properties; this.interceptors = (Interceptor[])interceptorsProvider.getIfAvailable(); this.resourceLoader = resourceLoader; this.databaseIdProvider = (DatabaseIdProvider)databaseIdProvider.getIfAvailable(); this.configurationCustomizers = (List)configurationCustomizersProvider.getIfAvailable(); } @Bean @ConditionalOnMissingBean public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception { SqlSessionFactoryBean factory = new SqlSessionFactoryBean(); factory.setDataSource(dataSource); factory.setVfs(SpringBootVFS.class); if (StringUtils.hasText(this.properties.getConfigLocation())) { factory.setConfigLocation(this.resourceLoader.getResource(this.properties.getConfigLocation())); } org.apache.ibatis.session.Configuration configuration = this.properties.getConfiguration(); if (configuration == null \u0026amp;\u0026amp; !StringUtils.hasText(this.properties.getConfigLocation())) { configuration = new org.apache.ibatis.session.Configuration(); } if (configuration != null \u0026amp;\u0026amp; !CollectionUtils.isEmpty(this.configurationCustomizers)) { Iterator var4 = this.configurationCustomizers.iterator(); while(var4.hasNext()) { ConfigurationCustomizer customizer = (ConfigurationCustomizer)var4.next(); customizer.customize(configuration); } } factory.setConfiguration(configuration); if (this.properties.getConfigurationProperties() != null) { factory.setConfigurationProperties(this.properties.getConfigurationProperties()); } if (!ObjectUtils.isEmpty(this.interceptors)) { factory.setPlugins(this.interceptors); } if (this.databaseIdProvider != null) { factory.setDatabaseIdProvider(this.databaseIdProvider); } if (StringUtils.hasLength(this.properties.getTypeAliasesPackage())) { factory.setTypeAliasesPackage(this.properties.getTypeAliasesPackage()); } if (StringUtils.hasLength(this.properties.getTypeHandlersPackage())) { factory.setTypeHandlersPackage(this.properties.getTypeHandlersPackage()); } if (!ObjectUtils.isEmpty(this.properties.resolveMapperLocations())) { factory.setMapperLocations(this.properties.resolveMapperLocations()); } return factory.getObject(); } @Bean @ConditionalOnMissingBean public SqlSessionTemplate sqlSessionTemplate(SqlSessionFactory sqlSessionFactory) { ExecutorType executorType = this.properties.getExecutorType(); return executorType != null ? new SqlSessionTemplate(sqlSessionFactory, executorType) : new SqlSessionTemplate(sqlSessionFactory); } 4.2 @MapperScan @mapperScan将Mapper类加入到容器中\n1 2 3 4 5 6 @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) @Documented @Import(MapperScannerRegistrar.class) public @interface MapperScan { } 引入MapperScannerRegistrar 类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 // 实现ImportBeanDefinitionRegistrar接口 public class MapperScannerRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware { private ResourceLoader resourceLoader; /** * {@inheritDoc} */ @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { // 获取MapperScan 注解 AnnotationAttributes annoAttrs = AnnotationAttributes.fromMap(importingClassMetadata.getAnnotationAttributes(MapperScan.class.getName())); ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); // this check is needed in Spring 3.1 if (resourceLoader != null) { scanner.setResourceLoader(resourceLoader); } // 解析MapperScan注解里面的参数，最终获取所有要扫描的包 Class\u0026lt;? extends Annotation\u0026gt; annotationClass = annoAttrs.getClass(\u0026#34;annotationClass\u0026#34;); if (!Annotation.class.equals(annotationClass)) { scanner.setAnnotationClass(annotationClass); } Class\u0026lt;?\u0026gt; markerInterface = annoAttrs.getClass(\u0026#34;markerInterface\u0026#34;); if (!Class.class.equals(markerInterface)) { scanner.setMarkerInterface(markerInterface); } Class\u0026lt;? extends BeanNameGenerator\u0026gt; generatorClass = annoAttrs.getClass(\u0026#34;nameGenerator\u0026#34;); if (!BeanNameGenerator.class.equals(generatorClass)) { scanner.setBeanNameGenerator(BeanUtils.instantiateClass(generatorClass)); } Class\u0026lt;? extends MapperFactoryBean\u0026gt; mapperFactoryBeanClass = annoAttrs.getClass(\u0026#34;factoryBean\u0026#34;); if (!MapperFactoryBean.class.equals(mapperFactoryBeanClass)) { scanner.setMapperFactoryBean(BeanUtils.instantiateClass(mapperFactoryBeanClass)); } scanner.setSqlSessionTemplateBeanName(annoAttrs.getString(\u0026#34;sqlSessionTemplateRef\u0026#34;)); scanner.setSqlSessionFactoryBeanName(annoAttrs.getString(\u0026#34;sqlSessionFactoryRef\u0026#34;)); List\u0026lt;String\u0026gt; basePackages = new ArrayList\u0026lt;String\u0026gt;(); for (String pkg : annoAttrs.getStringArray(\u0026#34;value\u0026#34;)) { if (StringUtils.hasText(pkg)) { basePackages.add(pkg); } } for (String pkg : annoAttrs.getStringArray(\u0026#34;basePackages\u0026#34;)) { if (StringUtils.hasText(pkg)) { basePackages.add(pkg); } } for (Class\u0026lt;?\u0026gt; clazz : annoAttrs.getClassArray(\u0026#34;basePackageClasses\u0026#34;)) { basePackages.add(ClassUtils.getPackageName(clazz)); } // 过滤 scanner.registerFilters(); // 对MapperScan 定义的basePackages进行扫描 scanner.doScan(StringUtils.toStringArray(basePackages)); } 1 2 3 4 5 6 7 8 9 10 11 12 13 public Set\u0026lt;BeanDefinitionHolder\u0026gt; doScan(String... basePackages) { // 调用将搜索并注册所有候选人的父搜索。 Set\u0026lt;BeanDefinitionHolder\u0026gt; beanDefinitions = super.doScan(basePackages); if (beanDefinitions.isEmpty()) { logger.warn(\u0026#34;No MyBatis mapper was found in \u0026#39;\u0026#34; + Arrays.toString(basePackages) + \u0026#34;\u0026#39; package. Please check your configuration.\u0026#34;); } else { // 然后对注册的对象进行后处理以将它们设置为 MapperFactoryBeans processBeanDefinitions(beanDefinitions); } return beanDefinitions; } ClassPathBeanDefinitionScanner#doScan\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 protected Set\u0026lt;BeanDefinitionHolder\u0026gt; doScan(String... basePackages) { Assert.notEmpty(basePackages, \u0026#34;At least one base package must be specified\u0026#34;); Set\u0026lt;BeanDefinitionHolder\u0026gt; beanDefinitions = new LinkedHashSet\u0026lt;\u0026gt;(); // 遍历包 for (String basePackage : basePackages) { // 获取包下类定义 Set\u0026lt;BeanDefinition\u0026gt; candidates = findCandidateComponents(basePackage); for (BeanDefinition candidate : candidates) { ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate); candidate.setScope(scopeMetadata.getScopeName()); String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry); if (candidate instanceof AbstractBeanDefinition) { // 根据bean类型来设置属性 postProcessBeanDefinition((AbstractBeanDefinition) candidate, beanName); } if (candidate instanceof AnnotatedBeanDefinition) { AnnotationConfigUtils.processCommonDefinitionAnnotations((AnnotatedBeanDefinition) candidate); } if (checkCandidate(beanName, candidate)) { // 创建BeanDefinitionHolder BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName); definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); beanDefinitions.add(definitionHolder); // 注册 registerBeanDefinition(definitionHolder, this.registry); } } } return beanDefinitions; } 将接口的注册成BeanDefinitionHolder，但是这个BeanDefinition肯定不能实例化啦，\n之后就后置处理BeanDefinitionHolder\nprocessBeanDefinitions\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 private void processBeanDefinitions(Set\u0026lt;BeanDefinitionHolder\u0026gt; beanDefinitions) { GenericBeanDefinition definition; for (BeanDefinitionHolder holder : beanDefinitions) { definition = (GenericBeanDefinition) holder.getBeanDefinition(); if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Creating MapperFactoryBean with name \u0026#39;\u0026#34; + holder.getBeanName() + \u0026#34;\u0026#39; and \u0026#39;\u0026#34; + definition.getBeanClassName() + \u0026#34;\u0026#39; mapperInterface\u0026#34;); } // the mapper interface is the original class of the bean // but, the actual class of the bean is MapperFactoryBean definition.getConstructorArgumentValues().addGenericArgumentValue(definition.getBeanClassName()); // issue #59 // 设置类型为mapperFactoryBean definition.setBeanClass(this.mapperFactoryBean.getClass()); definition.getPropertyValues().add(\u0026#34;addToConfig\u0026#34;, this.addToConfig); boolean explicitFactoryUsed = false; if (StringUtils.hasText(this.sqlSessionFactoryBeanName)) { definition.getPropertyValues().add(\u0026#34;sqlSessionFactory\u0026#34;, new RuntimeBeanReference(this.sqlSessionFactoryBeanName)); explicitFactoryUsed = true; } else if (this.sqlSessionFactory != null) { definition.getPropertyValues().add(\u0026#34;sqlSessionFactory\u0026#34;, this.sqlSessionFactory); explicitFactoryUsed = true; } if (StringUtils.hasText(this.sqlSessionTemplateBeanName)) { if (explicitFactoryUsed) { logger.warn(\u0026#34;Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored.\u0026#34;); } definition.getPropertyValues().add(\u0026#34;sqlSessionTemplate\u0026#34;, new RuntimeBeanReference(this.sqlSessionTemplateBeanName)); explicitFactoryUsed = true; } else if (this.sqlSessionTemplate != null) { if (explicitFactoryUsed) { logger.warn(\u0026#34;Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored.\u0026#34;); } definition.getPropertyValues().add(\u0026#34;sqlSessionTemplate\u0026#34;, this.sqlSessionTemplate); explicitFactoryUsed = true; } if (!explicitFactoryUsed) { if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Enabling autowire by type for MapperFactoryBean with name \u0026#39;\u0026#34; + holder.getBeanName() + \u0026#34;\u0026#39;.\u0026#34;); } definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE); } } } 4.3 MapperFactoryBean 包扫描之后，已经将MapperFactoryBean 注册到容器内。\nMapperFactoryBean是DaoSupport 的子类，DaoSupport 实现InitializingBean，checkDaoConfig（）会在执行InitializingBean#afterPropertiesSet中调用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class MapperFactoryBean\u0026lt;T\u0026gt; extends SqlSessionDaoSupport implements FactoryBean\u0026lt;T\u0026gt; { @Override protected void checkDaoConfig() { super.checkDaoConfig(); notNull(this.mapperInterface, \u0026#34;Property \u0026#39;mapperInterface\u0026#39; is required\u0026#34;); Configuration configuration = getSqlSession().getConfiguration(); if (this.addToConfig \u0026amp;\u0026amp; !configuration.hasMapper(this.mapperInterface)) { try { // 将mapper加入到configuration中 configuration.addMapper(this.mapperInterface); } catch (Exception e) { logger.error(\u0026#34;Error while adding the mapper \u0026#39;\u0026#34; + this.mapperInterface + \u0026#34;\u0026#39; to configuration.\u0026#34;, e); throw new IllegalArgumentException(e); } finally { ErrorContext.instance().reset(); } } } } ","date":"2022-12-04T23:50:55+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mybatis/mybatis%E6%89%A7%E8%A1%8C/","title":"Mybatis执行"},{"content":"MyBatis 的配置文件包含了会深深影响 MyBatis 行为的设置和属性信息。 配置文档的顶层结构如下：\nconfiguration（配置） properties（属性） settings（设置） typeAliases（类型别名） typeHandlers（类型处理器） objectFactory（对象工厂） plugins（插件） environments（环境配置） environment（环境变量） transactionManager（事务管理器） dataSource（数据源） databaseIdProvider（数据库厂商标识） mappers（映射器） 属性（properties） 作用： 将一些常见的参数整理处理，方便管理\n**这些属性可以在外部进行配置，并可以进行动态替换。**你既可以在典型的 Java 属性文件中配置这些属性，也可以在 properties 元素的子元素中设置。\n怎么用： 1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;!---定义---\u0026gt; \u0026lt;properties resource=\u0026#34;org/mybatis/example/config.properties\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;dev_user\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;F2Fa3!33TYyg\u0026#34;/\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;!---使用---\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;${driver}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;${url}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;${username}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;${password}\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; 也可以在java构造代码中传入属性值\n1 2 3 4 5 SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader, props); // ... 或者 ... SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader, environment, props); 顺序加载 首先读取在 properties 元素体内指定的属性。\n然后根据 properties 元素中的 resource 属性读取类路径下属性文件，或根据 url 属性指定的路径读取属性文件，并覆盖之前读取过的同名属性。\n最后读取作为方法参数传递的属性，并覆盖之前读取过的同名属性。\n默认值 从 MyBatis 3.4.2 开始，你可以为占位符指定一个默认值。\n1 2 3 4 5 6 7 8 9 10 \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;!-- ... --\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;${username:ut_user}\u0026#34;/\u0026gt; \u0026lt;!-- 如果属性 \u0026#39;username\u0026#39; 没有被配置，\u0026#39;username\u0026#39; 属性的值将为 \u0026#39;ut_user\u0026#39; --\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;!-- 开启默认值 --\u0026gt; \u0026lt;properties resource=\u0026#34;org/mybatis/example/config.properties\u0026#34;\u0026gt; \u0026lt;!-- ... --\u0026gt; \u0026lt;property name=\u0026#34;org.apache.ibatis.parsing.PropertyParser.enable-default-value\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;!-- 启用默认值特性 --\u0026gt; \u0026lt;/properties\u0026gt; 设置（settings） 作用 它们会改变 MyBatis 的运行时行为。\n设置名 描述 有效值 默认值 cacheEnabled 全局性地开启或关闭所有映射器配置文件中已配置的任何缓存。 true | false true lazyLoadingEnabled 延迟加载的全局开关。当开启时，所有关联对象都会延迟加载。 特定关联关系中可通过设置 fetchType 属性来覆盖该项的开关状态。 true | false false aggressiveLazyLoading 开启时，任一方法的调用都会加载该对象的所有延迟加载属性。 否则，每个延迟加载属性会按需加载（参考 lazyLoadTriggerMethods)。 true | false false （在 3.4.1 及之前的版本中默认为 true） multipleResultSetsEnabled 是否允许单个语句返回多结果集（需要数据库驱动支持）。 true | false true useGeneratedKeys 允许 JDBC 支持自动生成主键，需要数据库驱动支持。如果设置为 true，将强制使用自动生成主键。尽管一些数据库驱动不支持此特性，但仍可正常工作（如 Derby）。 true | false False autoMappingBehavior 指定 MyBatis 应如何自动映射列到字段或属性。 NONE 表示关闭自动映射；PARTIAL 只会自动映射没有定义嵌套结果映射的字段。 FULL 会自动映射任何复杂的结果集（无论是否嵌套）。 NONE, PARTIAL, FULL PARTIAL defaultExecutorType 配置默认的执行器。SIMPLE 就是普通的执行器；REUSE 执行器会重用预处理语句（PreparedStatement）； BATCH 执行器不仅重用语句还会执行批量更新。 SIMPLE REUSE BATCH SIMPLE defaultStatementTimeout 设置超时时间，它决定数据库驱动等待数据库响应的秒数。 任意正整数 未设置 (null) mapUnderscoreToCamelCase 是否开启驼峰命名自动映射，即从经典数据库列名 A_COLUMN 映射到经典 Java 属性名 aColumn。 true | false False localCacheScope MyBatis 利用本地缓存机制（Local Cache）防止循环引用和加速重复的嵌套查询。 默认值为 SESSION，会缓存一个会话中执行的所有查询。 若设置值为 STATEMENT，本地缓存将仅用于执行语句，对相同 SqlSession 的不同查询将不会进行缓存。 SESSION | STATEMENT SESSION returnInstanceForEmptyRow 当返回行的所有列都是空时，MyBatis默认返回 null。 当开启这个设置时，MyBatis会返回一个空实例。 请注意，它也适用于嵌套的结果集（如集合或关联）。（新增于 3.4.2） true | false false logPrefix 指定 MyBatis 增加到日志名称的前缀。 任何字符串 未设置 logImpl 指定 MyBatis 所用日志的具体实现，未指定时将自动查找。 SLF4J | LOG4J | LOG4J2 | JDK_LOGGING | COMMONS_LOGGING | STDOUT_LOGGING | NO_LOGGING 未设置 configurationFactory 指定一个提供 Configuration 实例的类。 这个被返回的 Configuration 实例用来加载被反序列化对象的延迟加载属性值。 这个类必须包含一个签名为static Configuration getConfiguration() 的方法。（新增于 3.2.3） 一个类型别名或完全限定类名。 未设置 shrinkWhitespacesInSql 从SQL中删除多余的空格字符。请注意，这也会影响SQL中的文字字符串。 (新增于 3.5.5) true | false false 类型别名（typeAliases） 作用 类型别名可为 Java 类型设置一个缩写名字。 它仅用于 XML 配置，意在降低冗余的全限定类名书写。\n1 2 3 4 5 6 7 8 \u0026lt;typeAliases\u0026gt; \u0026lt;typeAlias alias=\u0026#34;Author\u0026#34; type=\u0026#34;domain.blog.Author\u0026#34;/\u0026gt; \u0026lt;typeAlias alias=\u0026#34;Blog\u0026#34; type=\u0026#34;domain.blog.Blog\u0026#34;/\u0026gt; \u0026lt;typeAlias alias=\u0026#34;Comment\u0026#34; type=\u0026#34;domain.blog.Comment\u0026#34;/\u0026gt; \u0026lt;typeAlias alias=\u0026#34;Post\u0026#34; type=\u0026#34;domain.blog.Post\u0026#34;/\u0026gt; \u0026lt;typeAlias alias=\u0026#34;Section\u0026#34; type=\u0026#34;domain.blog.Section\u0026#34;/\u0026gt; \u0026lt;typeAlias alias=\u0026#34;Tag\u0026#34; type=\u0026#34;domain.blog.Tag\u0026#34;/\u0026gt; \u0026lt;/typeAliases\u0026gt; 如果在包内有相同的使用规则，可以指定包名\n1 2 3 4 5 6 7 8 9 10 \u0026lt;typeAliases\u0026gt; \u0026lt;package name=\u0026#34;domain.blog\u0026#34;/\u0026gt; \u0026lt;/typeAliases\u0026gt; 每一个在包 domain.blog 中的 Java Bean，在没有注解的情况下，会使用 Bean 的首字母小写的非限定类名来作为它的别名。 @Alias(\u0026#34;author\u0026#34;) public class Author { ... } 类型处理器（typeHandlers） 作用 **MyBatis 在设置预处理语句（PreparedStatement）中的参数或从结果集中取出一个值时， 都会用类型处理器将获取到的值以合适的方式转换成 Java 类型。**指明如何转换成Java对象。\n使用 你可以重写已有的类型处理器或创建你自己的类型处理器来处理不支持的或非标准的类型。 具体做法为：实现 org.apache.ibatis.type.TypeHandler 接口， 或继承一个很便利的类 org.apache.ibatis.type.BaseTypeHandler， 并且可以（可选地）将它映射到一个 JDBC 类型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // ExampleTypeHandler.java @MappedJdbcTypes(JdbcType.VARCHAR) public class ExampleTypeHandler extends BaseTypeHandler\u0026lt;String\u0026gt; { @Override public void setNonNullParameter(PreparedStatement ps, int i, String parameter, JdbcType jdbcType) throws SQLException { ps.setString(i, parameter); } @Override public String getNullableResult(ResultSet rs, String columnName) throws SQLException { return rs.getString(columnName); } @Override public String getNullableResult(ResultSet rs, int columnIndex) throws SQLException { return rs.getString(columnIndex); } @Override public String getNullableResult(CallableStatement cs, int columnIndex) throws SQLException { return cs.getString(columnIndex); } } 1 2 3 4 \u0026lt;!-- mybatis-config.xml --\u0026gt; \u0026lt;typeHandlers\u0026gt; \u0026lt;typeHandler handler=\u0026#34;org.mybatis.example.ExampleTypeHandler\u0026#34;/\u0026gt; \u0026lt;/typeHandlers\u0026gt; 使用上述的类型处理器将会覆盖已有的处理 Java String 类型的属性以及 VARCHAR 类型的参数和结果的类型处理器。 要注意 MyBatis 不会通过检测数据库元信息来决定使用哪种类型，所以你必须在参数和结果映射中指明字段是 VARCHAR 类型， 以使其能够绑定到正确的类型处理器上。这是因为 MyBatis 直到语句被执行时才清楚数据类型。\n通过类型处理器的泛型，MyBatis 可以得知该类型处理器处理的 Java 类型，不过这种行为可以通过两种方法改变：\n在xml配置文件中通过 类型处理器的配置元素（typeHandler 元素）上增加一个 javaType 属性（比如：javaType=\u0026quot;String\u0026quot;）； 在类型处理器的类上增加一个 @MappedTypes 注解指定与其关联的 Java 类型列表。 如果在 javaType 属性中也同时指定，则注解上的配置将被忽略。 可以通过两种方式来指定关联的 JDBC 类型：\n在xml配置文件中通过 类型处理器的配置元素上增加一个 jdbcType 属性（比如：jdbcType=\u0026quot;VARCHAR\u0026quot;）；\n在类型处理器的类上增加一个 @MappedJdbcTypes 注解指定与其关联的 JDBC 类型列表。 如果在 jdbcType 属性中也同时指定，则注解上的配置将被忽略。\n1 当在 ResultMap 中决定使用哪种类型处理器时，此时 Java 类型是已知的（从结果类型中获得），但是 JDBC 类型是未知的。 因此 Mybatis 使用 javaType=[Java 类型], jdbcType=null 的组合来选择一个类型处理器。 这意味着使用 @MappedJdbcTypes 注解可以限制类型处理器的作用范围，并且可以确保，除非显式地设置，否则类型处理器在 ResultMap 中将不会生效。 如果希望能在 ResultMap 中隐式地使用类型处理器，那么设置 @MappedJdbcTypes 注解的 includeNullJdbcType=true 即可。 然而从 Mybatis 3.4.0 开始，如果某个 Java 类型只有一个注册的类型处理器，即使没有设置 includeNullJdbcType=true，那么这个类型处理器也会是 ResultMap 使用 Java 类型时的默认处理器。 也可以一个类型处理器来处理多个java类型\n为了使用泛型类型处理器， 需要增加一个接受该类的 class 作为参数的构造器，这样 MyBatis 会在构造一个类型处理器实例的时候传入一个具体的类。\n1 2 3 4 5 6 7 8 9 //GenericTypeHandler.java public class GenericTypeHandler\u0026lt;E extends MyObject\u0026gt; extends BaseTypeHandler\u0026lt;E\u0026gt; { private Class\u0026lt;E\u0026gt; type; public GenericTypeHandler(Class\u0026lt;E\u0026gt; type) { if (type == null) throw new IllegalArgumentException(\u0026#34;Type argument cannot be null\u0026#34;); this.type = type; } 对象工厂（objectFactory） 作用 每次 MyBatis 创建结果对象的新实例时，它都会使用一个对象工厂（ObjectFactory）实例来完成实例化工作。 默认的对象工厂需要做的仅仅是实例化目标类，要么通过默认无参构造方法，要么通过存在的参数映射来调用带有参数的构造方法。 如果想覆盖对象工厂的默认行为，可以通过创建自己的对象工厂来实现。用于定制构造对象的方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // ExampleObjectFactory.java public class ExampleObjectFactory extends DefaultObjectFactory { public Object create(Class type) { return super.create(type); } public Object create(Class type, List\u0026lt;Class\u0026gt; constructorArgTypes, List\u0026lt;Object\u0026gt; constructorArgs) { return super.create(type, constructorArgTypes, constructorArgs); } public void setProperties(Properties properties) { super.setProperties(properties); } public \u0026lt;T\u0026gt; boolean isCollection(Class\u0026lt;T\u0026gt; type) { return Collection.class.isAssignableFrom(type); }} 使用 \u0026lt;!-- mybatis-config.xml --\u0026gt; \u0026lt;objectFactory type=\u0026#34;org.mybatis.example.ExampleObjectFactory\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;someProperty\u0026#34; value=\u0026#34;100\u0026#34;/\u0026gt; \u0026lt;/objectFactory\u0026gt; 插件 作用 MyBatis 允许你在映射语句执行过程中的某一点进行拦截调用。默认情况下，MyBatis 允许使用插件来拦截的方法调用包括\nExecutor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed)\nParameterHandler (getParameterObject, setParameters)\nResultSetHandler (handleResultSets, handleOutputParameters)\nStatementHandler (prepare, parameterize, batch, update, query)\n这里面的方法都可以被拦截\n使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 指明对哪个类哪个接口进行拦截 @Intercepts({@Signature( type= Executor.class, method = \u0026#34;update\u0026#34;, args = {MappedStatement.class,Object.class})}) public class ExamplePlugin implements Interceptor { private Properties properties = new Properties(); public Object intercept(Invocation invocation) throws Throwable { // implement pre processing if need Object returnObject = invocation.proceed(); // implement post processing if need return returnObject; } public void setProperties(Properties properties) { this.properties = properties; } } 1 2 3 4 5 6 \u0026lt;!-- mybatis-config.xml --\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin interceptor=\u0026#34;org.mybatis.example.ExamplePlugin\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;someProperty\u0026#34; value=\u0026#34;100\u0026#34;/\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; 上面的插件将会拦截在 Executor 实例中所有的 “update” 方法调用， 这里的 Executor 是负责执行底层映射语句的内部对象。\n环境配置（environments） 作用 MyBatis 可以配置成适应多种环境，这种机制有助于将 SQL 映射应用于多种数据库之中， 现实情况下有多种理由需要这么做。例如，开发、测试和生产环境需要有不同的配置。管理不同环境使用不同的配置\n尽管可以配置多个环境，但每个 SqlSessionFactory 实例只能选择一种环境。\n每个数据库对应一个 SqlSessionFactory 实例\n在java配置中通过传入参数的类型来选择数据库环境\n1 SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader, environment, properties); 使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;!--使用的默认环境---\u0026gt; \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;!--环境id---\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;!--事务管理器---\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;...\u0026#34; value=\u0026#34;...\u0026#34;/\u0026gt; \u0026lt;/transactionManager\u0026gt; \u0026lt;!--数据源---\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;${driver}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;${url}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;${username}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;${password}\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; 事务管理器(transactionManager） JDBC – 这个配置直接使用了 JDBC 的提交和回滚设施，它依赖从数据源获得的连接来管理事务作用域。\nMANAGED – 这个配置几乎没做什么。它从不提交或回滚一个连接，而是让容器来管理事务的整个生命周期（比如 JEE 应用服务器的上下文）。\n默认情况下它会关闭连接。然而一些容器并不希望连接被关闭，因此需要将 closeConnection 属性设置为 false 来阻止默认的关闭行为\n1 2 3 \u0026lt;transactionManager type=\u0026#34;MANAGED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;closeConnection\u0026#34; value=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;/transactionManager\u0026gt; 正在使用 Spring + MyBatis，则没有必要配置事务管理器，因为 Spring 模块会使用自带的管理器来覆盖前面的配置。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xmlns:aop=\u0026#34;http://www.springframework.org/schema/aop\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;sessionFactory\u0026#34; class=\u0026#34;org.springframework.orm.hibernate3.LocalSessionFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;configLocation\u0026#34; value=\u0026#34;classpath:hibernate.cfg.xml\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;configurationClass\u0026#34; value=\u0026#34;org.hibernate.cfg.AnnotationConfiguration\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- 定义事务管理器（声明式的事务） --\u0026gt; \u0026lt;bean id=\u0026#34;transactionManager\u0026#34; class=\u0026#34;org.springframework.orm.hibernate3.HibernateTransactionManager\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;sessionFactory\u0026#34; ref=\u0026#34;sessionFactory\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- 配置DAO --\u0026gt; \u0026lt;bean id=\u0026#34;userDaoTarget\u0026#34; class=\u0026#34;com.bluesky.spring.dao.UserDaoImpl\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;sessionFactory\u0026#34; ref=\u0026#34;sessionFactory\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;userDao\u0026#34; class=\u0026#34;org.springframework.transaction.interceptor.TransactionProxyFactoryBean\u0026#34;\u0026gt; \u0026lt;!-- 配置事务管理器 --\u0026gt; \u0026lt;property name=\u0026#34;transactionManager\u0026#34; ref=\u0026#34;transactionManager\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;target\u0026#34; ref=\u0026#34;userDaoTarget\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;proxyInterfaces\u0026#34; value=\u0026#34;com.bluesky.spring.dao.GeneratorDao\u0026#34; /\u0026gt; \u0026lt;!-- 配置事务属性 --\u0026gt; \u0026lt;property name=\u0026#34;transactionAttributes\u0026#34;\u0026gt; \u0026lt;props\u0026gt; \u0026lt;prop key=\u0026#34;*\u0026#34;\u0026gt;PROPAGATION_REQUIRED\u0026lt;/prop\u0026gt; \u0026lt;/props\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 数据源（dataSource） dataSource 元素使用标准的 JDBC 数据源接口来配置 JDBC 连接对象的资源。\n大多数 MyBatis 应用程序会按示例中的例子来配置数据源。虽然数据源配置是可选的，但如果要启用延迟加载特性，就必须配置数据源。 有三种内建的数据源类型（也就是 type=\u0026quot;[UNPOOLED|POOLED|JNDI]\u0026quot;）：\nUNPOOLED– 这个数据源的实现会每次请求时打开和关闭连接。虽然有点慢，但对那些数据库连接可用性要求不高的简单应用程序来说，是一个很好的选择。 性能表现则依赖于使用的数据库，对某些数据库来说，使用连接池并不重要，这个配置就很适合这种情形。UNPOOLED 类型的数据源仅仅需要配置以下 5 种属性：\ndriver – 这是 JDBC 驱动的 Java 类全限定名（并不是 JDBC 驱动中可能包含的数据源类）。 url – 这是数据库的 JDBC URL 地址。 username – 登录数据库的用户名。 password – 登录数据库的密码。 defaultTransactionIsolationLevel – 默认的连接事务隔离级别。 defaultNetworkTimeout – 等待数据库操作完成的默认网络超时时间（单位：毫秒）。查看 java.sql.Connection#setNetworkTimeout() 的 API 文档以获取更多信息。 作为可选项，你也可以传递属性给数据库驱动。只需在属性名加上“driver.”前缀即可，例如：\ndriver.encoding=UTF8 这将通过 DriverManager.getConnection(url, driverProperties) 方法传递值为 UTF8 的 encoding 属性给数据库驱动。\nPOOLED– 这种数据源的实现利用“池”的概念将 JDBC 连接对象组织起来，避免了创建新的连接实例时所必需的初始化和认证时间。 这种处理方式很流行，能使并发 Web 应用快速响应请求。\n除了上述提到 UNPOOLED 下的属性外，还有更多属性用来配置 POOLED 的数据源：\npoolMaximumActiveConnections – 在任意时间可存在的活动（正在使用）连接数量，默认值：10 poolMaximumIdleConnections – 任意时间可能存在的空闲连接数。 poolMaximumCheckoutTime – 在被强制返回之前，池中连接被检出（checked out）时间，默认值：20000 毫秒（即 20 秒） poolTimeToWait – 这是一个底层设置，如果获取连接花费了相当长的时间，连接池会打印状态日志并重新尝试获取一个连接（避免在误配置的情况下一直失败且不打印日志），默认值：20000 毫秒（即 20 秒）。 poolMaximumLocalBadConnectionTolerance – 这是一个关于坏连接容忍度的底层设置， 作用于每一个尝试从缓存池获取连接的线程。 如果这个线程获取到的是一个坏的连接，那么这个数据源允许这个线程尝试重新获取一个新的连接，但是这个重新尝试的次数不应该超过 poolMaximumIdleConnections 与 poolMaximumLocalBadConnectionTolerance 之和。 默认值：3（新增于 3.4.5） poolPingQuery – 发送到数据库的侦测查询，用来检验连接是否正常工作并准备接受请求。默认是“NO PING QUERY SET”，这会导致多数数据库驱动出错时返回恰当的错误消息。 poolPingEnabled – 是否启用侦测查询。若开启，需要设置 poolPingQuery 属性为一个可执行的 SQL 语句（最好是一个速度非常快的 SQL 语句），默认值：false。 poolPingConnectionsNotUsedFor – 配置 poolPingQuery 的频率。可以被设置为和数据库连接超时时间一样，来避免不必要的侦测，默认值：0（即所有连接每一时刻都被侦测 — 当然仅当 poolPingEnabled 为 true 时适用）。 JNDI – 这个数据源实现是为了能在如 EJB 或应用服务器这类容器中使用，容器可以集中或在外部配置数据源，然后放置一个 JNDI 上下文的数据源引用。这种数据源配置只需要两个属性：\ninitial_context – 这个属性用来在 InitialContext 中寻找上下文（即，initialContext.lookup(initial_context)）。这是个可选属性，如果忽略，那么将会直接从 InitialContext 中寻找 data_source 属性。 data_source – 这是引用数据源实例位置的上下文路径。提供了 initial_context 配置时会在其返回的上下文中进行查找，没有提供时则直接在 InitialContext 中查找。 和其他数据源配置类似，可以通过添加前缀“env.”直接把属性传递给 InitialContext。比如：\nenv.encoding=UTF8 这就会在 InitialContext 实例化时往它的构造方法传递值为 UTF8 的 encoding 属性。\n映射器（mappers） 找寻映射器的方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u0026lt;!-- 使用相对于类路径的资源引用 --\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper resource=\u0026#34;org/mybatis/builder/AuthorMapper.xml\u0026#34;/\u0026gt; \u0026lt;mapper resource=\u0026#34;org/mybatis/builder/BlogMapper.xml\u0026#34;/\u0026gt; \u0026lt;mapper resource=\u0026#34;org/mybatis/builder/PostMapper.xml\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;!-- 使用完全限定资源定位符（URL） --\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper url=\u0026#34;file:///var/mappers/AuthorMapper.xml\u0026#34;/\u0026gt; \u0026lt;mapper url=\u0026#34;file:///var/mappers/BlogMapper.xml\u0026#34;/\u0026gt; \u0026lt;mapper url=\u0026#34;file:///var/mappers/PostMapper.xml\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;!-- 使用映射器接口实现类的完全限定类名 --\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper class=\u0026#34;org.mybatis.builder.AuthorMapper\u0026#34;/\u0026gt; \u0026lt;mapper class=\u0026#34;org.mybatis.builder.BlogMapper\u0026#34;/\u0026gt; \u0026lt;mapper class=\u0026#34;org.mybatis.builder.PostMapper\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;!-- 将包内的映射器接口实现全部注册为映射器 --\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;package name=\u0026#34;org.mybatis.builder\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; ","date":"2022-12-04T23:50:16+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mybatis/%E9%85%8D%E7%BD%AE/","title":"配置"},{"content":" 所有数据操作都是在内存中,cpu不是短板，短板是机器的内存\n采用单线程处理io，避免频繁的上下文切换\n采用NIO形式处理网络请求，内核不是监视应用程序本身的连接，而是监视应用程序的文件描述符。通过当客户端运行时，它将生成具有不同事件类型的套接字。在服务器端，I / O 多路复用程序（I / O 多路复用模块）会将消息放入队列（也就是 下图的 I/O 多路复用程序的 socket 队列），然后通过文件事件分派器将其转发到不同的事件处理器。\n特殊的数据结构：在数据很少并且容量不大的时候采用特殊的结构\n全局采用hash结构来存储。查询时时间负责度O（1）,\n","date":"2022-12-04T23:49:25+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E9%AB%98%E6%95%88%E5%8E%9F%E5%9B%A0/","title":"高效原因"},{"content":"指令的基本格式是 ：\nCOMMAND KEYNAME\n指令 删除key del key 检查key是否存在 exists key：0-不存在，1-存在 设置key时间:秒为单位 Expire key second 找出符合模式的key keys pattern(keys *set 模糊搜索) 使key保存永久 persist key 返回key剩余时间：以秒为单位 ttl key Key 所处的类型 type key 修改key的名称，当新key不存在时 renamenx key newkey 给key设置value 并设置超时时间(以秒为单位) setex key time value 返回value 的长度 strlen key 返回key 对应的value 旧值，并设置新值 getset key new_value value 自增1 incr key 字符串的字串 getrange key start end 追加到字符串后面 append key value 设置hash一个键值对 hset key filed value 删除has键值对 hdel key filed 查看hash的所有key hkeys key 查看hash的所有value hvals key 批量设置hash多个键值对 hmset key filed1 vaule1 filed2 value2 查看所有hash键值对 hgetall key 查看hash一个键值对 hget key filed hash key的数量 hlen key 查看hash是否存在key hexists key filed 从列表头插入一个 lpush key value1 value2 从列表头弹出一个 lpop key 从列表头弹出一个，没有的话等待一定时间 blpop key time 获取索引下的员工(从0开始计算) lindex key index 获取列表长度 Lien key 获取列表所有元素 lrange key 0 -1 从类列表移除员工 Lrem key count value count\u0026gt; 0 从表头开始搜索，移除count个value,count\u0026lt; 0 从表尾开始搜索，移除count个value,count=0 移除所有 在列表指定位置设置元素(从0开始计算) lset key index value 向集合添加元素 sadd key value 集合元素个数 Scard key 集合移除一个员工到另一个集合 smove soure target member 查询集合所有元素 smembers key 集合差集 sdiff set set1 [仅返回set独有的] 集合交集 sinter set set1 集合并集 Union set set1 是否为集合元素 Sismember key value 随机移除一个集合元素 Spop set ","date":"2022-12-04T23:48:45+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E6%8C%87%E4%BB%A4/","title":"指令"},{"content":"字符串 string是redis最基本的类型，一个key对应一个value。\nstring类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。\nstring类型是Redis最基本的数据类型，一个键最大能存储512MB。\n1 2 3 set name \u0026#39;xaiohuo\u0026#39; get name 哈希 Redis hash 是一个键值对集合。\nRedis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。\n1 2 3 hmset objectname filed filed_value hgetall objectname 每个 hash 可以存储 232 - 1 键值对（40多亿）。\n列表 Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素导列表的头部（左边）或者尾部（右边）。\n1 2 3 4 5 6 7 # 放到左边 lpush queue xiao lpush queue xiaohong # 放到右边 rpush queue hhh 列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)。\n集合 Redis的Set是string类型的无序、不可重复的集合。\n1 2 3 4 # 不存在返回1 sadd set xx # 存在返回0 sadd set xx 集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。\n有序集合 Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。\n不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。\n1 2 3 zadd zset 40 xiali zrangebyscore zset 0 100 ","date":"2022-12-04T23:48:23+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","title":"数据类型"},{"content":"优势 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子 – Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 下载 使用brew 下载，超级简单\n1、先搜索可以下载的 1 brew search redis 2、下载 1 brew install redis 下载的时候提示配置文件位置：/usr/local/etc/redis.conf\n3、启动： brew services start redis 4、关闭：brew services stop redis 5、客户端链接 ","date":"2022-12-04T23:47:33+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85/","title":"下载按照"},{"content":"","date":"2022-12-04T23:46:47+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis/","title":"Redis"},{"content":" 表的字段不要太多，上限20-50\n数据库不做运算\n控制单表数据量 含char 不超过500 w\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 use information_schema; 该库中有一个 TABLES 表，这个表主要字段分别是： TABLE_SCHEMA : 数据库名 TABLE_NAME：表名 ENGINE：所使用的存储引擎 TABLES_ROWS：记录数 DATA_LENGTH：数据大小 INDEX_LENGTH：索引大小 # 查看指定库的大小 select concat(round(sum(DATA_LENGTH/1024/1024),2),\u0026#39;MB\u0026#39;) as data from TABLES where table_schema=\u0026#39;jishi\u0026#39;; # 查看指定库的指定表的大小 select concat(round(sum(DATA_LENGTH/1024/1024),2),\u0026#39;MB\u0026#39;) as data from TABLES where table_schema=\u0026#39;jishi\u0026#39; and table_name=\u0026#39;a_ya\u0026#39;; # 查看指定库的指定表的索引大小 SELECT CONCAT(ROUND(SUM(index_length)/(1024*1024), 2), \u0026#39; MB\u0026#39;) AS \u0026#39;Total Index Size\u0026#39; FROM TABLES WHERE table_schema = \u0026#39;test\u0026#39; and table_name=\u0026#39;a_yuser\u0026#39;; 拒绝3B\n大sql 大事务 大批量 用好数据类型：确定好数据的最大范围，之后定义数据的位数。\n有的只是标志位的话，就可以使用tinyint(1) 来表示\n可以用无符号int 来存储ip\n避免使用null 字段， 数据库表中的列最好设置初始值，或者设置成NOT NULL\n少用text 字段，效率很慢，强制生成临时表，消耗空间。varchar(65535) \u0026gt; 64k\n使用时可以拆分成独立的表\n尽量不使用外键\n字符字段必须建立前缀索引\n忌用字符串做主键\n使用自增字段作为主键\n多sql ,而不是大sql\n事务/连接原则：即开即用，用完即关；多个短事务代替长事务\n尽量不要使用 select * .会查询所有列，之后丢弃不需要的列\n使用union 来代替or\n避免负向查询【NOT LIke】，前缀模糊查询 【%，这个尽量放在查询参数的后半段】：\ncount(*) 开销巨大，能不用就不用\nunion all 来代替 union ， union 有去重,如果不关心有重复的字段时可以使用union all\n不建议进行两个表以上的join\nGroup by NULL无需排序，性能会好一点\n统一使用字符集UTF8 ,校对规则： utf8_general_ci\n索引名称默认 idx_\n","date":"2022-12-04T23:46:15+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/%E8%A7%84%E8%8C%83/","title":"规范"},{"content":"零、文档连接 https://mp.baomidou.com/guide/#%E7%89%B9%E6%80%A7\n一、安装 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 二、配置 1 2 3 4 5 6 7 8 @SpringBootApplication @MapperScan(\u0026#34;com.baomidou.mybatisplus.samples.quickstart.mapper\u0026#34;) public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } ","date":"2022-12-04T23:45:38+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mybatis-plus/","title":"Mybatis Plus"},{"content":"pageHelper是一种分页的插件。\n1 pageHelper将分页数据写入到ThreadLocal中，在后面执行SQL请求的时候，再从ThreadLocal中提取出来，拼凑在SQL里面 一、引入jar 1 2 3 4 5 6 7 \u0026lt;pagehelper.version\u0026gt;1.2.7\u0026lt;/pagehelper.version\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${pagehelper.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 二、编写工具类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 /** * @Author peilizhi * @Date 2021/6/3 19:45 **/ public class PageHelperUtil { /** * 分页查询 * * @param param 分页参数 * @param runnable 分页操作 * @return 查询结果 */ public static \u0026lt;T\u0026gt; Page\u0026lt;T\u0026gt; doPage(PageParam param, Runnable runnable) { return doPage(param.getPageNum(), param.getPageSize(), runnable); } /** * 分页查询 * * @param pageNum 分页当前页数，pageNum\u0026lt;=0为第一页 * @param pageSize 每页条数 * @param runnable 查询操作 * @return 查询结果 */ public static \u0026lt;T\u0026gt; Page\u0026lt;T\u0026gt; doPage(Integer pageNum, Integer pageSize, Runnable runnable) { Page\u0026lt;T\u0026gt; page = PageHelper.startPage(pageNum, pageSize); try { runnable.run(); } finally { PageHelper.clearPage(); } return page; } /** *结构转换 */ public static \u0026lt;T, R\u0026gt; PageDO\u0026lt;R\u0026gt; convertPageModel(Page\u0026lt;T\u0026gt; page, Function\u0026lt;T, R\u0026gt; func) { PageDO\u0026lt;R\u0026gt; pageDo = new PageDO\u0026lt;\u0026gt;(); pageDo.setPageNum(page.getPageNum()); pageDo.setPageSize(page.getPageSize()); pageDo.setTotalCount(page.getTotal()); pageDo.setTotalPages(page.getPages()); pageDo.setResult(page.getResult().stream().map(func).collect(Collectors.toList())); return pageDo; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * @Author peilizhi * @Date 2021/6/3 19:46 * 查询参数的父类，在子类中写查询的条件 **/ @Data public class PageParam { /** * 页数, 从 0 开始算第一页 * * @required */ private int pageNum = 0; /** * 每页大小 * * @required */ private int pageSize = 10; } 1 先设置查询的页码 1 2 3 4 5 6 7 8 9 public List\u0026lt;WindPowerEquipmentActivePO1\u0026gt; windPowerEquipmentActivePOList(Integer pageNo, Integer pageSize) { final Page\u0026lt;WindPowerEquipmentActivePO1\u0026gt; objectPage = PageHelperUtil.doPage(pageNo, pageSize, () -\u0026gt; mapper.selectAll()); System.out.println(\u0026#34;objectPage.getCountColumn() = \u0026#34; + objectPage.getCountColumn()); List\u0026lt;WindPowerEquipmentActivePO1\u0026gt; result = objectPage.getResult(); System.out.println(\u0026#34;objectPage.getResult() = \u0026#34; + result); System.out.println(\u0026#34;objectPage.getPages() = \u0026#34; + objectPage.getPages()); return result; } ","date":"2022-12-04T23:44:58+08:00","permalink":"https://blog.huochai.xyz/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/pagehelper/","title":"PageHelper"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 步骤： 1、确定状态 研究最优策略的最后一步： 定义dp数组。数组中的第i个元素是长度为i的最优解 转化为子问题： 一直dp[i]能否由dp[i-1]获取，并且在什么情况下能够获取到 要考虑前一个值是什么情况的，并且在这个情况下怎么计算当前值 求什么变成求之前到什么 2、确定状态转移方程 由子问题推导出来的 3、确定初始值和边界值 边界值：使数组有意义，并且在最左边或者最右边 初始值一般从零开始。 4、计算顺序（一般都是从左边到右边顺序计算） dp数组的定义也很重要：可以考虑当前i的值表示数据长度为i时的最值情况【一维】 【二维】定义的时候要保持连贯性 最值型动态规划 1 2 我们定义一个 dp 数组，其中第 i 个元素表示以下标为 i 的字符结尾的最长有效子字符串的长度。 定义的数组满足当前下标的值是 这种情况下的最值 例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 我们先看第 i 个位置，这个位置的元素 *s[i]*可能有如下两种情况： s[i] == \u0026#39;(\u0026#39; : 这时，s[i] 无法和其之前的元素组成有效的括号对，所以，dp[i] = 0 s[i] == \u0026#39;)\u0026#39; : 这时，需要看其前面对元素来判断是否有有效括号对。 情况1: s[i - 1] == \u0026#39;(\u0026#39; 即 s[i] 和 s[i - 1] 组成一对有效括号，有效括号长度新增长度2，i位置对最长有效括号长度为 其之前2个位置的最长括号长度加上当前位置新增的2，我们无需知道i-2位置对字符是否可以组成有效括号对。 那么有： dp[i] = dp[i - 2] + 2 2020041743046png 情况2: s[i - 1] == \u0026#39;)\u0026#39; 这种情况下，如果前面有和s[i]组成有效括号对的字符，即形如( (....) )，这样的话，就要求*s[i - 1]位置必然是有效的括号对，否则s[i]*无法和前面对字符组成有效括号对。 这时，我们只需要找到和*s[i]*配对对位置，并判断其是否是 ( 即可。和其配对对位置为：i - dp[i - 1] - 1。 如果：s[i - dp[i - 1] - 1] == \u0026#39;(\u0026#39; : 有效括号长度新增长度2，i位置对最长有效括号长度为 i-1位置的最长括号长度加上当前位置新增的2，那么有： dp[i] = dp[i - 1] + 2 值得注意的是，i - dp[i - 1] - 1 和 i 组成了有效括号对，这将是一段独立的有效括号序列，如果之前的子序列是形如 (...) 这种序列，那么当前位置的最长有效括号长度还需要加上这一段。所以： dp[i] = dp[i - 1] + dp[i - dp[i - 1] - 2] + 2 注： 这个在分析时是很容易遗漏的，分析要更细致。我在第一次分析是就遗漏了，提交后，有用例 )()(()))不过，分析后发现是少了这一段。 2020041742634png 子问题： 根据上面的分析，我们得到了如下两个计算公式： dp[i] = dp[i - 2] + 2 dp[i] = dp[i - 1] + dp[i - dp[i - 1] - 2] + 2 那么，求dp[i]就变成了求dp[i - 1]、 dp[i - 2]、*dp[i - dp[i - 1] - 2]*的子问题。 这样状态也明确了： 设dp 数组，其中第 i 个元素表示以下标为 i 的字符结尾的最长有效子字符串的长度。** 转移方程： 子问题明确后，转移方程直接由子问题得到： if s[i] == \u0026#39;(\u0026#39; : dp[i] = 0 if s[i] == \u0026#39;)\u0026#39; : if s[i - 1] == \u0026#39;(\u0026#39; : dp[i] = dp[i - 2] + 2 #要保证i - 2 \u0026gt;= 0 if s[i - 1] == \u0026#39;)\u0026#39; and s[i - dp[i - 1] - 1] == \u0026#39;(\u0026#39; : dp[i] = dp[i - 1] + dp[i - dp[i - 1] - 2] + 2 #要保证i - dp[i - 1] - 2 \u0026gt;= 0 初始条件和边界情况： 初始条件： dp[i] = 0 边界情况：需要保证计算过程中：i - 2 \u0026gt;= 0 和 i - dp[i - 1] - 2 \u0026gt;= 0 计算顺序： 无论第一个字符是什么，都有：dp[0] = 0 然后依次计算：dp[1], dp[2], ..., dp[n - 1] 结果是： max(dp[i]) ","date":"2022-12-04T23:43:04+08:00","permalink":"https://blog.huochai.xyz/posts/%E7%AE%97%E6%B3%95/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","title":"动态规划"},{"content":"背景 Java API规范(JSR303)定义了Bean校验的标准validation-api，但没有提供实现。hibernate validation是对这个规范的实现，并增加了校验注解如@Email、@Length等。\nSpring Validation是对hibernate validation的二次封装，用于支持spring mvc参数自动校验。接下来，我们以spring-boot项目为例，介绍Spring Validation的使用。\n主要是对http 请求传递过来的参数进行校验，提前暴露问题\n使用 如果spring-boot版本小于2.3.x，spring-boot-starter-web会自动传入hibernate-validator依赖。如果spring-boot版本大于2.3.x，则需要手动引入校验组件依赖：\n1 2 3 4 5 \u0026lt;!--校验组件--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-validation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 注：如果Spring-boot 版本小于2.3.x ,但是手动引入hibernate-validator 版本较大的时候，可能会出现校验无效的情况，\n在Controller层一定要做参数校验的！大部分情况下，请求参数分为如下两种形式：\nPOST、PUT请求，使用requestBody传递参数； GET请求，使用requestParam/PathVariable传递参数。 常用校验注解 原生javax.validation 里面支持的注解\nhibernate-validator 里面支持的校验注解\n校验Body参数 Body参数一般都是个对象，我们可以在对象中通过注解来校验对应的字段\n在对象上添加@Validated 注解\n在对应的属性上根据不同的规则设置不同的注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 /** * 员工对象 * * @author peilizhi * @date 2022/12/6 00:15 **/ @Data public class UserDO { /** * 最大长度32 */ @Length(max = 32, message = \u0026#34;userId最大长度为32位\u0026#34;) private String userId; /** * 不为空 */ @NotNull(message = \u0026#34;name 不能为空\u0026#34;) private String name; @Min(value = 0, message = \u0026#34;年龄最小值为0\u0026#34;) private Integer old; /** * 自定义固定值校验 */ @FixedValueValidator(fixedValue = {\u0026#34;boy\u0026#34;, \u0026#34;girl\u0026#34;}, message = \u0026#34;性别有误\u0026#34;) private String sex; @Length(min = 11, max = 11, message = \u0026#34;手机号只能为11位\u0026#34;) @Pattern(regexp = \u0026#34;^[1][3,4,5,6,7,8,9][0-9]{9}$\u0026#34;, message = \u0026#34;手机号格式有误\u0026#34;) private String phone; @Email(message = \u0026#34;邮箱格式不正确\u0026#34;) private String email; } 自定义校验类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 /** * 固定值校验 * * @author by peilizhi * @date 2022/12/6 00:46 */ @Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER}) @Retention(RUNTIME) @Documented @Constraint(validatedBy = {FixedValueValidator.FixedValueValid.class}) public @interface FixedValueValidator { String message() default \u0026#34;FixedValue\u0026#39;s value is invalid\u0026#34;; Class\u0026lt;?\u0026gt;[] groups() default {}; Class\u0026lt;? extends Payload\u0026gt;[] payload() default {}; String[] fixedValue(); class FixedValueValid implements ConstraintValidator\u0026lt;FixedValueValidator, Object\u0026gt; { String[] fixedValue = null; @Override public void initialize(FixedValueValidator validData) { this.fixedValue = validData.fixedValue(); } /** * 校验值是否在固定值范围里面 * * @param value 待校验的值 */ @Override public boolean isValid(Object value, ConstraintValidatorContext constraintContext) { if (fixedValue == null || fixedValue.length == 0) { return false; } if (value == null) { return true; } boolean flag = false; for (String str : fixedValue) { if (String.valueOf(value).equals(String.valueOf(str))) { flag = true; break; } } return flag; } } } 接口参数上标注校验\n1 2 3 4 5 6 @PostMapping(\u0026#34;insert-user\u0026#34;) public String insertUser( @Validated UserDO userDO) { userDO.setUserId(UUID.randomUUID().toString()); log.info(\u0026#34;user:{}\u0026#34;, JSONUtil.toJsonStr(userDO)); return userDO.getUserId(); } 处理校验失败的情况\n校验失败的时候会抛出 MethodArgumentNotValidException 异常，http 请求返回400（Bad request） 为了更友好的展示校验错误，需要对MethodArgumentNotValidException 异常进行处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 /** * 异常捕获处理类 * * @author peilizhi * @date 2022/12/6 01:37 **/ @RestControllerAdvice public class CommonExceptionHandler { @ExceptionHandler(value = {BindException.class}) @ResponseBody public ModelAndView handleBindException(BindException ex) { BindingResult bindingResult = ex.getBindingResult(); StringBuilder sb = new StringBuilder(\u0026#34;校验失败:\u0026#34;); for (FieldError fieldError : bindingResult.getFieldErrors()) { sb.append(fieldError.getField()).append(\u0026#34;：\u0026#34;).append(fieldError.getDefaultMessage()).append(\u0026#34;, \u0026#34;); } String msg = sb.toString(); MappingJackson2JsonView view = new MappingJackson2JsonView(); Map\u0026lt;String, Object\u0026gt; model = new HashMap\u0026lt;\u0026gt;(8); model.put(\u0026#34;code\u0026#34;, 500); model.put(\u0026#34;message\u0026#34;, msg); model.put(\u0026#34;status\u0026#34;, false); view.setAttributesMap(model); ModelAndView mav = new ModelAndView(); mav.setView(view); return mav; } @ExceptionHandler(value = {MethodArgumentNotValidException.class}) @ResponseBody public ModelAndView handleMethodArgumentNotValidException(MethodArgumentNotValidException ex) { BindingResult bindingResult = ex.getBindingResult(); StringBuilder sb = new StringBuilder(\u0026#34;校验失败:\u0026#34;); for (FieldError fieldError : bindingResult.getFieldErrors()) { sb.append(fieldError.getField()).append(\u0026#34;：\u0026#34;).append(fieldError.getDefaultMessage()).append(\u0026#34;, \u0026#34;); } String msg = sb.toString(); MappingJackson2JsonView view = new MappingJackson2JsonView(); Map\u0026lt;String, Object\u0026gt; model = new HashMap\u0026lt;\u0026gt;(8); model.put(\u0026#34;code\u0026#34;, 500); model.put(\u0026#34;message\u0026#34;, msg); model.put(\u0026#34;status\u0026#34;, false); view.setAttributesMap(model); ModelAndView mav = new ModelAndView(); mav.setView(view); return mav; } @ExceptionHandler({ConstraintViolationException.class}) @ResponseStatus(HttpStatus.OK) @ResponseBody public ModelAndView handleConstraintViolationException(ConstraintViolationException ex) { MappingJackson2JsonView view = new MappingJackson2JsonView(); Map\u0026lt;String, Object\u0026gt; model = new HashMap\u0026lt;\u0026gt;(8); model.put(\u0026#34;code\u0026#34;, 500); model.put(\u0026#34;message\u0026#34;, ex.getMessage()); model.put(\u0026#34;status\u0026#34;, false); view.setAttributesMap(model); ModelAndView mav = new ModelAndView(); mav.setView(view); return mav; } } 注： 在spring-boot 2.3.x 之前返回的异常类是BindException 之后才是ConstraintViolationException、MethodArgumentNotValidException 异常\n校验路径 这种在参数中增加校验注解的话，必须在类上标注@Validated 注解，如果不加的话，注解不起作用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 /** * @author peilizhi * @date 2022/12/6 00:54 **/ @Slf4j @RestController @RequestMapping(\u0026#34;validate\u0026#34;) @Validated public class UserController { @GetMapping(\u0026#34;{userId}\u0026#34;) public String queryUser(@PathVariable(\u0026#34;userId\u0026#34;) @FixedValueValidator(fixedValue = {\u0026#34;11\u0026#34;, \u0026#34;22\u0026#34;})String userId){ return userId; } } 校验参数 这种在参数中增加校验注解的话，必须在类上标注@Validated 注解，如果不加的话，注解不起作用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 /** * @author peilizhi * @date 2022/12/6 00:54 **/ @Slf4j @RestController @RequestMapping(\u0026#34;validate\u0026#34;) @Validated public class UserController { @GetMapping(value = \u0026#34;get-user\u0026#34;) public String getUser(@Length(min = 1,max = 12) String userId) { final String uuid = UUID.randomUUID().toString(); log.info(\u0026#34;user:{}\u0026#34;, JSONUtil.toJsonStr(uuid)); return uuid; } } 分组校验 有的情况下，字段是必须有值的，但是在另一种情况下是不需要有值的，这个时候就不能使用一个注解来处理这种复杂的情节，需要使用分组注解实现。\n需要先定义接口，用来表明分组,接口没有特殊函数，只是声明分组\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 /** * @author peilizhi * @date 2022/12/8 00:33 **/ public interface Update { } /** * @author peilizhi * @date 2022/12/8 00:33 **/ public interface Insert { } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 /** * 员工对象 * * @author peilizhi * @date 2022/12/6 00:15 **/ @Data public class UserDO { /** * 最大长度32 */ @Length(max = 32, message = \u0026#34;userId最大长度为32位\u0026#34;) @NotNull(groups = {Update.class}) private String userId; /** * 不为空 */ @NotNull(message = \u0026#34;name 不能为空\u0026#34;, groups = {Update.class, Insert.class}) private String name; @Min(value = 0, message = \u0026#34;年龄最小值为0\u0026#34;, groups = {Update.class, Insert.class}) private Integer old; /** * 自定义固定值校验 */ @FixedValueValidator(fixedValue = {\u0026#34;boy\u0026#34;, \u0026#34;girl\u0026#34;}, message = \u0026#34;性别有误\u0026#34;, groups = {Update.class, Insert.class}) private String sex; @Length(min = 11, max = 11, message = \u0026#34;手机号只能为11位\u0026#34;) @Pattern(regexp = \u0026#34;^[1][3,4,5,6,7,8,9][0-9]{9}$\u0026#34;, message = \u0026#34;手机号格式有误\u0026#34;) private String phone; @Email(message = \u0026#34;邮箱格式不正确\u0026#34;) private String email; } 在使用的时候需要在@Validated 里面表明使用的哪个分组\n1 2 3 4 5 6 7 8 9 10 11 12 13 @PostMapping(value = \u0026#34;insert-user\u0026#34;) public String insertUser(@RequestBody @Validated(Insert.class) UserDO userDO) { userDO.setUserId(UUID.randomUUID().toString()); log.info(\u0026#34;user:{}\u0026#34;, JSONUtil.toJsonStr(userDO)); return userDO.getUserId(); } @PostMapping(value = \u0026#34;update-user\u0026#34;) public String updateUser(@RequestBody @Validated(Update.class) UserDO userDO) { userDO.setUserId(UUID.randomUUID().toString()); log.info(\u0026#34;user:{}\u0026#34;, JSONUtil.toJsonStr(userDO)); return userDO.getUserId(); } 注：明确指定@Validated里面使用哪个分组的话，没有配置分组的注解就不生效\n嵌套校验 有的时候属性可能不光简单是String ，也有可能是对象形式的话，也是可以通过@Valid 校验对象里面的属性.并且@Valid不能缺少\n在这里可以嵌套集合或者map。集合对象的话就是校验集合中的每一个对象，map的话就是校验map的value\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 /** * 员工对象 * * @author peilizhi * @date 2022/12/6 00:15 **/ @Data public class UserDO { /** * 最大长度32 */ @Length(max = 32, message = \u0026#34;userId最大长度为32位\u0026#34;) @NotNull(groups = {Update.class}) private String userId; /** * 不为空 */ @NotNull(message = \u0026#34;name 不能为空\u0026#34;, groups = {Update.class, Insert.class}) private String name; @Min(value = 0, message = \u0026#34;年龄最小值为0\u0026#34;, groups = {Update.class, Insert.class}) @Max(value = 150, message = \u0026#34;年龄最大150岁\u0026#34;) private Integer old; /** * 自定义固定值校验 */ @FixedValueValidator(fixedValue = {\u0026#34;boy\u0026#34;, \u0026#34;girl\u0026#34;}, message = \u0026#34;性别有误\u0026#34;, groups = {Update.class, Insert.class}) private String sex; @Length(min = 11, max = 11, message = \u0026#34;手机号只能为11位\u0026#34;) @Pattern(regexp = \u0026#34;^[1][3,4,5,6,7,8,9][0-9]{9}$\u0026#34;, message = \u0026#34;手机号格式有误\u0026#34;) @NotNull private String phone; @Email(message = \u0026#34;邮箱格式不正确\u0026#34;) private String email; @NotNull(message = \u0026#34;地址不能为空\u0026#34;, groups = {Insert.class, Update.class}) @Valid private List\u0026lt;Address\u0026gt; address; @NotNull(message = \u0026#34;地址不能为空\u0026#34;, groups = {Insert.class, Update.class}) @Valid private Map\u0026lt;String,Address\u0026gt; addressMap; } 集合校验 如果参数直接是个集合的话，我们也想要校验集合里面的每一对象的话。直接使用java.util.Collection下的list或者set来接收数据，参数校验并不会生效！我们可以使用自定义list集合来接收参数。这种集合校验就是参考嵌套校验\n1 2 3 4 5 6 7 8 9 10 11 12 13 /** * @author peilizhi * @date 2022/12/8 01:04 **/ public class ValidationList\u0026lt;E\u0026gt;{ /** * 一定要加@Valid注解 */ @Valid @Delegate public List\u0026lt;E\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); } @Delegate是 lombook 的注解，用于为对象生成一些方法。可以理解为A、B 有相同的方法，但是调用A 里面方法的时候实际是调用B里面的方法\n1 2 3 4 5 6 7 8 @PostMapping(value = \u0026#34;batch-insert-user\u0026#34;) public String batchInsertUser(@RequestBody ValidationList\u0026lt;UserDO\u0026gt; UserList) { UserList.forEach(userDO -\u0026gt; { userDO.setUserId(UUID.randomUUID().toString()); log.info(\u0026#34;user:{}\u0026#34;, JSONUtil.toJsonStr(userDO)); }); return \u0026#34;OK\u0026#34;; } 自定义校验 先定义校验注解（指标注解作用域，作用时机） 添加 @Constraint 指明通过哪个类来校验 实现校验类 校验类需要实现ConstraintValidator \u0026lt;自定义注解，待校验的对象类型\u0026gt;注解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 /** * 固定值校验 * * @author by peilizhi * @date 2022/12/6 00:46 */ @Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER}) @Retention(RUNTIME) @Documented @Constraint(validatedBy = {FixedValueValidator.FixedValueValid.class}) public @interface FixedValueValidator { String message() default \u0026#34;FixedValue\u0026#39;s value is invalid\u0026#34;; Class\u0026lt;?\u0026gt;[] groups() default {}; Class\u0026lt;? extends Payload\u0026gt;[] payload() default {}; String[] fixedValue(); class FixedValueValid implements ConstraintValidator\u0026lt;FixedValueValidator, Object\u0026gt; { String[] fixedValue = null; @Override public void initialize(FixedValueValidator validData) { this.fixedValue = validData.fixedValue(); } /** * 校验值是否在固定值范围里面 * * @param value 待校验的值 */ @Override public boolean isValid(Object value, ConstraintValidatorContext constraintContext) { if (fixedValue == null || fixedValue.length == 0) { return false; } if (value == null) { return true; } boolean flag = false; for (String str : fixedValue) { if (String.valueOf(value).equals(String.valueOf(str))) { flag = true; break; } } return flag; } } } 编程式校验 编程式校验意味着不是通过注解自动校验，而是通过手动编码来校验\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Autowired private javax.validation.Validator globalValidator; @PostMapping(value = \u0026#34;manual-insert-user\u0026#34;) public String manualInsertUser(@RequestBody UserDO userDO) { log.info(\u0026#34;user0:{}\u0026#34;, JSONUtil.toJsonStr(userDO)); // 手动校验 final Set\u0026lt;ConstraintViolation\u0026lt;UserDO\u0026gt;\u0026gt; validate = globalValidator.validate(userDO); if (!validate.isEmpty()) { // 校验失败 return \u0026#34;ERROR\u0026#34;; } userDO.setUserId(UUID.randomUUID().toString()); log.info(\u0026#34;user:{}\u0026#34;, JSONUtil.toJsonStr(userDO)); return userDO.getUserId(); } 快速失败 校验是全部校验完成之后才结束，可以配置只有一个错误就提前退出\n1 2 3 4 5 6 7 8 9 @Bean public Validator validator() { ValidatorFactory validatorFactory = Validation.byProvider(HibernateValidator.class) .configure() // 快速失败模式 .failFast(true) .buildValidatorFactory(); return validatorFactory.getValidator(); } ","date":"2022-12-04T23:35:31+08:00","permalink":"https://blog.huochai.xyz/posts/springboot/validation/","title":"Validation"},{"content":"dafglfjnjklafkfkfk\n","date":"2022-12-01T00:09:51+08:00","permalink":"https://blog.huochai.xyz/posts/blog/%E6%A0%87%E7%AD%BE/","title":"标签"},{"content":"背景 最近工作上有需求需要了解 java 整合 js 计算引擎，就看了看同事之前写的代码，写的真好，对我有一种醍醐灌顶的感觉，也借此机会学习学习js 计算引擎\n项目中使用的是 Nashorn 引擎，\nNashorn官网\n使用 Nashorn 引擎计算的本质，在执行一个j s 函数，函数中可以自定义一些变量和函数，也可以使用j s 原生的函数，在使用自定义函数的时候需要告诉函数是怎么运行的。计算的结果也放在这个函数的作用域中，可以有多个计算结果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import javax.script.*; public class EvalScript { public static void main(String[] args) throws Exception { // create a script engine manager ScriptEngineManager factory = new ScriptEngineManager(); // create a Nashorn script engine ScriptEngine engine = factory.getEngineByName(\u0026#34;nashorn\u0026#34;); // evaluate JavaScript statement try { // 这里执行的时候 等同于执行 js脚本 engine.eval(\u0026#34;print(\u0026#39;Hello, World!\u0026#39;);\u0026#34;); } catch (final ScriptException se) { se.printStackTrace(); } } } 如果要使用自定义函数、变量的话，就需要再引擎里面声明这些自定义函数、变量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 /** * 公式计算 * * @param params 参数 */ public String calcuate(List\u0026lt;String\u0026gt; formulationList, Map\u0026lt;String, Double\u0026gt; params) throws Exception { if (CollectionUtils.isEmpty(formulationList)) { return StringUtils.EMPTY; } // 获取自定义解析器 ScriptEngine engine = factory.getScriptEngine(); for (IScriptStrategy iScriptStrategy : factory.getScriptStrategyList()) { final EFunctionEnum func = iScriptStrategy.getFunc(); // 绑定解析器 String key = func.toString(); engine.put(key, iScriptStrategy); // 绑定到引擎上,用于绑定自定义函数 engine.eval(\u0026#34;Object.bindProperties(this, \u0026#34; + key + \u0026#34;)\u0026#34;); } // 绑定参数 params.forEach(engine::put); // 计算 for (String formulation : formulationList) { engine.eval(formulation); } // 可以获取多个返回,直接从引擎到作用域中获取 final Object vale = engine.get(\u0026#34;得分\u0026#34;); final Object o = engine.get(\u0026#34;判断\u0026#34;); final String doubleValue = DoubleUtil.handleDoubleValue(o); System.out.println(\u0026#34;判断 = \u0026#34; + doubleValue); System.out.println(\u0026#34;DoubleUtil.handleDoubleValue(vale) = \u0026#34; + DoubleUtil.handleDoubleValue(vale)); return DoubleUtil.handleDoubleValue(vale); } put put方法就是向解析器注册一个变量、函数\nObject.bindProperties 这个方法用于向解析器绑定自定义的函数。需要先定义类，之后在将类中的所有方法放到解析器中，比较耗时\n这里绑定的函数 需要和公式里面的函数名称保持一致\nget 从解析器中获取对象，常用于换取结果。j s 中可以定义多个赋值语句，get 就能获取赋值语句的结果\n注：这里计算的时候很需要关注字段类型。\n字符串 与 Double 计算逻辑不一致的。\n举例： + 运算符对应 字符串来说就是拼接，对于Double 就是相加运算\n再举例： \u0026gt; 运算符对于 字段串来说 “5”\u0026gt; \u0026ldquo;10\u0026rdquo; true\n","date":"2022-11-29T16:30:31+08:00","permalink":"https://blog.huochai.xyz/posts/blog/nashorn%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/","title":"Js计算引擎"},{"content":"域名是打开与外界沟通的首要条件\n购买域名时个人用户的就首要考虑便宜，续费方便，安全\n在阿里云上购买域名 ：huochai.xyz\n配置dns 记录\n服务器还是购买的阿里云。使用老客户优惠。\n公网ip:47.93.247.254\n并且已经建立dns 解析\n购买域名、服务器之后要进行备案\n可以选择在阿里云上直接进行备案，备案就是填一些真实信息\n备案的时候可以选择身份证上所在的地址，如果地址不同的话需要提交暂住证\n修改域名服务器\n从阿里云上购买域名之后，默认使用阿里云的DNS服务器，想要修改为使用Cloudflare 名称服务器\n先注册Cloudflare 账号，再登录\n找到dns 服务器\n登录阿里云修改\n登录阿里云域名控制台。 把Cloudflare 里面dns域名服务器复制过来，再修改\n查看dns 解析过程\n1 2 3 4 5 # 显示解析过程 dig huochai.xyz +trace nslookup huochai.xyz 在国内购买域名之后都需要进行备案，否则外界无法使用https 访问\n","date":"2022-11-28T19:34:30+08:00","permalink":"https://blog.huochai.xyz/posts/blog/%E8%B4%AD%E4%B9%B0%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%99%A8/","title":"购买域名服务器"},{"content":"在typora 中书写博客\n一、 需要掌握markdown 语法 二、需要设置图片位置 在插入图片的时候，同时将图片复制到网站根目录 static/images 里面\n三、目录设置 ","date":"2022-11-28T14:56:46+08:00","permalink":"https://blog.huochai.xyz/posts/typora/","title":"Typora"},{"content":"这是第一篇博客测试\n的点点滴滴\n","date":"2022-11-25T22:33:06+08:00","permalink":"https://blog.huochai.xyz/posts/my-first-blog/","title":"My First Blog"},{"content":"","date":"0001-01-01T00:00:00Z","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%8D%95%E4%BE%8B11%E6%A8%A1%E5%BC%8F/","title":""},{"content":"","date":"0001-01-01T00:00:00Z","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%8D%95%E4%BE%8B22%E6%A8%A1%E5%BC%8F/","title":""},{"content":"","date":"0001-01-01T00:00:00Z","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%8D%95%E4%BE%8B23%E6%A8%A1%E5%BC%8F/","title":""},{"content":"","date":"0001-01-01T00:00:00Z","permalink":"https://blog.huochai.xyz/posts/java%E5%9F%BA%E7%A1%80/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%8D%95%E4%BE%8B24%E6%A8%A1%E5%BC%8F/","title":""}]